<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[django-filter]]></title>
    <url>%2F2019%2F06%2F24%2Fdjango-filter%2F</url>
    <content type="text"><![CDATA[Django-filter是一个通用的、可重用的应用程序来缓解写一些平凡的视图代码。具体地说,它允许用户过滤queryset基于模型的字段，从而显示对应的过滤结果。 使用django-filter 的时候能节省很多查询的后台代码 可自动生成docs文档 安装建议在虚拟环境中操作 1pip install django-filter 导入123456INSTALLED_APPS = [ ... &apos;django_filters&apos;, &apos;rest_framework&apos;, ...] 使用models.py用来生成数据库的，生成应用时会自带此文件 123456from django.db import modelsclass UserInfo(models.Model): username = models.CharField(max_length=255) phone = models.CharField(max_length=255) addr = models.CharField(max_length=255) myfilter.py新建文件，用来定义过滤类 12345678910from django_filters import rest_framework as filtersclass UserInfoFilter(filters.FilterSet): &quot;&quot;&quot; 获取用户信息 &quot;&quot;&quot; name = filters.CharFilter(field_name=&quot;username&quot;, lookup_expr=&apos;exact&apos;,help_text=u&apos;用户名&apos;) # exact 精确匹配 class Meta: model = UserInfo # models fields = () # 空=所有 或 (username,)指定列 serializers.py这个是DRF相关的东西，放着供参考 1234567from mytest.models import UserInfofrom rest_framework import serializersclass UserInfoSerializerI(serializers.ModelSerializer): class Meta: model = UserInfo fields = &apos;__all__&apos; view.py123456789101112131415from mytest.models import UserInfo # 这里导入的是models.py 下的方法from myfilter import UserInfoFilterfrom serializers import UserInfoSerializerfrom django_filters.rest_framework import DjangoFilterBackend# 这里使用了DRFclass FetchUserInof(mixins.ListModelMixin,viewsets.GenericViewSet): &quot;&quot;&quot; 获取用户信息 &quot;&quot;&quot; queryset = UserInfo.objects.all() serializer_class = UserInfoSerializer # 这里是DRF相关内容 filter_backends = (DjangoFilterBackend,) filter_class = UserInfoFilter]]></content>
      <categories>
        <category>web</category>
        <category>django</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gerrit安装和使用]]></title>
    <url>%2F2019%2F06%2F21%2Fgerrit%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[个人记录 安装新建用户1234# 创建专用账户useradd gerrit# 为账户设置密码passwd gerrit 安装java12345略$ java -versionjava version &quot;1.8.0_45&quot;Java(TM) SE Runtime Environment (build 1.8.0_45-b14)Java HotSpot(TM) 64-Bit Server VM (build 25.45-b02, mixed mode) 安装mysql如果不打算使用gerrit 自带的H2数据库的话 12345678910安装-----略# 创建db usermysql&gt; CREATE USER &apos;gerrit&apos;@&apos;%&apos; IDENTIFIED BY &apos;password&apos;;#创建要用的DBmysql&gt; CREATE DATABASE GerritDB;#授权mysql&gt; GRANT ALL ON GerritDB.* TO &apos;gerrit&apos;@&apos;%&apos;; 安装git1# yum -y install git 安装gerrit12345678# 切换用户su - gerrit# 下载wget https://gerrit-releases.storage.googleapis.com/gerrit-2.15.5.war#安装 review_site 为定义的安装目录，默认安装在当前目录下（家目录） java -jar gerrit-2.15.war init -d review_site 一路回车默认安装 (其中的认证方式处改为 HTTP) 1Authentication method [OPENID/?]: HTTP 另外，建议这几个插件也顺便安装上，全部选y 1234567Installing plugins.Install plugin commit-message-length-validator version v2.15.5 [y/N]?Install plugin download-commands version v2.15.5 [y/N]?Install plugin hooks version v2.15.5 [y/N]?Install plugin replication version v2.15.5 [y/N]?Install plugin reviewnotes version v2.15.5 [y/N]?Install plugin singleusergroup version v2.15.5 [y/N]? 文件夹授权 1# chown -R gerrit:gerrit review_site 修改配置 123456789101112131415161718192021222324$ vim review_site/etc/gerrit.config[gerrit] basePath = git #指定被gerrit管理git库存放位置：review_site_project/git/ serverId = 1048a788-9fb9-4d7d-8da4-aa44be83aa7a canonicalWebUrl = http://192.168.1.66:8088/ #指定web访问gerrit的网址，填自己的ip和端口号[database] type = h2 #指定gerrit所默认数据库类型，h2 已经够用了 可以选用mysql，安装并创建gerrit账户 database = /home/gerrit/review_site/db/GerritDB[index] type = LUCENE[auth] type = HTTP #指定浏览器登录gerrit时的认证方式[sendemail] smtpServer = localhost[container] user = gerrit #指定gerrit所在机器的用户身份与上文创建的用户对应一致,可以是root javaHome = /usr/local/jdk1.8.0_45/jre[sshd] listenAddress = *:29418 #指定sshd服务监听的端口号[httpd] listenUrl = http://*:8088/ #指定http代理地址[cache] directory = cache #缓存位置 启动 1review_site/bin/gerrit.sh start htpasswd12345 #工具安装yum -y install httpd-tools #生成密码文件htpasswd -c /home/gerrit/review_site/etc/gerrit.password gerrit #然后输入密码 注意，如果此时你是用root生成的密码文件，记得更改权限，粗暴点 1chown -R gerrit:gerrit /home/gerrit 安装gitweb1yum -y install gitweb 修改配置 1234/etc/gitweb.conf# 更改路径为你的路径our $projectroot = &quot;/home/gerrit/review_site/git&quot;; 修改 /home/gerrit/review_site/etc/gerrit.config,追加内容 123[gitweb] cgi = /var/www/git/gitweb.cgi type = gitweb 安装nginx1234# 安装依赖yum -y install gcc-c++ pcre pcre-devel zlib zlib-devel openssl安装 ----略 配置 123456789101112131415161718192021# 添加basic认证，修改locationserver &#123; listen 80; server_name 192.168.1.66; #charset koi8-r; #access_log logs/host.access.log main; auth_basic &quot;Welcomme!&quot;; auth_basic_user_file /home/gerrit/review_site/etc/gerrit.password; location / &#123; root html; index index.html index.htm; proxy_pass http://192.168.1.66:8088; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #proxy_set_header X-Forwarded-For $remote_addr; &#125; 重启服务12/home/gerrit/review_site/bin/gerrit.sh restart/usr/local/nginx/sbin/nginx -s reload 访问 http://192.168.1.xxx 既可 使用Projects –&gt; List能看到两个默认的项目All-Projects和 All-Users，这两个工程是两个基础的工程，我们新建的工程默认都是继承自All-Projects的权限 设置： 右上角-用户名--setting - Preferences 偏好设置，Show Change Number In Changes Table 勾选 右上角-用户名--setting - SSH Public Keys 将客户机的公钥添加上 右上角-用户名--setting - HTTP Password 生成一个访问密码，可用来访问API接口 创建项目老版UI Projects –&gt; List 点进项目可查看到项目的一些配置，无需更改太多 Require Change-Id in commit message: true ，其余可默认 点access 点 edit 可对项目进行单独的授权等 点Add Reference ，将Reference设置为 refs/* 点Add Permission ,选read 然后进行相应的赋权 添加普通用户添加普通用户的访问 1234# 密钥文件可提前收集好cat ~/home/zili.pub | ssh gerrit gerrit create-account --full-name zili --email zili@zili.com --ssh-key - zili此命令意味着 管理员把用户zili加入到了Anonymous Users用户组中，并且设置了他的全称，邮件以及公钥文件 然后我们就可以去 People - List Groups 创建组，将人员划分到组内，同时 创建项目的时候就能添加相应的组了。 克隆项目12345git clone ssh://gerrit@192.168.1.66:29418/test &amp;&amp; scp -p -P 29418 gerrit@192.168.1.66:hooks/commit-msg test/.git/hooks/git config user.name testgit config user.email test@test.com 修改push分支1git config remote.origin.push refs/heads/*:refs/for/* 当执行push命令时，将会推送到refs/for/当前head所在的分支上 然后我们做的所有操作都将会被gerrit记录下来了 review略 api使用安装 pygerrit2 1234567891011from pygerrit2 import GerritRestAPI, HTTPBasicAuthauth = HTTPBasicAuth(&apos;gerrit&apos;, &apos;2X8XonAccDXFY7mLFfFcadHMuS1QIA2FHfPQyIXUvg&apos;)#auth = HTTPBasicAuth(&apos;gerrit&apos;, &apos;gerrit&apos;)print(auth)rest = GerritRestAPI(url=&apos;http://192.168.1.66:8088&apos;, auth=auth)changes = rest.get(&quot;/access/?project=All-Projects&quot;)print(changes)# 注意使用的是基本认证还是摘要认证，还有版本 2.14 前后区别,见官网 详见https://github.com/dpursehouse/pygerrit2]]></content>
      <categories>
        <category>运维工具</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>gerrit</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx+lua获取get和post参数]]></title>
    <url>%2F2019%2F05%2F15%2Fnginx-lua%E8%8E%B7%E5%8F%96get%E5%92%8Cpost%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[nginx 获取GET参数，或者POST参数，进行动态的转发等 mkdir /opt/packages 安装nginx12345678910111213141516171819202122# 安装依赖yum -y install gcc gcc-c++ glib* make autoconf openssl openssl-devel \libxslt-devel gd gd-devel pcre pcre-devel readline-devel wget curlcd /opt/packageswget http://nginx.org/download/nginx-1.12.2.tar.gz#新建用户，如果不新建，configure时则不要指定用户useradd -M -s /sbin/nologin nginx #编译，此时可以不编译安装，因为后续需添加模块到nginx./configure --user=nginx --group=nginx --prefix=/usr/local/nginx --with-file-aio \--with-http_ssl_module --with-http_realip_module --with-http_addition_module \--with-http_xslt_module --with-http_image_filter_module --with-http_sub_module \--with-http_dav_module --with-http_flv_module --with-http_mp4_module \--with-http_gunzip_module --with-http_gzip_static_module \--with-http_auth_request_module --with-http_random_index_module \--with-http_secure_link_module --with-http_degradation_module \--with-http_stub_status_module#安装make -j2 &amp;&amp; make install 安装LuaJIT12345cd /opt/packageswget http://luajit.org/download/LuaJIT-2.0.5.tar.gztar -zxvf LuaJIT-2.0.5.tar.gzcd LuaJIT-2.0.5make install PREFIX=/usr/local/LuaJIT 输出 以下内容则成功 ==== Successfully installed LuaJIT 2.0.5 to /usr/local/LuaJIT ==== 修改环境变量 12345export LUAJIT_LIB=/usr/local/LuaJIT/libexport LUAJIT_INC=/usr/local/LuaJIT/include/luajit-2.0#退出后source /etc/profile ngx_devel_kit12345cd /opt/packageswget https://github.com/simplresty/ngx_devel_kit/archive/v0.3.0.tar.gztar zxvf v0.3.0.tar.gz#放着，一会编译ngxin时导入。 安装lua-nginx-module 12345cd /opt/packageswget https://github.com/openresty/lua-nginx-module/archive/v0.10.13.tar.gztar zxvf v0.10.13.tar.gz#放着，一会编译ngxin时导入。 编译模块至nginx123456789101112131415#如果nginx已经安装 执行nginx -V 可查看编译参数./configure --user=nginx --group=nginx --prefix=/usr/local/nginx --with-file-aio \--with-http_ssl_module --with-http_realip_module --with-http_addition_module \--with-http_xslt_module --with-http_image_filter_module --with-http_sub_module \--with-http_dav_module --with-http_flv_module --with-http_mp4_module \--with-http_gunzip_module --with-http_gzip_static_module \--with-http_auth_request_module --with-http_random_index_module \--with-http_secure_link_module --with-http_degradation_module \--with-http_stub_status_module \--with-ld-opt=-Wl,-rpath,/usr/local/LuaJIT/lib \--add-module=/opt/packages/ngx_devel_kit-0.3.0 \--add-module=/opt/packages/lua-nginx-module-0.10.13make -j2 &amp;&amp; make install 编译主要添加的是 这三条数据 123--with-ld-opt=-Wl,-rpath,/usr/local/LuaJIT/lib \--add-module=/opt/packages/ngx_devel_kit-0.3.0 \--add-module=/opt/packages/lua-nginx-module-0.10.13 测试lua模块修改nginx.conf 的server 添加如下 12345678910location /lua &#123; default_type &apos;text/plain&apos;; content_by_lua &apos;ngx.say(&quot;lua install success&quot;)&apos;; &#125;# 重加载nginxnginx -s reloadcurl http://127.0.0.1/lua#返回 ： lua install success lua 模块安装完毕。 安装 cjson如果需要lua解析json，可安装此模块 123cd /opt/packageshttp://www.kyne.com.au/~mark/software/download/lua-cjson-2.1.0.tar.gzmake 如若报错如下 123456cc -c -O3 -Wall -pedantic -DNDEBUG -I/usr/local/include -fpic -o lua_cjson.o lua_cjson.clua_cjson.c:43:17: 致命错误：lua.h：没有那个文件或目录 #include &lt;lua.h&gt; ^编译中断。make: *** [lua_cjson.o] 错误 1 修改Makefile 这两处 12PREFIX = /usr/local/LuaJITLUA_INCLUDE_DIR = $(PREFIX)/include/luajit-2.0 复制cjson.so 12cp cjson.so /usr/local/LuaJIT/lib/lua/5.1/chmod 755 /usr/local/LuaJIT/lib/lua/5.1/cjson.so 使用lua 去rewrite路由123456789101112131415161718192021222324252627282930313233location /zili &#123; # 请求体的size大于nginx配置里的client_body_buffer_size # 则会导致请求体被缓冲到磁盘临时文件里，client_body_buffer_size默认是8k或者16k # 如果考虑性能，可以使用ngx.req.get_body_file()，见后续 client_max_body_size 100m ; client_body_buffer_size 100m ; set $proxy &apos;&apos;; rewrite_by_lua_block &#123; local request_method = ngx.var.request_method if request_method == &quot;GET&quot; then local arg = ngx.req.get_uri_args()[&quot;proxy&quot;] or 0 ngx.var.proxy = arg elseif request_method == &quot;POST&quot; then ngx.req.read_body() local jkdata = ngx.req.get_body_data() --ngx.print(jkdata) if jkdata then --如果传进来的是 json 通过这种方式解析， --cjson = require &quot;cjson&quot; --jkval = cjson.decode(jkdata) --ngx.var.proxy = valp[&quot;proxy&quot;] --这里比较糙，使用正则去匹配了需要的ip字符串 ngx.var.proxy = jkdata:match(&quot;(%d+%.%d+%.%d+%.%d+)&quot;) --ngx.var.proxy = jkval[&quot;proxy&quot;] end end &#125; include /usr/local/nginx/conf/uwsgi_params; proxy_pass $proxy:18001; access_log logs/aaa_access.log zili;&#125; ngx.req.get_body_file() 1234567891011121314151617181920212223ngx.req.read_body()body_data = ngx.req.get_body_data()if not body_data then local datafile = ngx.req.get_body_file() if not datafile then error_code = 1 error_msg = &quot;no request body found&quot; else local fh, err = io.open(datafile, &quot;r&quot;) if not fh then error_code = 2 error_msg = &quot;failed to open &quot; .. tostring(datafile) .. &quot;for reading: &quot; .. tostring(err) else fh:seek(&quot;set&quot;) body_data = fh:read(&quot;*a&quot;) fh:close() if body_data == &quot;&quot; then error_code = 3 error_msg = &quot;request body is empty&quot; end end end end 相关包1链接: https://pan.baidu.com/s/1nq9pOQO7uj88DwfHaT0EDg 提取码: p3fh 完]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django RESTful API]]></title>
    <url>%2F2018%2F10%2F21%2Fdjango-RESTful-API%2F</url>
    <content type="text"><![CDATA[django RESTful API 官网开发中经常遇到前后端分离,实现就要借助API.API简单说就是开发人员提供编程接口被其他人调用,他们调用之后会返回数据供其使用API的类型有多种，但是现在比较主流且实用的就是RESTful API.本文用作个人记录 依赖环境123Django (1.11.11)django-filter (1.1.0)djangorestframework (3.8.2) 我的项目如下,myproject是项目 , api应用,data是主应用 1234567891011121314151617181920212223242526├── myproject│ ├── wsgi.py│ ├── urls.py│ ├── settings.py│ └── __init__.py├── manage.py└── api ├── views.py ├── urls.py ├── tests.py ├── serializer.py ├── models.py ├── migrations │ └── __init__.py ├── __init__.py ├── apps.py └── admin.py└── data ├── views.py ├── tests.py ├── models.py ├── migrations │ └── __init__.py ├── __init__.py ├── apps.py └── admin.py 注入应用修改setting文件 123456INSTALLED_APPS = [ ... &apos;data&apos;, &apos;rest_framework&apos;, &apos;api&apos;,] 全局渲染其实渲染有多种类型,局部的全局的等 这里设置的是全局的 在项目setting 追加 12345REST_FRAMEWORK = &#123; &apos;DEFAULT_RENDERER_CLASSES&apos;: ( &apos;rest_framework.renderers.JSONRenderer&apos;, )&#125; 使用模型序列器ModelSerializers api项目下新建文件serializer.py和urls.py 内如参考如下 serializer.py12345678910111213141516171819from rest_framework import serializersfrom data.models import * #导入data下的modelsclass OsInfoSerializer(serializers.ModelSerializer): class Meta: model =OsInfo #fields = &apos;__all__&apos; # 所有 fields =(&apos;id&apos;,&apos;host_ip&apos;,&apos;os_sys&apos;,&apos;os_version&apos;,等等)#定义了针对数据库表数据的过滤筛选类#=================第二种，post 推荐======================class FetchOsInfoSerializer(serializers.Serializer): &quot;&quot;&quot; 获取操作系统信息参数序列化 &quot;&quot;&quot; ip = serializers.CharField(min_length=7, max_length=15, label=&quot;主机ip&quot;,help_text=&apos;操作系统ip&apos;) urls.py123456789101112from django.conf.urls import url, includefrom rest_framework.routers import DefaultRouterfrom api import views as api_viewsrouter = DefaultRouter()# os router.register(&apos;osinfo/one&apos;,api_views.OsInfoOne,base_name=&apos;os_info_one&apos;)urlpatterns = [ url(r&apos;^&apos;, include(router.urls)),] views.py1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# data dbfrom data.models import *#serializerfrom serializer import * #rest frameworkimport django_filtersfrom rest_framework import viewsets, filtersfrom rest_framework.response import Responseclass OsInfoOne(viewsets.ViewSet): def list(self,request): ip = request.GET[&apos;ip&apos;] if ip is not None: try: queryset = OsInfo.objects.filter(host_ip=ip) serializer_class = OsInfoSerializer serializer = OsInfoSerializer(queryset, many=True) except: return Response(&apos;OsInfoOne serializer error&apos;) else: return Response(&apos;missing parameter ip=xxx&apos;) if serializer.data == []: return Response(&apos;None&apos;) else: return Response(serializer.data) #=================第二种，post 推荐======================class OsInfoOne(mixins.CreateModelMixin,viewsets.GenericViewSet): &quot;&quot;&quot; 这里是接口描述 &quot;&quot;&quot; serializer_class = FetchOsInfoSerializer def create(self,request): &quot;&quot;&quot; 根据ip获取主机信息 &quot;&quot;&quot; serializer = self.get_serializer(data=request.data) serializer.is_valid(raise_exception=True) post_data = serializer.validated_data # print(post_data[&apos;ip&apos;]) if post_data[&quot;ip&quot;]: try: queryset = OsInfo.objects.filter(host_ip=post_data[&quot;ip&quot;]) serializer = serializers.OsInfoSerializer(queryset, many=True) except Exception as e: return Response(&#123;&quot;status&quot;:&quot;failed&quot;,&quot;message&quot;:str(e)&#125;) else: try: queryset = OsInfo.objects.all() serializer = serializers.OsInfoSerializer(queryset, many=True) except Exception as e: return Response(&#123;&quot;status&quot;:&quot;failed&quot;,&quot;message&quot;:str(e)&#125;) if serializer.data == []: return Response(&#123;&quot;status&quot;:&quot;failed&quot;,&quot;message&quot;:&apos;Data is empty&apos;&#125;) else: return Response(serializer.data) urls.py(project下)1234urlpatterns = [ url(r&apos;^admin/&apos;, admin.site.urls), url(r&apos;^api/&apos;, include(&apos;api.urls&apos;)), .... 到这里整个流程基本走完了. 运行程序1python manage.py runserver 0.0.0.0:8888 浏览器访问http://ipaddress:8888/api/osinfo/one/?ip=192.168.1.55 返回结果: 123456789101112131415[ &#123; id: 30, host_ip: &quot;192.168.1.55&quot;, os_sys: &quot;GNU/Linux&quot;, os_version: &quot;CentOS Linux release 7.2.1511 (Core) &quot;, os_kernel: &quot;3.10.0-327.el7.x86_64&quot;, cpu_model: &quot; Intel(R) Xeon(R) CPU E5-2643 v2 @ 3.50GHz&quot;, cpu_num: &quot;2&quot;, cpu_core: &quot; 1&quot;, mem_total: &quot;4096&quot;, disk_total: &quot;100 GB&quot;, product_id: &quot; VMware-42 1a 0e 57 54 30 bc a6-67 a5 f7 63 41 dd ed db&quot; &#125;] 更多方法的使用见官网或参考这里]]></content>
      <categories>
        <category>web</category>
        <category>django</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二进制安装kubernetes集群]]></title>
    <url>%2F2018%2F09%2F18%2F%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E8%A3%85kubernetes%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[kubernetes集群部署 集群规划一主二从 master:192.168.1.245(k8s) 组件 版本 路径 etcd 3.3.8 /usr/bin flannel 0.10.0 /opt/flannel/ cni 0.7.1 /opt/cni/ kubernetes 1.10.7 /usr/bin/kube-apiserver,kube-controller-manager,kube-scheduler node-1:192.168.1.161(k8s01)node-2:192.168.1.162(k8s02) 组件 版本 路径 docker 18.03.1-ce /usr/bin etcd 3.3.8 /usr/bin flannel 0.10.0 /opt/flannel/ cni 0.7.1 /opt/cni/ kubernetes 1.10.7 /usr/bin/kubelet,kube-proxy 安装包下载 etcd：https://github.com/coreos/etcd/releases/ flannel：https://github.com/coreos/flannel/releases/ cni：https://github.com/containernetworking/plugins/releases kubernetes：https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.10.md#v1107 前提,docker已安装 docker安装不赘述. 服务安装前置工作主机名解析是必须的! 设置好三台主机的主机名 hostnamectl --static set-hostname k8s/k8s01/k8s02 修改三台机器的/etc/hosts 添加修改如下 123456127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 k8s#127的修改是自己的主机名,在最后添加即可192.168.1.245 k8s192.168.1.161 k8s01192.168.1.162 k8s02 关闭防火墙和selinux 关闭SWAP分区 如果不关闭,kubelet将无法启动 swapoff -a 关闭. 然后vi /etc/fsta 12#/dev/mapper/centos-swap swap swap defaults 0 0# 注释此行 同步时间 12yum -y install ntpdatentpdate 0.cn.pool.ntp.org 安装etcd集群etcd入门 1234tar -zxvf etcd-v3.3.8-linux-amd64.tar.gzcp etcd etcdctl /usr/binmkdir -p /var/lib/etcd /etc/etcd #创建相关文件夹 以上操作,三台机器都要做. etcd配置文件三台机器都要有，略有不同,主要是两个文件 /usr/lib/systemd/system/etcd.service 和 /etc/etcd/etcd.conf etcd集群的主从节点关系与kubernetes集群的主从节点关系不是同的 etcd的配置文件只是表示三个etcd节点,etcd集群在启动和运行过程中会选举出主节点 因此，配置文件中体现的只是三个节点etcd-i，etcd-ii，etcd-iii 配置好三个节点的配置文件后,便可以启动etcd集群了 ndoe1 /usr/lib/systemd/system/etcd.service 123456789101112[Unit]Description=Etcd ServerAfter=network.target [Service]Type=notifyWorkingDirectory=/var/lib/etcd/EnvironmentFile=/etc/etcd/etcd.confExecStart=/usr/bin/etcd [Install]WantedBy=multi-user.target /etc/etcd/etcd.conf 123456789101112131415161718192021# [member]# 节点名称ETCD_NAME=etcd-i# 数据存放位置ETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot;# 监听其他Etcd实例的地址ETCD_LISTEN_PEER_URLS=&quot;http://192.168.1.245:2380&quot;# 监听客户端地址ETCD_LISTEN_CLIENT_URLS=&quot;http://192.168.1.245:2379,http://127.0.0.1:2379&quot; #[cluster]# 通知其他Etcd实例地址ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;http://192.168.1.245:2380&quot;# 初始化集群内节点地址ETCD_INITIAL_CLUSTER=&quot;etcd-i=http://192.168.1.245:2380,etcd-ii=http://192.168.1.161:2380,etcd-iii=http://192.168.1.162:2380&quot;# 初始化集群状态，new表示新建ETCD_INITIAL_CLUSTER_STATE=&quot;new&quot;# 初始化集群tokenETCD_INITIAL_CLUSTER_TOKEN=&quot;etcd-cluster-token&quot;# 通知客户端地址ETCD_ADVERTISE_CLIENT_URLS=&quot;http://192.168.1.245:2379,http://127.0.0.1:2379&quot; node2 /usr/lib/systemd/system/etcd.service 123456789101112[Unit]Description=Etcd ServerAfter=network.target [Service]Type=notifyWorkingDirectory=/var/lib/etcd/EnvironmentFile=/etc/etcd/etcd.confExecStart=/usr/bin/etcd [Install]WantedBy=multi-user.target /etc/etcd/etcd.conf 123456789101112131415161718192021# [member]# 节点名称ETCD_NAME=etcd-ii# 数据存放位置ETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot;# 监听其他Etcd实例的地址ETCD_LISTEN_PEER_URLS=&quot;http://192.168.1.161:2380&quot;# 监听客户端地址ETCD_LISTEN_CLIENT_URLS=&quot;http://192.168.1.161:2379,http://127.0.0.1:2379&quot; #[cluster]# 通知其他Etcd实例地址ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;http://192.168.1.161:2380&quot;# 初始化集群内节点地址ETCD_INITIAL_CLUSTER=&quot;etcd-i=http://192.168.1.245:2380,etcd-ii=http://192.168.1.161:2380,etcd-iii=http://192.168.1.162:2380&quot;# 初始化集群状态，new表示新建ETCD_INITIAL_CLUSTER_STATE=&quot;new&quot;# 初始化集群tokenETCD_INITIAL_CLUSTER_TOKEN=&quot;etcd-cluster-token&quot;# 通知客户端地址ETCD_ADVERTISE_CLIENT_URLS=&quot;http://192.168.1.161:2379,http://127.0.0.1:2379&quot; node3 /usr/lib/systemd/system/etcd.service 123456789101112[Unit]Description=Etcd ServerAfter=network.target [Service]Type=notifyWorkingDirectory=/var/lib/etcd/EnvironmentFile=/etc/etcd/etcd.confExecStart=/usr/bin/etcd [Install]WantedBy=multi-user.target /etc/etcd/etcd.conf 123456789101112131415161718192021# [member]# 节点名称ETCD_NAME=etcd-iii# 数据存放位置ETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot;# 监听其他Etcd实例的地址ETCD_LISTEN_PEER_URLS=&quot;http://192.168.1.162:2380&quot;# 监听客户端地址ETCD_LISTEN_CLIENT_URLS=&quot;http://192.168.1.162:2379,http://127.0.0.1:2379&quot; #[cluster]# 通知其他Etcd实例地址ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;http://192.168.1.162:2380&quot;# 初始化集群内节点地址ETCD_INITIAL_CLUSTER=&quot;etcd-i=http://192.168.1.245:2380,etcd-ii=http://192.168.1.161:2380,etcd-iii=http://192.168.1.162:2380&quot;# 初始化集群状态，new表示新建ETCD_INITIAL_CLUSTER_STATE=&quot;new&quot;# 初始化集群tokenETCD_INITIAL_CLUSTER_TOKEN=&quot;etcd-cluster-token&quot;# 通知客户端地址ETCD_ADVERTISE_CLIENT_URLS=&quot;http://192.168.1.162:2379,http://127.0.0.1:2379&quot; 启动etcd集群 12systemctl daemon-reloadsystemctl start etcd.service 检查集群状态 1234567891011[root@k8s ~]# etcdctl member list29c11a00212167fb: name=etcd-iii peerURLs=http://192.168.1.162:2380 clientURLs=http://127.0.0.1:2379,http://192.168.1.162:2379 isLeader=false393b6040645f784e: name=etcd-ii peerURLs=http://192.168.1.161:2380 clientURLs=http://127.0.0.1:2379,http://192.168.1.161:2379 isLeader=false9d56a160db6a1fd1: name=etcd-i peerURLs=http://192.168.1.245:2380 clientURLs=http://127.0.0.1:2379,http://192.168.1.245:2379 isLeader=true[root@k8s ~]# etcdctl cluster-healthmember 29c11a00212167fb is healthy: got healthy result from http://127.0.0.1:2379member 393b6040645f784e is healthy: got healthy result from http://127.0.0.1:2379member 9d56a160db6a1fd1 is healthy: got healthy result from http://127.0.0.1:2379cluster is healthy[root@k8s ~]# 安装flannel集群机器均需操作 flannel服务依赖etcd，必须先安装好etcd，并配置etcd服务地址-etcd-endpoints -etcd-prefix是etcd存储的flannel网络配置的键前缀 12mkdir -p /opt/flannel/bin/tar -xzvf flannel-v0.10.0-linux-amd64.tar.gz -C /opt/flannel/bin/ flannel配置文件/usr/lib/systemd/system/flannel.service 1234567891011121314151617[Unit]Description=Flanneld overlay address etcd agentAfter=network.targetAfter=network-online.targetWants=network-online.targetAfter=etcd.serviceBefore=docker.service [Service]Type=notifyExecStart=/opt/flannel/bin/flanneld -etcd-endpoints=http://192.168.1.245:2379,http://192.168.1.161:2379,http://192.168.1.162:2379 -etcd-prefix=coreos.com/networkExecStartPost=/opt/flannel/bin/mk-docker-opts.sh -d /etc/docker/flannel_net.env -cRestart=on-failure [Install]WantedBy=multi-user.targetRequiredBy=docker.service 执行一下命令设置flannel网络配置.(ip等信息可修改) 123etcdctl mk /coreos.com/network/config &apos;&#123;&quot;Network&quot;:&quot;172.18.0.0/16&quot;, &quot;SubnetMin&quot;: &quot;172.18.1.0&quot;, &quot;SubnetMax&quot;: &quot;172.18.254.0&quot;, &quot;Backend&quot;: &#123;&quot;Type&quot;: &quot;vxlan&quot;&#125;&#125;&apos;#删除 etcdctl rm /coreos.com/network/config 下载flannelflannel服务依赖flannel镜像，所以要先下载flannel镜像，执行以下命令从阿里云下载，并创建镜像tag： 12docker pull registry.cn-beijing.aliyuncs.com/k8s_images/flannel:v0.10.0-amd64docker tag registry.cn-beijing.aliyuncs.com/k8s_images/flannel:v0.10.0-amd64 quay.io/coreos/flannel:v0.10.0 配置dockerflannel配置中有一项 ExecStartPost=/opt/flannel/bin/mk-docker-opts.sh -d /etc/docker/flannel_net.env -c flannel启动后执行mk-docker-opts.sh，并生成/etc/docker/flannel_net.env文件 flannel会修改docker网络,flannel_net.env是flannel生成的docker配置参数,因此,还要修改docker配置项 /usr/lib/systemd/system/docker.service 12345678910111213141516171819202122232425262728293031323334353637[Unit]Description=Docker Application Container EngineDocumentation=https://docs.docker.com# After=network-online.target firewalld.serviceAfter=network-online.target flannel.serviceWants=network-online.target [Service]Type=notify# the default is not to use systemd for cgroups because the delegate issues still# exists and systemd currently does not support the cgroup feature set required# for containers run by dockerEnvironmentFile=/etc/docker/flannel_net.env#ExecStart=/usr/bin/dockerd $DOCKER_OPTSExecStart=/usr/bin/dockerdExecReload=/bin/kill -s HUP $MAINPIDExecStartPost=/usr/sbin/iptables -P FORWARD ACCEPT# Having non-zero Limit*s causes performance problems due to accounting overhead# in the kernel. We recommend using cgroups to do container-local accounting.LimitNOFILE=infinityLimitNPROC=infinityLimitCORE=infinity# Uncomment TasksMax if your systemd version supports it.# Only systemd 226 and above support this version.#TasksMax=infinityTimeoutStartSec=0# set delegate yes so that systemd does not reset the cgroups of docker containersDelegate=yes# kill only the docker process, not all processes in the cgroupKillMode=process# restart the docker process if it exits prematurelyRestart=on-failureStartLimitBurst=3StartLimitInterval=60s [Install]WantedBy=multi-user.target After：flannel启动之后再启动docker EnvironmentFile：配置docker的启动参数，由flannel生成 ExecStart：增加docker启动参数 ExecStartPost：在docker启动之后执行,会修改主机的iptables路由规则。 启动123systemctl daemon-reloadsystemctl start flannel.servicesystemctl restart docker.service CNI配置集群机器均需操作 CNI(Container Network Interface)容器网络接口，是Linux容器网络配置的一组标准和库，用户需要根据这些标准和库来开发自己的容器网络插件 12mkdir -p /opt/cni/bin /etc/cni/net.dtar -xzvf cni-plugins-amd64-v0.7.1.tgz -C /opt/cni/bin /etc/cni/net.d/10-flannel.conflist 12345678910111213141516171819&#123; &quot;name&quot;:&quot;cni0&quot;, &quot;cniVersion&quot;:&quot;0.3.1&quot;, &quot;plugins&quot;:[ &#123; &quot;type&quot;:&quot;flannel&quot;, &quot;delegate&quot;:&#123; &quot;forceAddress&quot;:true, &quot;isDefaultGateway&quot;:true &#125; &#125;, &#123; &quot;type&quot;:&quot;portmap&quot;, &quot;capabilities&quot;:&#123; &quot;portMappings&quot;:true &#125; &#125; ]&#125; 安装k8s集群CA证书证书生成漏了一个,然后后续补上的.命令并不一定正确!!! 还未验证 建议去网上搜索其他ca生成教程. 证书用途 命名 根证书和私钥 ca.crt、ca.key kube-apiserver证书和私钥 server.crt、server.key kube-controller-manager/kube-scheduler证书和私钥 cs_client.crt、cs_client.key kubelet/kube-proxy证书和私钥 kubelet_client.crt、kubelet_client.key master 创建证书目录 mkdir -p /etc/kubernetes/ca 生成根证书和私钥 1234openssl genrsa -out ca.key 2048openssl req -x509 -new -nodes -key ca.key -subj &quot;/CN=k8s&quot; -days 5000 -out ca.crt#/CN=主机名 生成kube-apiserver证书和私钥 新建master_ssl.conf 12345678910111213141516[req]req_extensions = v3_reqdistinguished_name = req_distinguished_name[req_distinguished_name][ v3_req ]basicConstraints = CA:FALSEkeyUsage = nonRepudiation, digitalSignature, keyEnciphermentsubjectAltName = @alt_names[alt_names]DNS.1 = kubernetesDNS.2 = kubernetes.defaultDNS.3 = kubernetes.default.svcDNS.4 = kubernetes.default.svc.cluster.localDNS.5 = k8s #master hostnameIP.1 = 172.18.0.1 #master clusterip 可通过kubectl get service获取IP.2 = 192.168.1.245 #master ip 生成 这里的生成经网友提醒后添加的,刚开始忘记写了.时间悠久也忘记了当时的命令 所以这个生成命令可能并不正确.- .. 有空再去验证记录把,这里记录下. 12345678# 生成 apiserver 私钥openssl genrsa -out server.key 2048# 生成签署请求openssl req -new -key server.key -out server.csr -subj &quot;/CN=k8s&quot; -days 5000 -config master_ssl.conf# 使用自建 CA 签署openssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out server.crt -days 5000 -extensions v3_req -extfile master_ssl.cnf #/CN=主机名 生成kube-controller-manager/kube-scheduler证书和私钥 12345openssl genrsa -out cs_client.key 2048openssl req -new -key cs_client.key -subj &quot;/CN=k8s&quot; -out cs_client.csropenssl x509 -req -in cs_client.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out cs_client.crt -days 5000 #/CN=主机名 node1 其他node同! IP据情况而定 123456mkdir -p /etc/kubernetes/ca# 将master节点的根证书和私钥拷贝到该目录下，执行以下命令生成证书和私钥：openssl genrsa -out kubelet_client.key 2048 openssl req -new -key kubelet_client.key -subj &quot;/CN=192.168.1.161&quot; -out kubelet_client.csr openssl x509 -req -in kubelet_client.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out kubelet_client.crt -days 5000 安装(master)123456789#解压tar -zxvf kubernetes-server-linux-amd64.tar.gz -C /opt#复制bin文件cd /opt/kubernetes/server/bincp -a `ls |egrep -v &quot;*.tar|*_tag&quot;` /usr/bin#创建日志文件路径mkdir -p /var/log/kubernetes 配置kube-apiserver /usr/lib/systemd/system/kube-apiserver.service 123456789101112131415[Unit]Description=Kubernetes API ServerDocumentation=https://github.com/GoogleCloudPlatform/kubernetesAfter=etcd.serviceWants=etcd.service [Service]EnvironmentFile=/etc/kubernetes/apiserver.confExecStart=/usr/bin/kube-apiserver $KUBE_API_ARGSRestart=on-failureType=notifyLimitNOFILE=65536 [Install]WantedBy=multi-user.target /etc/kubernetes/apiserver.conf 1234567891011121314151617181920212223242526KUBE_API_ARGS=&quot;\ --storage-backend=etcd3 \ --etcd-servers=http://192.168.1.245:2379,http://192.168.1.161:2379,http://192.168.1.162:2379 \ --bind-address=0.0.0.0 \ --secure-port=6443 \ --service-cluster-ip-range=172.18.0.0/16 \ --service-node-port-range=1-65535 \ --kubelet-port=10250 \ --advertise-address=192.168.1.245 \ --allow-privileged=false \ --anonymous-auth=false \ --client-ca-file=/etc/kubernetes/ca/ca.crt \ --tls-private-key-file=/etc/kubernetes/ca/server.key \ --tls-cert-file=/etc/kubernetes/ca/server.crt \ --enable-admission-plugins=NamespaceLifecycle,LimitRanger,NamespaceExists,SecurityContextDeny,ServiceAccount,DefaultStorageClass,ResourceQuota \ --logtostderr=true \ --log-dir=/var/log/kubernets \ --v=2&quot;##############################解释说明--etcd-servers #连接到etcd集群--secure-port #开启安全端口6443--client-ca-file、--tls-private-key-file、--tls-cert-file配置CA证书--enable-admission-plugins #开启准入权限--anonymous-auth=false #不接受匿名访问,若为true,则表示接受,此处设置为false,便于dashboard访问 配置kube-controller-managerserver 引用conf ,conf 里引用yaml /etc/kubernetes/kube-controller-config.yaml 1234567891011121314151617apiVersion: v1kind: Configusers:- name: controller user: client-certificate: /etc/kubernetes/ca/cs_client.crt client-key: /etc/kubernetes/ca/cs_client.keyclusters:- name: local cluster: certificate-authority: /etc/kubernetes/ca/ca.crtcontexts:- context: cluster: local user: controller name: default-contextcurrent-context: default-context /usr/lib/systemd/system/kube-controller-manager.service 1234567891011121314[Unit]Description=Kubernetes Controller ManagerDocumentation=https://github.com/GoogleCloudPlatform/kubernetesAfter=kube-apiserver.serviceRequires=kube-apiserver.service [Service]EnvironmentFile=/etc/kubernetes/controller-manager.confExecStart=/usr/bin/kube-controller-manager $KUBE_CONTROLLER_MANAGER_ARGSRestart=on-failureLimitNOFILE=65536 [Install]WantedBy=multi-user.target /etc/kubernetes/controller-manager.conf 1234567891011121314151617KUBE_CONTROLLER_MANAGER_ARGS=&quot;\ --master=https://192.168.1.245:6443 \ --service-account-private-key-file=/etc/kubernetes/ca/server.key \ --root-ca-file=/etc/kubernetes/ca/ca.crt \ --cluster-signing-cert-file=/etc/kubernetes/ca/ca.crt \ --cluster-signing-key-file=/etc/kubernetes/ca/ca.key \ --kubeconfig=/etc/kubernetes/kube-controller-config.yaml \ --logtostderr=true \ --log-dir=/var/log/kubernetes \ --v=2&quot; #######################master连接到master节点service-account-private-key-file、root-ca-file、cluster-signing-cert-file、cluster-signing-key-file配置CA证书kubeconfig是配置文件 配置kube-scheduler/etc/kubernetes/kube-scheduler-config.yaml 1234567891011121314151617apiVersion: v1kind: Configusers:- name: scheduler user: client-certificate: /etc/kubernetes/ca/cs_client.crt client-key: /etc/kubernetes/ca/cs_client.keyclusters:- name: local cluster: certificate-authority: /etc/kubernetes/ca/ca.crtcontexts:- context: cluster: local user: scheduler name: default-contextcurrent-context: default-context /usr/lib/systemd/system/kube-scheduler.service 123456789101112131415[Unit]Description=Kubernetes SchedulerDocumentation=https://github.com/GoogleCloudPlatform/kubernetesAfter=kube-apiserver.serviceRequires=kube-apiserver.service [Service]User=rootEnvironmentFile=/etc/kubernetes/scheduler.confExecStart=/usr/bin/kube-scheduler $KUBE_SCHEDULER_ARGSRestart=on-failureLimitNOFILE=65536 [Install]WantedBy=multi-user.target /etc/kubernetes/scheduler.conf 123456KUBE_SCHEDULER_ARGS=&quot;\ --master=https://192.168.1.245:6443 \ --kubeconfig=/etc/kubernetes/kube-scheduler-config.yaml \ --logtostderr=true \ --log-dir=/var/log/kubernetes \ --v=2&quot; 启动master1234systemctl daemon-reloadsystemctl start kube-apiserver.servicesystemctl start kube-controller-manager.servicesystemctl start kube-scheduler.service 日志查看. 12345journalctl -xeu kube-apiserver --no-pagerjournalctl -xeu kube-controller-manager --no-pagerjournalctl -xeu kube-scheduler --no-pager# 实时查看加 -f 安装(node)server 包中已包含了节点二进制文件. 123456789#解压tar -zxvf kubernetes-server-linux-amd64.tar.gz -C /opt#复制bin文件cd /opt/kubernetes/server/bincp -a kubectl kubelet kube-proxy /usr/bin/#创建日志文件路径mkdir -p /var/log/kubernetes touch /etc/sysctl.d/k8s.conf 12345net.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1# 修改内核参数,iptables过滤规则生效.如果未用到可忽略.# sysctl -p #配置生效 配置kubelet/etc/kubernetes/kubelet-config.yaml 12345678910111213141516171819apiVersion: v1kind: Configusers:- name: kubelet user: client-certificate: /etc/kubernetes/ca/kubelet_client.crt client-key: /etc/kubernetes/ca/kubelet_client.keyclusters:- cluster: certificate-authority: /etc/kubernetes/ca/ca.crt server: https://192.168.1.245:6443 name: localcontexts:- context: cluster: local user: kubelet name: default-contextcurrent-context: default-contextpreferences: &#123;&#125; /usr/lib/systemd/system/kubelet.service 12345678910111213[Unit]Description=Kubelet ServerDocumentation=https://github.com/GoogleCloudPlatform/kubernetesAfter=docker.serviceRequires=docker.service [Service]EnvironmentFile=/etc/kubernetes/kubelet.confExecStart=/usr/bin/kubelet $KUBELET_ARGSRestart=on-failure [Install]WantedBy=multi-user.target /etc/kubernetes/kubelet.conf 12345678910111213141516171819202122KUBELET_ARGS=&quot;\ --kubeconfig=/etc/kubernetes/kubelet-config.yaml \ --pod-infra-container-image=registry.aliyuncs.com/archon/pause-amd64:3.0 \ --hostname-override=192.168.1.161 \ --network-plugin=cni \ --cni-conf-dir=/etc/cni/net.d \ --cni-bin-dir=/opt/cni/bin \ --logtostderr=true \ --log-dir=/var/log/kubernetes \ --v=2&quot;###################--hostname-override #配置node名称 建议使用node节点的IP#--pod-infra-container-image=gcr.io/google_containers/pause-amd64:3.0 \--pod-infra-container-image #指定pod的基础镜像 默认是google的,建议改为国内,或者FQ或者 下载到本地重新命名镜像docker pull registry.cn-hangzhou.aliyuncs.com/google-containers/pause-amd64:3.0docker tag registry.cn-hangzhou.aliyuncs.com/google-containers/pause-amd64:3.0 gcr.io/google_containers/pause-amd64:3.0--kubeconfig #为配置文件 配置kube-proxy/etc/kubernetes/proxy-config.yaml 12345678910111213141516171819apiVersion: v1kind: Configusers:- name: proxy user: client-certificate: /etc/kubernetes/ca/kubelet_client.crt client-key: /etc/kubernetes/ca/kubelet_client.keyclusters:- cluster: certificate-authority: /etc/kubernetes/ca/ca.crt server: https://192.168.1.245:6443 name: localcontexts:- context: cluster: local user: proxy name: default-contextcurrent-context: default-contextpreferences: &#123;&#125; /usr/lib/systemd/system/kube-proxy.service 1234567891011121314[Unit]Description=Kube-Proxy ServerDocumentation=https://github.com/GoogleCloudPlatform/kubernetesAfter=network.targetRequires=network.service [Service]EnvironmentFile=/etc/kubernetes/proxy.confExecStart=/usr/bin/kube-proxy $KUBE_PROXY_ARGSRestart=on-failureLimitNOFILE=65536 [Install]WantedBy=multi-user.target /etc/kubernetes/proxy.conf 123456789101112KUBE_PROXY_ARGS=&quot;\ --master=https://192.168.1.245:6443 \ --hostname-override=192.168.1.161 \ --kubeconfig=/etc/kubernetes/proxy-config.yaml \ --logtostderr=true \ --log-dir=/var/log/kubernetes \ --v=2&quot; ######################--hostname-override #配置node名称,要与kubelet对应，kubelet配置了，则kube-proxy也要配置--master #连接master服务--kubeconfig #为配置文件 启动node123systemctl daemon-reloadsystemctl start kubelet.servicesystemctl start kube-proxy.service 日志查看 1234journalctl -xeu kubelet --no-pagerjournalctl -xeu kube-proxy --no-pager# 实时查看加 -f 查看节点全部安装完成后.可在master上查看node 1234[root@k8s bin]# kubectl get nodesNAME STATUS ROLES AGE VERSION192.168.1.161 Ready &lt;none&gt; 55m v1.10.7192.168.1.162 Ready &lt;none&gt; 15s v1.10.7 集群测试配置nginx 测试文件 (master) nginx-rc.yaml 123456789101112131415161718192021apiVersion: v1kind: ReplicationControllermetadata: name: nginx-rc labels: name: nginx-rcspec: replicas: 2 selector: name: nginx-pod template: metadata: labels: name: nginx-pod spec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent ports: - containerPort: 80 nginx-svc.yaml 123456789101112131415apiVersion: v1kind: Servicemetadata: name: nginx-service labels: name: nginx-servicespec: type: NodePort ports: - port: 80 protocol: TCP targetPort: 80 nodePort: 30081 selector: name: nginx-pod 启动 12345678kubectl create -f nginx-rc.yamlkubectl create -f nginx-svc.yaml#查看pod创建情况：kubectl get pod -o widehttp://node-ip:30081/ WEB UI下载dashboard yaml1wget https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml 修改文件 kubernetes-dashboard.yaml 1234image 那里 要修改下.默认的地址被墙了#image: k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.0image: mirrorgooglecontainers/kubernetes-dashboard-amd64:v1.8.3 12345678910111213141516171819202122232425262728293031323334kind: ServiceapiVersion: v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kube-systemspec: ports: - port: 443 targetPort: 8443 selector: k8s-app: kubernetes-dashboard##############修改后#############kind: ServiceapiVersion: v1metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kube-systemspec: type: NodePort ports: - port: 443 targetPort: 8443 nodePort: 30000 selector: k8s-app: kubernetes-dashboard添加type:NodePort暴露端口 ：30000 创建权限控制yamldashboard-admin.yaml 1234567891011121314apiVersion: rbac.authorization.k8s.io/v1beta1 kind: ClusterRoleBinding metadata: name: kubernetes-dashboard labels: k8s-app: kubernetes-dashboard roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: kubernetes-dashboard namespace: kube-system 创建 12kubectl create -f kubernetes-dashboard.yamlkubectl create -f dashboard-admin.yaml 查看 123[root@k8s test]# kubectl get pods --all-namespaces -o wideNAMESPACE NAME READY STATUS RESTARTS AGE IP NODEkube-system kubernetes-dashboard-66c9d98865-78r5h 1/1 Running 0 6s 172.18.100.7 192.168.1.161 访问 成功后可以直接访问 https://NODE_IP:配置的端口 访问 我这边是 https://192.168.1.162:30000 访问会提示登录.我们采取token登录 1kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk &apos;&#123;print $1&#125;&apos;) | grep token 1234567[root@k8s test]# kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk &apos;&#123;print $1&#125;&apos;) | grep tokenName: admin-user-token-rlmgnType: kubernetes.io/service-account-tokentoken: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9..(很多字符)#####将这些字符复制到前端登录即可.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django-celery]]></title>
    <url>%2F2018%2F08%2F02%2Fdjango-celery%2F</url>
    <content type="text"><![CDATA[Celery 是一个 基于python开发的分布式异步消息任务队列，通过它可以轻松的实现任务的异步处理.执行发生连接中断,自动尝试重新执行.使用场景:1: 比如对大量器执行一条批量命令，需要长时间等待的情况下2: 大量的定时任务,执行相关脚本,检测信息等. 流程: 任务(异步任务,定时任务) —&gt;消息中间件(broker) —&gt;执行(celery worker)—&gt;存储(backend) 安装pip install celery 即可. 个人环境 123Django==1.11.11celery==3.1.26.post2django-celery==3.2.2 celery 默认使用RabbitMQ为broker.当然使用redis也可以.具体支持哪些可以去官网查看以redis为例,redis安装不赘述,基本开箱即用,活使用docker run 一个.本地还需要安装celery的redis组件pip install -U &quot;celery[redis]&quot; 配置也很简单格式为: redis://:password@hostname:port/db_number 参开如下:12broker = &apos;redis://:123qweASD@localhost:6379/0&apos;backend = &apos;redis://:123qweASD@localhost:6379/0&apos; 无密码格式如下:redis://localhost:6379/0 单脚本使用新建文件就叫tasks.py吧 123456789101112#!/usr/bin/pythonfrom celery import Celerybroker = &apos;redis://:123qweASD@192.168.1.xxx:6379/1&apos;backend = &apos;redis://:123qweASD@192.168.1.xxx:6379/2&apos;app = Celery(&apos;tasks&apos;, broker=broker, backend=backend)@app.taskdef add(x,y): print &quot;running.....&quot;,x,y return x+y 当前目录下执行celery -A tasks worker --loglevel=info此时celery worker运行,终端可看到类似如下信息 123456789......[tasks] . tasks.add[2018-08-02 09:04:26,974: INFO/MainProcess] Connected to redis://:**@192.168.1.244:6379/5[2018-08-02 09:04:26,980: INFO/MainProcess] mingle: searching for neighbors[2018-08-02 09:04:28,000: INFO/MainProcess] mingle: all alone[2018-08-02 09:04:28,019: INFO/MainProcess] celery@zili-test ready. 我们在新开个终端,或者同级目录下新建文件就叫get.py吧 12345678910111213141516171819202122from tasks import addres = add.delay(5,11)# 这里可加上判断# res.ready() # 任务执行返回true,反之false.# res.status #执行状态# 具体的结果方面的方法可在官方查看# http://docs.celeryproject.org/en/latest/reference/celery.result.htmlprint res.get()# 执行可看到返回结果为16[root@zili-test celery]# python test.py 16# 同时,在worker终端可看到如下信息[2018-08-02 09:10:09,805: WARNING/ForkPoolWorker-1] running.....[2018-08-02 09:10:09,805: WARNING/ForkPoolWorker-1] 5[2018-08-02 09:10:09,805: WARNING/ForkPoolWorker-1] 11[2018-08-02 09:10:09,811: INFO/ForkPoolWorker-1] Task tasks.add[34f964fd-afa9-45d8-845e-4b19c7d19b73] succeeded in 0.00624344032258s: 16 项目方式使用项目结构如下: 12345test├── celeryconfig.py├── celery.py├── __init__.py├── tasks.py celeryconfig.pycelery配置文件,具体参考官网1234567891011121314151617# 使用Redis作为消息代理BROKER_URL = &apos;redis://192.168.1.xxx:6379/1&apos; # 把任务结果保存在Redis中CELERY_RESULT_BACKEND = &apos;redis://192.168.1.xxx:6379/2&apos; # 任务序列化和反序列化使用msgpack方案CELERY_TASK_SERIALIZER = &apos;msgpack&apos; # 读取任务结果一般性能要求不高，所以使用了可读性更好的JSONCELERY_RESULT_SERIALIZER = &apos;json&apos; # 任务过期时间，这样写更加明显CELERY_TASK_RESULT_EXPIRES = 60 * 60 * 24 # 指定接受的内容类型CELERY_ACCEPT_CONTENT = [&apos;json&apos;, &apos;msgpack&apos;] celery.py1234567891011121314151617181920#!/usr/bin/pythonfrom __future__ import absolute_import, unicode_literalsfrom celery import Celery#import Celerybroker = &apos;redis://:123qweASD@192.168.1.244:6379/1&apos;backend = &apos;redis://:123qweASD@192.168.1.244:6379/2&apos;app = Celery(&apos;test&apos;, broker=broker, backend=backend, include=[&apos;test.tasks&apos;])# Optional configuration, see the application user guide.app.conf.update( result_expires=3600,)# app.config_from_object(&apos;celery.celeryconfig&apos;) if __name__ == &apos;__main__&apos;: app.start() tasks.py1234567 from __future__ import absolute_importfrom .celery import app @app.taskdef add(x, y): return x+y 启动 celery -A test worker --loglevel=info注意test为项目名,启动命令与项目同级 在项目同级下新建脚本调用即可使用celery,注意同级,不要再项目内调用.否则会报错. 123from test.tasks import addres = add.delay(5,11)print res.get() 定时任务celery支持定时任务,设定好任务的执行时间,celery就会定时自动帮你执行,这个定时任务模块叫celery beat.两种方式 1: 在配置文件中指定 2: 在程序中指定 新建脚本 crontab_task.py 程序中指定 123456789101112131415161718192021from celery import Celeryfrom celery.schedules import crontabbroker = &apos;redis://:123qweASD@192.168.1.244:6379/1&apos;backend = &apos;redis://:123qweASD@192.168.1.244:6379/2&apos;app = Celery(&apos;tasks&apos;, broker=broker, backend=backend)@app.on_after_configure.connectdef set_crontab_task(sender, **kwargs): sender.add_periodic_task(3.0, test.s(&apos;hello&apos;),name=&apos;add every 3s&apos;) sender.add_periodic_task(5.0, test.s(&apos;world&apos;), expires=10) sender.add_periodic_task( crontab(hour=7, minute=30, day_of_week=1), test.s(&apos;Happy Mondays!&apos;), )#编写test函数.定时任务调用@app.taskdef test(args): print args 新建脚本 crontab_task_2.py 配置文件中指定 123456789101112131415161718192021222324from celery import Celeryfrom celery.schedules import crontabbroker = &apos;redis://:123qweASD@192.168.1.244:6379/1&apos;backend = &apos;redis://:123qweASD@192.168.1.244:6379/2&apos;app = Celery(&apos;tasks&apos;, broker=broker, backend=backend)@app.taskdef send(message): print message return messageapp.conf.beat_schedule = &#123; &apos;send-every-10-seconds&apos;: &#123; &apos;task&apos;: &apos;crontab_task2.send&apos;, #&apos;schedule&apos;: 3.0, &apos;schedule&apos;: crontab(minute=&apos;*/1&apos;), &apos;args&apos;: (&apos;Hello World&apos;,) &#125;,&#125;app.conf.timezone = &apos;UTC&apos; crontab 定时配置示例 格式 解释 crontab() 每分钟执行 crontab(minute=0, hour=0) 每天零点 crontab(minute=0, hour=’*/3’) 每三小时执行一次 crontab(minute=’*/15’) 每15分钟执行一次 crontab(day_of_week=’sunday’) 周日开始每分钟执行 crontab(minute=’*/10’,hour=’3,17’,day_of_week=’thu,fri’) 每周四周五的3-4,点17-18点,每十分钟执行一次 crontab(0, 0,day_of_month=’11’,month_of_year=’5’) 每年的五月十一日 1: 在脚本同级目录执行celery -A tasks worker -B 即启动worker和beat服务2: 或者先用celery -A proj worker –loglevel=INFO启动worker再用celery -A tasks beat -s /tmp/celerybeat-schedule 这里的-s /tmp/celerybeat-schedule 指定一个记录文件 测试脚本123from test.tasks import addres = add.delay(5,11)print res.get() 后台启动目前我们所有的操作其实都是在shell中前台运行的.关闭终端worker就结束了.所以我们需要后台的方式来运行程序.目前知道的方法有两个,supervisor和init-script 以init-scritp为例首先去celery官方github 下载相关的启动脚本.一个是异步任务,一个是周期任务的 将celeryd复制到/etc/init.d/celeryd 文件中并赋予可执行的权限然后在 /etc/default/ 文件夹下创建 celeryd 配置文件： 需要更改CELERY_BIN CELERY_APP CELERYD_CHDIR CELERYD_USER CELERYD_GROUP根据实际项目情况更改(用户和组可选择已有的或者新建,注意相关项目权限要给到) 1234567891011121314151617181920212223242526272829303132333435# Names of nodes to start# most people will only start one node:CELERYD_NODES=&quot;worker1&quot;# but you can also start multiple and configure settings# for each in CELERYD_OPTS#CELERYD_NODES=&quot;worker1 worker2 worker3&quot;# alternatively, you can specify the number of nodes to start:#CELERYD_NODES=10# Absolute or relative path to the &apos;celery&apos; command:CELERY_BIN=&quot;/usr/bin/celery&quot;#CELERY_BIN=&quot;/virtualenvs/def/bin/celery&quot;# App instance to use# comment out this line if you don&apos;t use an appCELERY_APP=&quot;test&quot;# or fully qualified:#CELERY_APP=&quot;test.tasks:app&quot;# Where to chdir at start.CELERYD_CHDIR=&quot;/root/celery&quot;# Extra command-line arguments to the workerCELERYD_OPTS=&quot;--time-limit=300 --concurrency=8&quot;# Configure node-specific settings by appending node name to arguments:#CELERYD_OPTS=&quot;--time-limit=300 -c 8 -c:worker2 4 -c:worker3 2 -Ofair:worker1&quot;# Set logging level to DEBUG#CELERYD_LOG_LEVEL=&quot;DEBUG&quot;# %n will be replaced with the first part of the nodename.CELERYD_LOG_FILE=&quot;/var/log/celery/%n%I.log&quot;CELERYD_PID_FILE=&quot;/var/run/celery/%n.pid&quot;# Workers should run as an unprivileged user.# You need to create this user manually (or you can choose# a user/group combination that already exists (e.g., nobody).CELERYD_USER=&quot;root&quot;CELERYD_GROUP=&quot;root&quot;# If enabled pid and log directories will be created if missing,# and owned by the userid/group configured.CELERY_CREATE_DIRS=1 /etc/init.d/celerybeat {start|stop|restart|create-paths|status} 如果要运行周期性的任务: 下载celerybeat 其余同上,可使用同一个配置文件. django中使用(异步)Celery 4.0支持django1.8及以上的版本，低于1.8的项目使用Celery 3.1 安装 django-celery 项目设置修改项目settings.py 123456789101112131415161718import djcelerydjcelery.setup_loader() CELERY_TIMEZONE=&apos;Asia/Shanghai&apos; #与下面TIME_ZONE应该一致BROKER_URL=&apos;redis://:123qweASD@192.168.1.xxx:6379/1&apos; #消息队列CELERY_RESULT_BACKEND = &apos;redis://:123qweASD@192.168.1.xxx:6379/2&apos; #任务结果CELERYBEAT_SCHEDULER = &apos;djcelery.schedulers.DatabaseScheduler&apos; #使用djcelery默认的数据库调度模型,任务执行周期都被存在你指定的orm数据库中CELERY_TASK_SERIALIZER = &apos;json&apos; #任务序列化CELERY_RESULT_SERIALIZER = &apos;json&apos; # 结果序列化CELERY_ACCEPT_CONTENT = [&apos;json&apos;] # 指定接受的内容类型CELERYD_MAX_TASKS_PER_CHILD = 3 # 每个worker最多执行3个任务就会被销毁，可防止内存泄露#CELERY_ENABLE_UTC = FalseINSTALLED_APPS = [ ... &apos;djcelery&apos;, ... ] settings.py同级目录下__init__.py修改 123456from __future__ import absolute_import# This will make sure the app is always imported when# Django starts so that shared_task will use this app.from .celery import app as celery_app__all__ = [&apos;celery_app&apos;] 在项目下新建celery.py 12345678910111213141516171819from __future__ import absolute_importimport osfrom celery import Celeryos.environ.setdefault(&apos;DJANGO_SETTINGS_MODULE&apos;, &apos;zlcelery.settings&apos;) #项目视情况from django.conf import settingsapp = Celery(&apos;zlcelery&apos;) #项目视情况app.config_from_object(&apos;django.conf:settings&apos;)app.autodiscover_tasks(lambda: settings.INSTALLED_APPS)@app.task(bind=True)def debug_task(self): print(&apos;Request: &#123;0!r&#125;&apos;.format(self.request)) #dumps its own request information app设置在需要定时的app下新建tasks.py 12345678910from __future__ import absolute_importfrom celery import shared_taskimport time# 这里写定时的方法即可@shared_taskdef add(x, y): time.sleep(10) return x + y 然后在views.py 就可以调用此方法了. 12345678910111213141516def celery_test(request): x = request.GET[&apos;x&apos;] y = request.GET[&apos;y&apos;] from .tasks import add #调用异步方法 #delay函数实现异步 result = add.delay(x,y) res = &#123;&apos;code&apos;:200, &apos;message&apos;:&apos;ok&apos;, &apos;data&apos;:[&#123;&apos;x&apos;:x, &apos;y&apos;:y&#125;]&#125; #result = add(2,5) #return result return render(request, &apos;zl/return_value.html&apos;, &#123;&apos;return_value&apos;: json.dumps(res)&#125;) #此时请求可直接返回定义的结果.然后继续下下去.而不需要等待执行结果出来再继续了. 同步数据库123python manage.py makemigrationspython manage.py migrate 创建admin1234567python manage.py createsuperuserUsername (leave blank to use &apos;work&apos;): adminEmail address: Password: Password (again): Superuser created successfully. celery -A zlcelery worker -l info -B 启动worker和beat 默认启动后celery不能多进程,所以当有其余进程任务是,不会运行.比如我们用celery调用了ansible.ansible其实并不会执行,返回为空.那么使用这个命令启动,即可. export PYTHONOPTIMIZE=1 &amp;&amp; celery -A zlcelery worker -l info -B 动态增减 参考 export PYTHONOPTIMIZE=1 &amp;&amp; celery -A zlcelery worker --autoreload -l info -B 还有一种方法.未作真实性验证: 2.disable python packet multiprocessing process.py line 102:assert not _current_process._config.get(‘daemon’), \ ‘daemonic processes are not allowed to have children’注释掉python包multiprocessing下面process.py中102行，关闭assert 然后我们访问到ip:port/admin登录即可看到相关的celery定时任务配置前端页面. tasks.py是可以调用其他库的,比如ansible 123456789101112131415from zl.ansible_api.get_sys_info import GetSysInfoL@shared_taskdef get_date(ip,user,pwd): ip = ip user = user pwd = pwd get_res = GetSysInfoL(username=user,password=pwd,ip=ip) res=get_res.get_info() return res# @shared_task 装饰器# ip user pwd等信息是前端页面传来的 格式djcelery规定好的# [&quot;192.168.1.xx&quot;,&quot;root&quot;,&quot;xxxxxxx&quot;] 调用DB相关的定制化,其实就是操作djcelery的数据库.不再从admin页面进入.自己设计页面通过django-celery 的数据库CURD来设置任务计划 12345#导入先关的 模块from djcelery.models import PeriodicTask, CrontabSchedulefrom djcelery.schedulers import ModelEntry, DatabaseSchedulerfrom djcelery import loaders]]></content>
      <categories>
        <category>web</category>
        <category>django</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>celery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-lnmp-java]]></title>
    <url>%2F2018%2F07%2F31%2Fdocker-lnmp-java%2F</url>
    <content type="text"><![CDATA[java 项目,前端nginx. 涉及知识点较多,本文主要写的是容器化的部分.其余的知识点并不会做过多的解释.主要是容器相关的配置文件解释.阅读前提,熟悉linux系统,具有一定docker知识.对compose编排有了解.熟悉zabbix,nginx的编译安装.清楚相关配置参数,依赖等.如果对以上提到的几点有不清楚的,那么不建议阅读. 构建rpm包由于在容器内编译是需要很多组件以及依赖和工具.所以导致生成的容器以及镜像体积非常大. 所以,建议下载相关的源码包,构建完毕后在容器内安装,这样整个包体积就缩小非常多! 当然如果对整个编译依赖非常非常清楚,也可以在容器内编译,然后编译完毕后删除不需要的依赖包以及缓存等. 具体rpm构建方式不赘述了.有兴趣可以点此阅读 ,相关的rpm构建配置文档如下 nginx rpm包构建nginx.spec 文件配置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273Name: nginx Version: 1.12.2 Release: 1%&#123;?dist&#125; Summary: nginx-1.12.2 Group: nginx License: GPLURL: http://blog.dl1548.siteSource0: nginx-1.12.2.tar.gzSource1: nginx.confSource2: fastcgi_paramsSource3: index.phpBuildRequires: openssl,openssl-devel,pcre,pcre-devel #制作rpm包时，所依赖的基本库,很多,并未写完,具体的在dockerfile体现Requires: openssl,openssl-devel,pcre,pcre-devel#BuildRoot: %&#123;_tmpdir&#125;/%&#123;name&#125;-%&#123;version&#125;%description creata by lizili%pre grep nginx /etc/passwd &gt; /dev/nullif [ $? != 0 ] then useradd nginx -M -s /sbin/nologinfi[ -d /usr/local/zabbix ]||rm -rf /usr/local/nginx*%post %preun /usr/local/nginx/sbin/nginx -s stop%postun userdel nginxrm -rf /usr/local/nginx%prep%setup -q #这里就是nginx编译安装的相关配置信息%build ./configure --user=nginx --group=nginx --prefix=/usr/local/%&#123;name&#125; --with-file-aio --with-http_ssl_module \--with-http_realip_module --with-http_addition_module --with-http_xslt_module --with-http_image_filter_module \--with-http_sub_module --with-http_dav_module --with-http_flv_module --with-http_mp4_module --with-http_gunzip_module \--with-http_gzip_static_module --with-http_auth_request_module --with-http_random_index_module --with-http_secure_link_module \--with-http_degradation_module --with-http_stub_status_modulemake -j8 %&#123;?_smp_mflags&#125;%install test -L %&#123;buildroot&#125;/usr/local/%&#123;name&#125; &amp;&amp; rm -f %&#123;buildroot&#125;/usr/local/%&#123;name&#125;make install DESTDIR=%&#123;buildroot&#125;install -p -D -m 0755 %&#123;SOURCE1&#125; %&#123;buildroot&#125;/usr/local/%&#123;name&#125;/conf/nginx.confinstall -p -D -m 0755 %&#123;SOURCE2&#125; %&#123;buildroot&#125;/usr/local/%&#123;name&#125;/conf/fastcgi_paramsinstall -p -D -m 0755 %&#123;SOURCE3&#125; %&#123;buildroot&#125;/usr/local/%&#123;name&#125;/html/index.php%files%defattr (-,root,root,0755) /usr/local/%&#123;name&#125;/*%changelog #主要用于软件的变更日志。该选项可有可无%clean rm -rf %&#123;buildroot&#125; #清理临时文件 zabbix_server rpm包构建zabbxi_server.spec 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273%define zabbix_user zabbix Name: zabbix Version: 3.0.5 Release: 1%&#123;?dist&#125; Summary: zabbix_server Group: zabbix License: GPLURL: http://blog.dl1548.siteSource0: zabbix-3.0.5.tar.gzBuildRequires: unixODBC #制作rpm包时，所依赖的基本库,依赖很多,简单写一个Requires: unixODBC#BuildRoot: %&#123;_tmpdir&#125;/%&#123;name&#125;-%&#123;version&#125;-%&#123;release&#125;%description Zabbix server 3.0.5creata by lizili%pre grep zabbix /etc/passwd &gt; /dev/nullif [ $? != 0 ] then useradd zabbix -M -s /sbin/nologinfi[ -d /usr/local/zabbix ]||rm -rf /usr/local/zabbix*rm -rf /etc/zabbix*%post #修改启动文件路径sed -i &quot;/BASEDIR=\/usr\/local/c\BASEDIR=\/usr\/local\/%&#123;name&#125;&quot; /etc/init.d/zabbix_agentdsed -i &quot;/BASEDIR=\/usr\/local/c\BASEDIR=\/usr\/local\/%&#123;name&#125;&quot; /etc/init.d/zabbix_server%preun /etc/init.d/zabbix_server stop%postun userdel zabbixrm -rf /usr/local/zabbix*%prep%setup -q %build #定义编译软件包时的操作./configure --prefix=/usr/local/%&#123;name&#125; --enable-server --enable-agent --enable-ipv6 --with-mysql --with-net-snmp --with-libcurl --with-openipmi --with-ldap --with-ssh2 --enable-java --with-libxml2make -j8 %&#123;?_smp_mflags&#125;%install test -L %&#123;buildroot&#125;/usr/local/%&#123;name&#125; &amp;&amp; rm -f %&#123;buildroot&#125;/usr/local/%&#123;name&#125;install -d %&#123;buildroot&#125;/etc/profile.dinstall -d %&#123;buildroot&#125;/etc/init.dmake install DESTDIR=%&#123;buildroot&#125;#复制启动脚本cp %&#123;_builddir&#125;/%&#123;name&#125;-%&#123;version&#125;/misc/init.d/fedora/core/zabbix_agentd %&#123;buildroot&#125;/etc/init.d/zabbix_agentdcp %&#123;_builddir&#125;/%&#123;name&#125;-%&#123;version&#125;/misc/init.d/fedora/core/zabbix_server %&#123;buildroot&#125;/etc/init.d/zabbix_server%files%defattr (-,root,root,0755) #定义rpm包安装时创建的相关目录及文件/usr/local/%&#123;name&#125;/*/etc/init.d/zabbix_agentd/etc/init.d/zabbix_server%changelog #主要用于软件的变更日志。该选项可有可无%clean rm -rf %&#123;buildroot&#125; #清理临时文件 事后会得到两个编译好的rpm包. 保存下来,给容器使用. 编排本文使用的docker官网的编排工具docker-compose 编排的前提是,先要创建一个私有网络docker network create -d bridge --subnet 172.1.0.0/16 jk 这样,可以不用映射某些不必要的端口.容器内可直接访问相关的地址. 当然,也可以配置通过映射访问.那么需要更改几个文件. 建议容器内互联,这样,可不用进入容器内更改配置.而且不必要的端口不用曝露出来,增加安全性 编排结构如下 12345678910111213141516171819202122232425262728293031├── docker-compose.yml├── monitor│ └── apache-tomcat-8.5.24.tar.gz│ └── Dockerfile │ └── jdk-8u45-linux-x64.tar.gz│ └── monitor.war├── mysql│ ├── cnf│ │ ├── 3.0.5│ │ │ ├── data.sql│ │ │ ├── images.sql│ │ │ ├── monitor.sql│ │ │ └── schema.sql│ │ ├── init_database.sql│ │ ├── init_db.sh│ │ └── mysqld.cnf│ ├── datadir│ └── Dockerfile├── nginx│ ├── Dockerfile│ ├── nginx-1.12.2-1.el7.centos.x86_64.rpm│ ├── nginx.conf│ └── zabbix│ ├── 3.0.5│ │ ├── logs│ │ │ └── zabbix_server.log│ │ ├── web│ │ │ └── zabbix.conf.php│ │ └── zabbix_server.conf│ └── zabbix-3.0.5-1.el7.centos.x86_64.rpm└── readme monitor 此文件夹下是monitor项目的Dockerfile需要的文件以及配置 mysql 此文件夹下是mysql项目的Dockerfile需要的文件以及配置 nginx 此文件夹下是nginx项目的Dockerfile需要的文件以及配置(包括zabbix) docker-compose.yml 是编排文件,通过它来构建整个monitor的容器化 monitor此文件夹下的先关配置用来构建公司monitor项目. Dockerfile如下: 1234567891011121314FROM centosADD jdk-8u45-linux-x64.tar.gz /usr/localENV RUN_AS_USER=rootENV JAVA_HOME /usr/local/jdk1.8.0_45ENV CLASS_HOME=/usr/local/jdk1.8.0_45/lib:$JAVA_HOME/jre/libENV CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib:$CLASSPATHENV PATH=$PATH:$JAVA_HOME/binADD apache-tomcat-8.5.24.tar.gz /usr/localEXPOSE 8080ENTRYPOINT [&quot;/usr/local/apache-tomcat-8.5.24/bin/catalina.sh&quot;, &quot;run&quot;] mysqlcnf文件夹 数据库相关配置文件.数据库配置就是mysqld.cnf Dockerfile 将此文件进行映射并赋权. 这样在生成镜像的时候,相关的数据库配置就能生效了.不用去容器内修改.注意权限! 3.0.5 针对的是zabbix版本,存放的也是zabbix需要预先生成并导入的表. init_database.sql 初始化数据的文件 12CREATE DATABASE IF NOT EXISTS zabbix default charset utf8 COLLATE utf8_general_ci;CREATE DATABASE IF NOT EXISTS monitor default charset utf8 COLLATE utf8_general_ci; init_db.sh 初始化数据库的脚本 12345678910111213141516#init dbmysql -uroot -p$MYSQL_ROOT_PASSWORD &lt;&lt; EOFsource $WORK_PATH/$FILE_0;EOF# init zbxmysql -uroot -p$MYSQL_ROOT_PASSWORD zabbix &lt;&lt; EOFsource $WORK_PATH/$FILE_1;source $WORK_PATH/$FILE_2;source $WORK_PATH/$FILE_3;EOF#init monitormysql -uroot -p$MYSQL_ROOT_PASSWORD monitor &lt;&lt; EOFsource $WORK_PATH/$FILE_4;EOF datadir 用来做数据持久化使用 Dockerfile如下: 1234567891011121314151617181920212223242526272829303132333435FROM mysql:5.7.21MAINTAINER lizili(blog.dl1548.site)ENV WORK_PATH /usr/local/work#此目录下的脚本在生成容器是会自动执行.用来做初始化使用ENV AUTO_RUN_DIR /docker-entrypoint-initdb.d#定义sql文件名ENV FILE_0 init_database.sql ENV FILE_1 schema.sqlENV FILE_2 images.sqlENV FILE_3 data.sqlENV FILE_4 monitor.sql#定义shell文件名ENV INSTALL_DB_SHELL init_db.sh#把数据库初始化数据的文件复制到工作目录下COPY cnf/$FILE_0 $WORK_PATH/COPY cnf/3.0.5/$FILE_1 $WORK_PATH/COPY cnf/3.0.5/$FILE_2 $WORK_PATH/COPY cnf/3.0.5/$FILE_3 $WORK_PATH/COPY cnf/3.0.5/$FILE_4 $WORK_PATH/#把要执行的shell文件放到/docker-entrypoint-initdb.d/目录下，容器会自动执行这个shellCOPY cnf/$INSTALL_DB_SHELL $AUTO_RUN_DIR/#mysql配置文件COPY cnf/mysqld.cnf /etc/mysql/mysql.conf.d/mysqld.cnf#给执行文件增加可执行权限.权限一定要更改.否则配置不生效.这个权限困扰我一段时间..有点坑.RUN mkdir -p $WORK_PATH \ &amp;&amp; chown mysql:mysql /etc/mysql/mysql.conf.d/mysqld.cnf \ &amp;&amp; chmod 600 /etc/mysql/mysql.conf.d/mysqld.cnf \ &amp;&amp; chmod a+x $AUTO_RUN_DIR/$INSTALL_DB_SHELL nginxnginx-1.12.2-1.el7.centos.x86_64.rpm 前面构建的rpm安装包. nginx.conf nginx配置文件,需要注意这里的nginx路径是由构建rpm是决定的. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586#user nobody;worker_processes auto;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; use epoll; worker_connections 51200; multi_accept on;&#125;http &#123; include mime.types; default_type application/octet-stream; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #access_log logs/access.log main; sendfile on; client_max_body_size 500m; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 256k; gzip on; gzip_min_length 1k; gzip_buffers 4 16k; gzip_http_version 1.1; gzip_comp_level 2; gzip_types text/plain application/javascript application/x-javascript text/javascript text/css application/xml application/xml+rss; gzip_vary on; gzip_proxied expired no-cache no-store private auth; gzip_disable &quot;MSIE [1-6]\.&quot;; server &#123; listen 80; server_name localhost; index index.html index.htm index.php; root /usr/local/nginx/html; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; location ~ [^/]\.php(/|$) &#123; #try_files $uri =404; root /usr/local/nginx/html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; #fastcgi_param SCRIPT_FILENAME /usr/local/nginx/html/$fastcgi_script_name; include fastcgi_params; &#125; location ~ .*\.(gif|jpg|jpeg|png|bmp|swf)$ &#123; expires 30d; &#125; location ~ .*\.(js|css)?$ &#123; expires 12h; &#125; location ~ /\. &#123; deny all; &#125; access_log logs/php_access.log; error_log logs/php_error.log notice; &#125;&#125; zabbix 此文件夹是用来搭建监控服务. 3.0.5 是为了zabbix版本分类使用 web 存放的是zabbix官方提供的监控前端php等文件. zabbix.conf.php zabbix前端的配置文件.主要是指定连接的数据库地址,以及监控server地址 此文件可直接在官网提供的前端文件中,复制,重命名,然后更改. 注意我指定的数据库地址,就是容器内地址,可不通过端口映射访问,一定程度上讲,访问速度也有所提升. 123456789101112131415161718&lt;?php// Zabbix GUI configuration file.global $DB;$DB[&apos;TYPE&apos;] = &apos;MYSQL&apos;;$DB[&apos;SERVER&apos;] = &apos;172.1.0.33&apos;;$DB[&apos;PORT&apos;] = &apos;3306&apos;;$DB[&apos;DATABASE&apos;] = &apos;zabbix&apos;;$DB[&apos;USER&apos;] = &apos;root&apos;;$DB[&apos;PASSWORD&apos;] = &apos;123qweASD&apos;;// Schema name. Used for IBM DB2 and PostgreSQL.$DB[&apos;SCHEMA&apos;] = &apos;&apos;;$ZBX_SERVER = &apos;192.168.1.244&apos;;$ZBX_SERVER_PORT = &apos;10051&apos;;$ZBX_SERVER_NAME = &apos;&apos;;$IMAGE_FORMAT_DEFAULT = IMAGE_FORMAT_PNG; zabbix_server.conf zabbix_server服务配置. 这个文件主要是要指定数据库为远程数据库.以及配置相关库和账户密码等 主要更改的几个点 1234DBHost=172.1.0.33 #这里指定的也是容器内的地址.如果是端口映射,那么指定os地址.DBName=zabbixDBUser=rootDBPassword=123qweASD zabbix-3.0.5-1.el7.centos.x86_64.rpm 前面构建的rpm安装包. Dockerfile 配置如下: 这个dockerfile是最复杂的,安装了nginx,zabbix,php-fpm的运行环境以及依赖. 安装了容器中文语言环境支持,用来支持zabbix的中文语言环境(需要做相关配置.具体公司操作文档有.可直接在web内的前端文件修改,docker会自动映射到容器内部),修改了一下配置文件,使zabbix可正常运行. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546FROM centosMAINTAINER zili.li(blog.dl1548.site)COPY nginx-1.12.2-1.el7.centos.x86_64.rpm /tmp/nginx-1.12.2-1.el7.centos.x86_64.rpmCOPY zabbix/zabbix-3.0.5-1.el7.centos.x86_64.rpm /tmp/zabbix-3.0.5-1.el7.centos.x86_64.rpm#zabbix rpmWORKDIR /tmp#install serverRUN nginxDeps=&apos;glib* autoconf openssl openssl-devel libxslt-devel gd gd-devel pcre pcre-devel &apos; \ &amp;&amp; phpDeps=&apos;php php-mysql php-common php-fpm php-gd php-ldap \ php-odbc php-pear php-xml php-mcrypt php-xmlrpc php-devel \ php-mbstring php-snmp php-soap curl curl-devel php-bcmath mod_ssl&apos; \ &amp;&amp; zbxDeps=&apos;fping mysql-connector-odbc mysql-devel libdbi-dbd-mysql \ libssh2 libxml2 libxml2-devel libssh2-devel unixODBC unixODBC-devel \ pam-devel net-snmp-devel net-snmp-utils OpenIPMI OpenIPMI-devel rpm-build \ openldap openldap-devel libcurl-devel java java-devel&apos; \ &amp;&amp; useradd -M -s /sbin/nologin nginx \ &amp;&amp; useradd -M -s /sbin/nologin php \ &amp;&amp; yum -y install epel-release \ &amp;&amp; yum clean all \ &amp;&amp; yum -y install $nginxDeps $phpDeps $zbxDeps kde-l10n-Chinese \ &amp;&amp; rpm -ivh nginx-1.12.2-1.el7.centos.x86_64.rpm \ &amp;&amp; rpm -ivh zabbix-3.0.5-1.el7.centos.x86_64.rpm \ &amp;&amp; rm -rf /tmp/* \ &amp;&amp; rm -rf /var/cache/* \ &amp;&amp; sed -i &apos;s/upload_max_filesize = 2M/upload_max_filesize = 50M/g&apos; /etc/php.ini \ &amp;&amp; sed -i &apos;s/;date.timezone =/date.timezone =PRC/&apos; /etc/php.ini \ &amp;&amp; sed -i &apos;s/max_execution_time = 30/max_execution_time = 600/g&apos; /etc/php.ini \ &amp;&amp; sed -i &apos;s/max_input_time = 60/max_input_time = 600/g&apos; /etc/php.ini \ &amp;&amp; sed -i &apos;s/memory_limit = 128M/memory_limit = 256M/g&apos; /etc/php.ini \ &amp;&amp; sed -i &apos;s/post_max_size = 8M/post_max_size = 16M/g&apos; /etc/php.ini \ &amp;&amp; rm -rf /etc/localtime &amp;&amp; ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \ &amp;&amp; localedef -c -f UTF-8 -i zh_CN zh_CN.utf8#ENV TIME_ZONE Asia/ShanghaiENV PATH /usr/local/nginx/sbin:$PATH ENV LC_ALL zh_CN.utf8EXPOSE 80#ENTRYPOINT [&quot;nginx&quot;]CMD /usr/local/nginx/sbin/nginx &amp;&amp; /etc/init.d/zabbix_server start &amp;&amp; /etc/init.d/zabbix_agentd start &amp;&amp; /usr/sbin/php-fpm docker-compose.yml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354version: &quot;3&quot;services: backserver: hostname: MonitorBack build: ./nginx volumes: - ./nginx/nginx.conf:/usr/local/nginx/conf/nginx.conf:rw - ./nginx/zabbix/3.0.5/web/:/usr/local/nginx/html/monitor:rw - ./nginx/zabbix/3.0.5/zabbix_server.conf:/usr/local/zabbix/etc/zabbix_server.conf:rw ports: - 80:80 - 10050:10050 - 10051:10051 networks: jk: ipv4_address: 172.1.0.80 restart: always depends_on: - dbserver - webserver webserver: hostname: JKMonitor build: ./monitor restart: always volumes: - ./monitor/monitor.war:/usr/local/apache-tomcat-8.5.24/webapps/monitor.war ports: - 8080:8080 networks: jk: ipv4_address: 172.1.0.88 depends_on: - dbserver dbserver: hostname: MonitorDB build: ./mysql volumes: #- ./my.cnf:/etc/my.cnf.d/zili.cnf:rw #在dockerfile中配置并赋权 - ./mysql/datadir:/var/lib/mysql:rw #ports: # - 3306:3306 networks: jk: ipv4_address: 172.1.0.33 restart: always environment: MYSQL_ROOT_PASSWORD: &apos;123qweASD&apos; MYSQL_ROOT_HOST: &apos;%&apos;networks: jk: external: true 进入jk下 执行docker-compose up --build 即可,后台加-d 完.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[uWSGI+Nginx部署Django项目]]></title>
    <url>%2F2018%2F06%2F22%2FuWSGI-Nginx%E9%83%A8%E7%BD%B2Django%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[nginx + uwsgi socket 的方式来部署 Django请求流程:the web client &lt;-&gt; the web server &lt;-&gt; the socket &lt;-&gt; uwsgi &lt;-&gt; Djangonginx是可选的. 安装yum install python-devel如果没有,先安装 epel-release.或下载源码安装. 安装 nginx123具体参数,按需添加./configure --prefix=/usr/local/nginx/ --with-http_v2_module --with-http_ssl_module --with-http_sub_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre 安装 pip install uwsgi --upgrade uwsgiuWSGI是一个Web服务器，它实现了WSGI协议、uwsgi、http等协议。uWSGI支持许多不同的语言，因此也支持许多Web应用程序,Nginx中HttpUwsgiModule的作用是与uWSGI服务器进行交换. 测试uWSGI是否能正常运行新建文件uwsgi_test.py1234def application(env, start_response): start_response(&apos;200 OK&apos;,[(&apos;Content-Type&apos;, &apos;text/html&apos;)]) return [&apos;Hello world&apos;] # Python2 #return [b&apos;Hello world&apos;] # Python3 在文件目录下执行uwsgi --http 0.0.0.0:8001 --wsgi-file uwsgi_test.py使用浏览器访问 ip:8001返回hello world 即表示,uwsgi是可运行的 使用uWSGI运行django项目 uwsgi --http 0.0.0.0:8001 --chdir /path/to/project --home=/path/to/env --module project.wsgi --master --processes 4 --threads 2 –home 指定virtualenv 路径，如果没有可以去掉project.wsgi 指的是 project/wsgi.py 文件(比如项目叫test,那就是test.wsgi)或者直接指定入口文件 uwsgi --http 0.0.0.0:8001 --chdir /path/to/project --wsgi-file project/wsgi.py --master --processes 4 --threads 2 执行这个命令会产生4个uwsgi进程（每个进程2个线程），1个master进程，当有子进程死掉时再产生子进程，1个 the HTTP router进程，共6 个进程。这个Http route进程的地位有点类似nginx，(可以认为与nginx同一层)负责路由http请求给worker, Http route进程和worker之间使用的是uwsgi协议 访问ip:8001 可正常访问,表明项目已通过uwsgi启动成功 编写uwsgi配置文件参数过多,可以通过ini配置文件来解决. 通过配置文件启动django项目,此配置是,通过uwsgi来启动django项目 uwsgi django.ini 123456789101112131415161718192021222324[uwsgi]#绑定地址http=0.0.0.0:8001#项目路径,不是应用路径chdir=/opt/cmdb#后台启动,输出log#daemonize=/var/log/uwsgi.log master=true#processes=4#threads=2#并发处理进程work=20 # 并发的socket 连接数。默认为100,具体视情况listen=2048 # 和系统配置有关,系统配置见后socket-timeout=60die-on-term = truemodule=cmdb.wsgi#指定pid和status路径,目录需新建stats=%(chdir)/uwsgi/uwsgi.statuspidfile=%(chdir)/uwsgi/uwsgi.pid 其他建议通过配置文件,我们开启了多进程,多并发连接.但是这些还受限于其他的配置.比如nginx 和系统自身 系统配置vim /etc/sysctl.conf 添加如下net.core.somaxconn = 2048net.core.somaxconn是Linux中的一个kernel参数，表示socket监听（listen）的backlog上限backlog就是socket的监听队列，当一个请求（request）尚未被处理或建立时，他会进入backlog。而socket server可以一次性处理backlog中的所有请求，处理后的请求不再位于监听队列中。当server处理请求较慢，以至于监听队列被填满后，新来的请求会被拒绝。默认 128 vim /etc/security/limits.conf 123456789101112* soft nofile 65535* hard nofile 65535#“*”表示所有用户都生效soft（应用软件）级别限制的最大可打开文件数的限制hard表示操作系统级别限制的最大可打开文件数的限制重启成效或者 ulimit -n 65535 临时性生效 nginx 配置 123456789worker_processes xx; #可以设置成cpu个数，或者autoworker_rlimit_nofile 65535; #worker进程打开最大连接数 和系统配置有关events &#123; use epoll; worker_connections 9000; # 不可超过worker_rlimit_nofile multi_accept on; #告诉nginx收到一个新连接通知后接受尽可能多的连接&#125; uwsgi --ini uwsgin.ini 启动uwsgi --reload uwsgi/uwsgi.pid 重启uwsgi --stop uwsgi/uwsgi.pid 停止uwsgi --connect-and-read uwsgi/uwsgi.status 查看状态 1234567891011121314151617181920212223242526272829常用选项：http ： 协议类型和端口号processes ： 开启的进程数量workers ： 开启的进程数量，等同于processes（官网的说法是spawn the specified number of workers / processes）chdir ： 指定运行目录（chdir to specified directory before apps loading）wsgi-file ： 载入wsgi-file（load .wsgi file）stats ： 在指定的地址上，开启状态服务（enable the stats server on the specified address）threads ： 运行线程。由于GIL的存在，觉得这个真心没啥用。（run each worker in prethreaded mode with the specified number of threads）master ： 允许主进程存在（enable master process）daemonize ： 使进程在后台运行，并将日志打到指定的日志文件或者udp服务器（daemonize uWSGI）。实际上最常用的，还是把运行记录输出到一个本地文件上。pidfile ： 指定pid文件的位置，记录主进程的pid号。vacuum ： 当服务器退出的时候自动清理环境，删除unix socket文件和pid文件（try to remove all of the generated file/sockets）max-requests=500 #为每个工作进程设置请求数的上限。当一个工作进程处理的请求数达到这个值，那么该工作进程就会被回收重用（重启）。你可以使用这个选项来默默地对抗内存泄漏daemonize : 日志socket-timeout #为所有的socket操作设置内部超时时间（默认4秒）。 至此,项目已经可正常运行.下面要做的是与nginx结合. nginx+uwsgi+django通过sock文件或者http都是可以的.不同方式,nginx配置有所改变. tuoch uwsgi_http.ini 1234567891011121314151617181920212223242526272829303132333435[uwsgi]#这里不要使用http了,否则访问nginx会出现502.socket=0.0.0.0:18001chdir = /opt/cmdbwsgi-file = cmdb/wsgi.pydaemonize = /opt/cmdb/uwsgi/cmdb.logtouch-reload = /opt/cmdb/uwsgi/reload#processes = 2#threads = 4workers=20listen=2048stats=%(chdir)/uwsgi/uwsgi.statuspidfile=%(chdir)/uwsgi/uwsgi.pidsocket-timeout=60die-on-term=true-------------------建议使用此配置.将ini文件当到项目下,与manage.py同级[uwsgi]socket=0.0.0.0:18001chdir=%d#virtualenv=%d../venv/module=cmdb.wsgi:applicationmaster=Truepidfile=%(chdir)/uwsgi/uwsgi.pidtouch-reload=%(chdir)/uwsgi/reloadenable-threads=Truevacuum=Truemax-requests=500daemonize=%(chdir)/uwsgi/cmdb.logprocesses=%kthreads=2buffer-size=32768#socket-timeout=60 touch-reload是指,reload文件被修改就重新加载进程.项目下新建reload文件,只要touch下这个文件（touch reload) 项目就会重启 nginx配置新建nginx配置文件比如.cmdb.conf 1234567891011121314151617181920212223242526272829303132333435server &#123; listen 8008; server_name cmdb; charset utf-8; client_max_body_size 75M; proxy_connect_timeout 300; proxy_read_timeout 300; proxy_send_timeout 300; proxy_buffer_size 64k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; error_log logs/cmdb_error.log; access_log logs/cmdb_access.log; location /media &#123; alias /opt/cmdb/media; &#125; location /static &#123; alias /opt/cmdb/static; &#125; location / &#123; #uwsgi_pass的意思动态内容请求都通过名为django的upstream传递给uWSGI uwsgi_pass 0.0.0.0:8001; uwsgi_send_timeout 600; # 指定向uWSGI传送请求的超时时间，完成握手后向uWSGI传送请求的超时时间。 uwsgi_connect_timeout 600; # 指定连接到后端uWSGI的超时时间。 uwsgi_read_timeout 600; # 指定接收uWSGI应答的超时时间，完成握手后接收uWSGI应答的超时时间。 #uwsgi_params文件是Nginx向uWSGI传递的参数 include /usr/local/nginx-1.12.2/conf/uwsgi_params; &#125;&#125; 服务自启nginx自启centos6vim /etc/init.d/nginx 参考官网Red Hat NGINX Init Script修改的地方:nginx=”/usr/local/nginx-1.12.2/sbin/nginx” #修改成nginx执行程序的路径。NGINX_CONF_FILE=”/usr/local/nginx-1.12.2/conf/nginx.conf” #修改成nginx.conf文件的路径。 chmod a+x /etc/init.d/nginxchkconfig –add /etc/init.d/nginxchkconfig nginx on centos7vi /lib/systemd/system/nginx.service 12345678910111213[Unit]Description=nginxAfter=network.target [Service]Type=forkingExecStart=/usr/local/nginx-1.12.2/sbin/nginxExecReload=/usr/local/nginx-1.12.2/sbin/nginx -s reloadExecStop=/usr/local/nginx-1.12.2/sbin/nginx -s quitPrivateTmp=true [Install]WantedBy=multi-user.target systemctl enable nginx.service uwsgi自启chmod +x /etc/rc.d/rc.local追加内容如下:(路径根据实际情况设置)cd /opt/cmdb/uwsgi &amp;&amp; /usr/bin/uwsgi --ini uwsgi_http.ini 需要注意的是,ini的配置要设置下后台daemonize = /opt/cmdb/uwsgi/uwsgi_http.log` 看起来是完美了.重启的时候会发现,界面一直卡着…1[ *] A stop job is running for /etc/rc.d...........Compatibility 是因为没有配置rc-local.service 导致 vim /etc/systemd/system/rc-local.service 12345678910111213141516171819# This file is part of systemd.## systemd is free software; you can redistribute it and/or modify it# under the terms of the GNU Lesser General Public License as published by# the Free Software Foundation; either version 2.1 of the License, or# (at your option) any later version.# This unit gets pulled automatically into multi-user.target by# systemd-rc-local-generator if /etc/rc.d/rc.local is executable.[Unit]Description=/etc/rc.d/rc.local CompatibilityConditionFileIsExecutable=/etc/rc.d/rc.localAfter=network.target[Service]Type=forkingExecStart=/etc/rc.d/rc.local startTimeoutSec=5RemainAfterExit=yes systemctl daemon-reload #重新加载systemctlsystemctl enable rc-local #开机自启]]></content>
      <categories>
        <category>web</category>
        <category>django</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker学习]]></title>
    <url>%2F2018%2F05%2F15%2Fdocker%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[docker Docker三个基本概念 镜像（image） 容器（container） 仓库（rrepository) 安装不同系统安装方式不同，详见以centos为例(仅支持64位kernel &gt;=3.10)建议使用国内源卸载原有版本yum remove docker docker-common docker-selinux docker-engineyum-util 提供yum-config-manager功能，另外两个是devicemapper驱动依赖yum install -y yum-utils device-mapper-persistent-data lvm2添加yum源1234#中科大sudo yum-config-manager --add-repo https://mirrors.ustc.edu.cn/docker-ce/linux/centos/docker-ce.repo# 官方源# sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 查看版本yum list docker-ce --showduplicates | sort -r可选择版本进行安装。默认仓库只开放稳定版12sudo yum install docker-ce #默认安装最新稳定版sudo yum install docker-ce-17.12.0.ce #安装指定版本 然后启动并开机启动，docker version即可查看版本 创建用户组为了安全起见，docker只允许root和docker用户组的用户进行访问groupadd dockerusermod -G docker username 镜像加速若文件不存在,则手动创建vim /etc/docker/daemon.json12345678#docker国内镜像加速应该是挂了&#123; &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;]&#125;#阿里云镜像加速登陆[阿里云](https://cr.console.aliyun.com),获取专属加速地址类似 https://xxxx.mirror.aliyuncs.com 替换上面的地址 systemctl daemon-reloadsystemctl restart docker image获取镜像docker pull [选项] [ 仓库地址] 仓库名/标签 默认从docker hub 中拉取例如 ： docker pull centos #默认就是从docker hub下载最新的如果需要下载制定tag的，可去官网查询docker search xxxx 不显示tagdocker pull centos:7.4.1708 下载指定版本 docker images -a 列出镜像 (显示包括中间层镜像)中间层镜像：是其他镜像所依赖的镜像，不能删除，否则会导致上层镜像因为依赖丢失报错，事实上也无需删除，相同的层只会存储一遍。 docker system df 查看镜像,容器,数据卷占用空间 docker images -f since(或before)=image name 列出某个image之前(之后)的镜像 docker image prune删除虚悬镜像(dangling) 虚悬镜像：也就是新旧镜像重名而导致的，pull和build都可能会出现这种情况，docker image ls -f dangling=true可 查看，虚悬镜像都是无价值的，可删除 docker rmi $(docker images -q -f dangling=true) 批量删除dangling docker run --name webserver -d -p 80:80 nginx 以nginx镜像为基础，运行容器，也就是新建个容器 构建镜像Dockerfile123456$ mkdir mynginx$ cd mynginx$ touch Dockerfilecat DockerfileFROM nginxRUN echo &apos;&lt;h1&gt;Dockerfile&lt;/h1&gt;&apos; &gt; &gt; /usr/share/nginx/html/index.html FROM image必写,定制镜像也是以镜像为基础的.这里就是选定一个基础镜像,可以以相关服务镜像为基础(nginx,mysql等),也可是是系统(ubuntu,centos等).另外,dicker还提供FROM scratch 意味不以任何镜像为基础. RUNshell格式 : 用来执行命令行命令.exec格式: RUN [&quot;可执行文件&quot;,&quot;参数1&quot;, &quot;参数2&quot;]这像是函数调用RUN命令常用来安装软件包 构建docker build [选项] &lt;上下文路径/URL/-&gt;在文件目录下执行docker build -t nginx:v3 .12345678910[root@docker docker]# docker build -t nginx:v3 .Sending build context to Docker daemon 2.048kBStep 1/2 : FROM nginx ---&gt; b8efb18f159bStep 2/2 : RUN echo &apos;&lt;h1&gt; Dockerfile!&lt;/h1&gt;&apos; &gt;&gt; /usr/share/nginx/html/index.html ---&gt; Running in 8b921720af4c ---&gt; 2cd0174a0aeaRemoving intermediate container 8b921720af4cSuccessfully built 2cd0174a0aeaSuccessfully tagged nginx:v3 实例解析12345678FROM debian:jessieRUN apt-get updateRUN apt-get install -y gcc libc6-dev makeRUN wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-3.2.5.tar.gz&quot;RUN mkdir -p /usr/src/redisRUN tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1RUN make -C /usr/src/redisRUN make -C /usr/src/redis install Dockerfile中一个RUN指令,就会建立一层.就和cimmit类似,一层层的叠加然后生成新的image.这样没有意义,很多无用的东西都装进了image.编译环境,软件包等.而且UnionFS是有层数限制的的.所以,正确的写法应该是这样12345678910111213FROM debian:jessieRUN buildDeps=&apos;gcc libc6-dev make&apos; \ &amp;&amp; apt-get update \ &amp;&amp; apt-get install -y $buildDeps \ &amp;&amp; wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-3.2.5.tar.gz&quot; \ &amp;&amp; mkdir -p /usr/src/redis \ &amp;&amp; tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 \ &amp;&amp; make -C /usr/src/redis \ &amp;&amp; make -C /usr/src/redis install \ &amp;&amp; rm -rf /var/lib/apt/lists/* \ &amp;&amp; rm redis.tar.gz \ &amp;&amp; rm -r /usr/src/redis \ &amp;&amp; apt-get purge -y --auto-remove $buildDeps 一层一个目的,而不是一层一条命令,我们是在构建image并不是在写shell脚本.并且要记得做相关清理工作. build中的点.docker build 命令最后有个点.,它表示当前目录,而Dockerfile就在当前目录.所以会让人认为点.指的就是Dockerfile的路径,其实是不准确的.如果对照bulid格式,会发现,这里的点其实指的是上下文.理解上下文要理解下docker工作原理,docker运行时,分为server和client.我们其实是使用client控制docker服务端,所有的操作其实是服务端完成的.也就是C/S结构.所以我们构建image的时候,可以使用ADD.COPY等指令,将本地文件复制进镜像.构建是在服务端.服务端如何获取本地文件呢?这里就用到了上下文.用户指定了上下文路径,build的时候就会将路径下的内容打包.然后上传到Docker server.当Docker server收到后展开就能获得所需的一切文件比如COPY ./package.json /app这并不是要复制执行docker build命令所在的目录下的package.json ,也不是复制Dockerfile所在目录下的package.json而是复制上下文(context)目录下的package.json所以,这里的路径是相对的, COPY ../package.json /app或者COPY /opt/xxxx /app 其实都已经超出了上下文的范围.那当我们需要context范围外的文件怎么办?很简单,先把文件cp到上下文目录中.默认情况下,Dockerfile会将上下文目录下的Dockerfile文件作为Dockerfile.所以很多人会误认为 .就是指Dockerfile所在目录通常习惯上我们也不会去更改. Dockerfile其他指令COPY12COPY &lt;源路径&gt;... &lt;目标路径&gt; COPY [&quot;&lt;源路径1&gt;&quot;,... &quot;&lt;目标路径&gt;&quot;] 源路径可以指定多个,也可以是还是用通配符.此COPY 自带 -p.会保留源文件的属性. ADD基本和COPY是一致的.但是他俩的使用建议遵守一个原则文件复制使用COPY,需要解压缩使用ADD CMD此命令类似RUN 支持两种格式 shell 和 execshell 格式: CMD &lt;命令&gt;exec格式: CMD [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;...]参数列表格式: CMD[&quot;参数1&quot;, &quot;参数2&quot;...]在指定了 ENTRYPOINT 指令后,用 CMD指定具体的参数。 Docker不是虚拟机,容器是进程.所以容器的启动需要指定运行程序和参数.CMD 就是用于指定默认容易主进程的启动命令或者这样理解,CMD 执行的是默认容器启动后执行的命令以及参数.一般只允许使用一次CMD,常用于文件最后 命令格式上推荐使用exec , 默认情况下 shell 是会被封装成为sh -c如:CMD echo $HOME –&gt; CMD [&quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot;]注意! exec格式 一定要用双引号!因为在解析时会被解析成json docker不是虚拟机,容器的应用也应该是以前台执行的,容器不存在后台的概念.不能以虚拟机的方式去执行后台服务等所以 CMD service nginx start肯定是错误的.会转换为 CMD [&quot;sh&quot;, &quot;-c&quot;, &quot;service nginx start&quot;] 显而易见,主进程是sh,所以这种格式的命令,会导致容器退出.正确的方式 是CMD [&quot;nginx&quot;,&quot;-g&quot;,&quot;daemon off&quot;] ENTRYPOINT同样支持两种格式: exec 和shell 当指定了ENTRYPOINT后CMD的含义就发生了变化,它不在直接运行命令,而是将内容传送给ENTYRPOINT运行同CMD,一个文件只写一次. ENV环境变量ENV KEY VALUE ENV KEY=VALUE 两种方式都可以下列指令可以支持环境变量展开：ADD、COPY、ENV、EXPOSE、LABEL、USER、WORKDIR、VOLUME、STOPSIGNAL、ONBUILD例:(node官方)123456789ENV NODE_VERSION 7.2.0RUN curl -SLO &quot;https://nodejs.org/dist/v$NODE_VERSION/node-v$NODE_VERSION-linux-x64.tar.xz&quot; \ &amp;&amp; curl -SLO &quot;https://nodejs.org/dist/v$NODE_VERSION/SHASUMS256.txt.asc&quot; \ &amp;&amp; gpg --batch --decrypt --output SHASUMS256.txt SHASUMS256.txt.asc \ &amp;&amp; grep &quot; node-v$NODE_VERSION-linux-x64.tar.xz\$&quot; SHASUMS256.txt | sha256sum -c - \ &amp;&amp; tar -xJf &quot;node-v$NODE_VERSION-linux-x64.tar.xz&quot; -C /usr/local --strip-components=1 \ &amp;&amp; rm &quot;node-v$NODE_VERSION-linux-x64.tar.xz&quot; SHASUMS256.txt.asc SHASUMS256.txt \ &amp;&amp; ln -s /usr/local/bin/node /usr/local/bin/nodejs ARG变量ARG key ARG key=valueARG指令定义的参数，在docker build命令中以–build-arg key=value形式赋值。ARG变量不像ENV变量始终存在于镜像中。不过ARG变量会以类似的方式对构建缓存产生影响。如果Dockerfile中定义的ARG变量的值与之前定义的变量值不一样，那么就有可能产生“cache miss”。比如RUN指令使用ARG定义的变量时，ARG变量的值变了之后，就会导致缓存失效。 VOLUMEVOLUME path VOLUME [&quot;path1&quot;,&quot;path2&quot;]容器运行,尽量让存储层不发生写操作,通常数据都存放在卷中,此命令可实现指定挂载某目录,以防用户忘记将动态文件目录挂载为卷.这样可以保证容器的正常运行,并且不会向存储写数据 EXPOSEEXPOSE 80EXPOSE 22声明运行容器时提供服务端口,单单只是声明,并不会真的去开启这个端口.当使用docker run -P时,会自动随机映射EXPOSE的端口 WORKDIR指定工作目录WORKDIR dir用来指定工作目录,WORKDIR类似命令cd。WORKDIR参数后可以是相对路径或者带/的绝对路径，使用相对路径就依据上一个WORKDIR参数决定下面的Dockerfile工作目录。可以重复定义，以切换Dockerfile的工作目录。 12RUN cd /appRUN echo &quot;hello&quot; &gt; world.txt 两个RUN 其实是运行了两个容器.第一个RUN并不会对第二个产生任何影响.所以第二个将会找不到路径,此时就需要设置工作目录 WORKDIR /app ONBUILD该命令实际上是个触发器,其参数是任意一个Dockerfile 指令ONBUILD RUN mkdir /testdir当我们在一个Dockerfile文件中加上ONBUILD指令，该指令对利用该Dockerfile构建镜像（比如为A镜像）不会产生实质性影响。但是当我们编写一个新的Dockerfile文件来基于A镜像构建一个镜像（比如为B镜像）时，这时构造A镜像的Dockerfile文件中的ONBUILD指令就生效了. USERUSER usernameUSER会改变以后命令的执行用户.或者说,他就是切换用户的.前提,用户是存在的,否则失败. 如果以 root 执行的脚本，在执行期间希望改变身份，比如希望以某个已经建立好的用户来运行某个服务进程不要使用 su 或者 sudo，这些都需要比较麻烦的配置，而且在 TTY 缺失的环境下经常出错。建议使用 gosu。12345678# 建立 redis 用户，并使用 gosu 换另一个用户执行命令RUN groupadd -r redis &amp;&amp; useradd -r -g redis redis# 下载 gosuRUN wget -O /usr/local/bin/gosu &quot;https://github.com/tianon/gosu/releases/download/1.7/gosu-amd64&quot; \ &amp;&amp; chmod +x /usr/local/bin/gosu \ &amp;&amp; gosu nobody true# 设置 CMD，并以另外的用户执行CMD [ &quot;exec&quot;, &quot;gosu&quot;, &quot;redis&quot;, &quot;redis-server&quot; ] HEALTHCHECKHEALTHCHECK [option] CMD &lt;command&gt;HEALTHCHECK NONE 可屏蔽基础镜像的健康检测指令 其命令和ENTTYPOINT类似.--interval 间隔时间,两次检测时间间隔,默认30s--timeout 超时.健康检测运行超时时间.默认30s--retries 重试.默认3次.返回值:0:成功,1:失败 2:保留 1234FROM nginxRUN apt-get update &amp;&amp; apt-get install -y curl &amp;&amp; rm -rf /var/lib/apt/lists/*HEALTHCHECK --interval=15s --timeout=5s \ CMD curl -fs http://localhost/ || exit 1 Dockerfile多阶段构建123456789101112FROM muninn/glide:alpine AS build-envADD . /go/src/appWORKDIR /go/src/appRUN glide installRUN go build -v -o /go/src/app/app-serverFROM alpineRUN apk add -U tzdataRUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeCOPY --from=build-env /go/src/app/app-server /usr/local/bin/app-serverEXPOSE 80CMD [&quot;app-server&quot;] 首先，第一个 FROM 后边多了个 AS 关键字，可以给这个阶段起个名字。第二部分用了官方的 alpine 镜像，改变时区到中国注意COPY 关键字，它现在可以接受 –from= 这样的参数，从上个我们起名字的阶段复制文件过来。 Dockerfile文件解析1234567891011121314151617181920212223242526272829303132333435363738394041#docker build -t centos_nginx:v5 .#docker run --name web_5 -d -p 85:80 centos_nginx:v5 FROM centosMAINTAINER zili.liADD nginx-1.12.2.tar.gz /usr/local/srcRUN buildDeps=&apos;gcc gcc-c++ glib make autoconf openssl openssl-devel libxslt-devel gd gd-devel GeoIP GeoIP-devel pcre pcre-devel wget curl&apos; \ &amp;&amp; yum -y install $buildDeps \ &amp;&amp; useradd -M -s /sbin/nologin nginx#多个用逗号分隔#docker inspect web_5 的 Mounts下可看到文件挂载信息.#docker exec -it web_5 /bin/bash 进入容器可查看到挂载的目录,其内容和Mounts是同步的VOLUME [&quot;/usr/local/nginx/html&quot;]WORKDIR /usr/local/src/nginx-1.12.2RUN ./configure --user=nginx --group=nginx --prefix=/usr/local/nginx --with-file-aio --with-http_ssl_module --with-http_realip_module --with-http_addition_module --with-http_xslt_module --with-http_image_filter_module --with-http_geoip_module --with-http_sub_module --with-http_dav_module --with-http_flv_module --with-http_mp4_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_auth_request_module --with-http_random_index_module --with-http_secure_link_module --with-http_degradation_module --with-http_stub_status_module \ &amp;&amp; make \ &amp;&amp; make install \ &amp;&amp; rm -rf /usr/local/src/nginx-1.12.2#指定了环境变量,所以生成容器的时候 不用在指定路径.直接nginx 即可ENV PATH /usr/local/nginx/sbin:$PATH EXPOSE 80#当ENTRYPOINT和CMD连用时，CMD的命令是ENTRYPOINT命令的参数，两者连用相当于nginx -g &quot;daemon off;&quot;#如果CMD [&quot;-g&quot;,&quot;daemon on;&quot;] 那么生成的容器将不会处于up状态.但是执行run的时候加入 -g &quot;daemon off;&quot;此参数将会传入给ENTRYPOINT#容器中的应用都应该以前台执行,容器没有后台概念,-d 表示的后台,是程序的后台,程序完毕容器停止,而不是容器后台.容器都是前台的.ENTRYPOINT [&quot;nginx&quot;]#CMD service nginx start 这是初学经常搞模糊的地方!#对于容器而言，其启动程序就是容器应用进程，容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出.# CMD service nginx start 会被理解为 CMD [ &quot;sh&quot;, &quot;-c&quot;, &quot;service nginx start&quot;]#因此主进程实际上是 sh,那么当 service nginx start 命令结束后，sh 也就结束，sh作为主进程退出了自然就会令容器退出#正确的做法是直接执行 nginx 可执行文件，并且要求以前台形式运行。比如：CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;],或CMD /bin/sh -c &apos;nginx -g &quot;daemon off;&quot;&apos;CMD [&quot;-g&quot;,&quot;daemon off;&quot;] container新建容器docker run 此命令是用来新建容器例如：docker run ubuntu /bin/echo &#39;test&#39; 会输出test后终止容器，终止容器并不是删除容器，所以容器还是存在的，添加--rm 则会临时性的执行，完后删除容器docker run --rm .... docker run -it ubuntu /bin/bash 会生成一个伪终端。可通过终端进行简单的操作。同样，此容器也是存在的。docker ps -a查看 docker run流程 检查本地是否存在指定的镜像，不存在就从公有仓库下载 利用镜像创建并启动一个容器 分配一个文件系统，并在只读的镜像层外面挂载一层可读写层 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去 从地址池配置一个 ip 地址给容器 执行用户指定的应用程序 执行完毕后容器被终止,并不是删除，容器还可以再次启动 启动容器docker container start -i container_id会重新启动一个已终止的容器。 docker container 还有很多命令，建议使用 –help查看使用说明 容器后台运行docker run -d不是用后台运行时，结果输出会到当前主机12345[root@zili ~]# docker run ubuntu /bin/sh -c &quot;while true; do echo test -d; sleep 1; done&quot;test -dtest -dtest -dtest -d 使用后台运行时候,容器将后台运行，那么如何查看结果呢？12[root@zili ~]# docker run -d ubuntu /bin/sh -c &quot;while true; do echo test -d; sleep 1; done&quot;69931b53bfea873daf9cfeb82c926be84980e41a3c0f62f966b039ffbaa0b1c1 docker container log container_id 可以来查看相关的容器输出12345678[root@zili ~]# docker container logs 699test -dtest -dtest -dtest -dtest -dtest -d... 需要注意的是，容器是否能长久运行和指定的命令有关系，也就是说，命令结束，容器停止，和-d参数并无关系，它只是用来让容器后台运行而已。停止容器运行使用docker container stop container_id 进入容器docker attach 不建议使用,因为使用此命令,如果容器是-d后台运行,stdin退出时,容器运行状态将终止.也就是说,此命令进入容器,退出时会导致后台运行的容器终止 docker exec -it 不会导致后台运行中的容器终止.推荐使用~!参数说明请使用 docker exec --help 导入和导出docker container export 导出123456[root@docker ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES0828d964cc2f ubuntu:16.04 &quot;/bin/bash&quot; 29 minutes ago Exited (0) 29 minutes ago attach[root@docker ~]# docker container export attach &gt; attach.tar[root@docker ~]# lsanaconda-ks.cfg attach.tar docker myip docker image import 导入12345[root@docker ~]# cat attach.tar | docker import - test/ubuntusha256:e9b17f2d8f7546a1d3e143f684b234ebf2301b95193782d8685d2cdb2f05b2f5[root@docker ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEtest/ubuntu latest e9b17f2d8f75 4 seconds ago 98.4MB 也可以通过URL导入docker import http://example.com/exampleimage.tgz example/imagerepo 删除容器docker rmdocker rm -f 删除运行中的容器docker container prune 删除所有终止的容器 其他命令docker diff container name 查看容器变化docker history container:tag 查看container 历史 Repository官方repository Docker hub docker search 命令查找官方repository的镜像.docker pull 命令把镜像拉取下来 docker login 登录docker hubdocker logout 退出docker hubdocker push 推送镜像 私有仓库略 数据管理容器管理数据主要有两种方式,数据卷（Volumes）和挂载主机目录(Bind mounts) 数据卷(Volumes)数据卷可以在容器之间共享和重用,数据卷 的修改会立马生效且数据卷 的更新，不会影响镜像数据卷 默认会一直存在，即使容器被删除 注意：数据卷 的使用，类似于 Linux 下对目录或文件进行 mount，镜像中的被指定为挂载点的目录中的文件会隐藏掉，能显示看的是挂载的 数据卷。 数据卷有 --mount -v 或者 --volume 但是推荐使用 --mount 参数 创建/删除volumedocker volume create webtest 创建一个webtest的数据卷docker volume inspect webtest 查看数据卷123456789101112[root@docker ~]# docker volume inspect webtest[ &#123; &quot;CreatedAt&quot;: &quot;2018-04-15T10:54:40+08:00&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Labels&quot;: &#123;&#125;, &quot;Mountpoint&quot;: &quot;/var/lib/docker/volumes/webtest/_data&quot;, &quot;Name&quot;: &quot;webtest&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Scope&quot;: &quot;local&quot; &#125;] docker volume rm webtest 删除数据卷,前提数据卷没有被容器使用 数据卷是独立于容器的,用来做数据初始化的,所以容器的删除不会影响数据卷,若删除容器时想要删除数据卷 则使用docker rm -v清理无主的数据卷 docker volume prune 涉及删除的操作,思之,慎之而行之 启动挂载数据卷的容器docker run时，使用 --mount 标记来将数据卷挂载到容器里,在一次 docker run 中可以挂载多个数据卷 -v后面的映射关系是&quot;宿主机文件/目录:容器里对应的文件/目录&quot;，其中，宿主机上的文件/目录是要提前存在的，容器里对应的文件/目录会自动创建。 两种方式本质上没有区别,mount更加清晰直观.docker run -it --name web -d -p 80:80 --mount source=webtest,target=/webdir nginxdocker run -it --name web -d -p 80:80 -v webtest:/webdir nginx 查看数据卷具体信息docker inspect web 数据卷的信息在Mounts下123456789101112&quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;volume&quot;, &quot;Name&quot;: &quot;webtest&quot;, &quot;Source&quot;: &quot;/var/lib/docker/volumes/webtest/_data&quot;, &quot;Destination&quot;: &quot;/webdir&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mode&quot;: &quot;z&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;&quot; &#125; ], docker exec -it container /bin/bash 可进入容器查看挂载的目录并新建文件等12345678910root@f24f73d240d9:/# cd webdir/root@f24f73d240d9:/webdir# touch 123root@f24f73d240d9:/webdir# df -hFilesystem Size Used Avail Use% Mounted on/dev/mapper/centos-root 50G 1.8G 49G 4% /webdir然后退出可在宿主机上看到此文件[root@docker ~]# cd /var/lib/docker/volumes/webtest/_data/[root@docker _data]# ls123 挂载目录(Bind mounts)多个目录的挂载 多写几次--mount即可 [root@docker web]# docker run --name dirbind -d -p 80:80 --mount type=bind,source=/root/web,target=/usr/share/nginx/html nginx首先我在root下新建web目录并写个index.html文件将其挂到由nginx镜像生成的容器dirbind的html下. 12345678[root@docker web]# docker run --name dirbind -d -p 80:80 --mount type=bind,source=/root/web,target=/usr/share/nginx/html nginx2648c6f9e8ff3660e37dc64b0483bc906e5987082224fb0f8604e2bceef2da65[root@docker web]# docker exec -it 264 /bin/bash#此时已进入容器root@2648c6f9e8ff:/# cd /usr/share/nginx/htmlroot@2648c6f9e8ff:/usr/share/nginx/html# lsindex.html#index文件已经挂载上来了. 再次访问nginx就能看到index的内容了. 查看容器信息docker inspect dirbind #Mounts部分可看到挂载信息,注意这里,RW: true说明是读写权限的,其实还可以挂载个只读的文件.后有说明.12345678910&quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;bind&quot;, &quot;Source&quot;: &quot;/root/web&quot;, &quot;Destination&quot;: &quot;/usr/share/nginx/html&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;rprivate&quot; &#125; ], 只读目录挂载docker run --name dirbind -d -p 80:80 --mount type=bind,source=/root/web,target=/usr/share/nginx/html,readonly nginx 挂载单个文件docker run --name bindfile -d -p 80:80 \ --mount type=bind,source=/root/web,target=/usr/share/nginx/html \ --mount type=bind,source=/root/a.html,target=/usr/share/nginx/html/index.html nginx第二个--mount是挂载单个文件,其会覆盖挂载的第一个目录下的index文件. 单个文件的挂载要求容器内必须也存在此文件 docker网络docker 网络分为 外部访问和容器互联两种情况 外部访问这个已经并不陌生了就是在docker run的时候加上-p参数即可指定本地端口和容器端口一个指定端口上只可以绑定一个容器格式有ip:hostPort:containerPort | ip::containerPort | hostPort:containerPort 还可以指定端口格式(tcp或udp)127.0.0.1:1111:1111/udp 注意:若需多个端口绑定,重复只用-p 即可 docker port container_id 可查看容器端口映射情况 使用-P 大写的P默认会自动分配端口进行映射. 容器互联新建网络docker network create -d bridge web-net 新建一个web-net的网络-d 参数指定 Docker 网络类型，有 bridge overlay。其中 overlay 网络类型用于 Swarm mode123456789101112131415161718192021222324252627282930313233[root@docker ~]# docker network create -d bridge web-net3a06ef1bde3ea75c16afe1d3024d1a161d33c3c9499646521f30a74992607407[root@docker ~]# docker network inspect web-net[ &#123; &quot;Name&quot;: &quot;web-net&quot;, &quot;Id&quot;: &quot;3a06ef1bde3ea75c16afe1d3024d1a161d33c3c9499646521f30a74992607407&quot;, &quot;Created&quot;: &quot;2018-04-15T14:08:13.044203584+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.18.0.0/16&quot;, &quot;Gateway&quot;: &quot;172.18.0.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123;&#125;, &quot;Options&quot;: &#123;&#125;, &quot;Labels&quot;: &#123;&#125; &#125;] 容器关联网络通过--network 参数指定容器网络docker run --name web1 -d -P --network web-net nginxdocker run --name web2 -d -P --network web-net nginx12345678910111213141516171819202122232425262728293031323334353637383940414243444546[root@docker ~]# docker network inspect web-net[ &#123; &quot;Name&quot;: &quot;web-net&quot;, &quot;Id&quot;: &quot;3a06ef1bde3ea75c16afe1d3024d1a161d33c3c9499646521f30a74992607407&quot;, &quot;Created&quot;: &quot;2018-04-15T14:08:13.044203584+08:00&quot;, &quot;Scope&quot;: &quot;local&quot;, &quot;Driver&quot;: &quot;bridge&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;172.18.0.0/16&quot;, &quot;Gateway&quot;: &quot;172.18.0.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123; &quot;21250caa4838de429eeda541aab9d4e6e0697a4b9038d9656e0ee318db9f2636&quot;: &#123; &quot;Name&quot;: &quot;web2&quot;, &quot;EndpointID&quot;: &quot;46cac28abeef408daa1351bd2c376376928c82c1bb2836cb729adcd7379022ce&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:12:00:02&quot;, &quot;IPv4Address&quot;: &quot;172.18.0.2/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125;, &quot;aca3aa6558188c41a2ab1f79993d845d6cea392fcc8c61d8acc0bc9864550834&quot;: &#123; &quot;Name&quot;: &quot;web1&quot;, &quot;EndpointID&quot;: &quot;26e27856326d3bc04f29ecaf083dab789c80b0f64ce7c09159df31e896052ca6&quot;, &quot;MacAddress&quot;: &quot;02:42:ac:12:00:03&quot;, &quot;IPv4Address&quot;: &quot;172.18.0.3/16&quot;, &quot;IPv6Address&quot;: &quot;&quot; &#125; &#125;, &quot;Options&quot;: &#123;&#125;, &quot;Labels&quot;: &#123;&#125; &#125;] 进入容器中docker exec -it /bin/bashubuntu容器没有ping则安装123apt-get updateapt install net-tools # ifconfigapt install iputils-ping # ping 1234root@0b8f77731024:~# ping web2PING net2 (172.18.0.2) 56(84) bytes of data.64 bytes from web2.web-net (172.18.0.2): icmp_seq=1 ttl=64 time=0.085 ms64 bytes from web2.web-net (172.18.0.2): icmp_seq=2 ttl=64 time=0.043 ms 如果有过个容器要互联,如果你有多个容器之间需要互相连接，Docker Compose了解一下. DNS进入容器中执行mount1234root@0b8f77731024:~# mount/dev/mapper/centos-root on /etc/resolv.conf type xfs (rw,relatime,attr2,inode64,noquota)/dev/mapper/centos-root on /etc/hostname type xfs (rw,relatime,attr2,inode64,noquota)/dev/mapper/centos-root on /etc/hosts type xfs (rw,relatime,attr2,inode64,noquota) 可以看到,dns,主机名,hosts文件是被挂载上去的,这样只要宿主机有变更,那么容器就能立即得到更新.同理,如果有需要可单独见文件进行挂载,并指向容器内相关文件. 还有一种方式 通过/etc/docker/daemon.json来配置,这样影响所有容器123456&#123; &quot;dns&quot; : [ &quot;114.114.114.114&quot;, &quot;8.8.8.8&quot; ]&#125; 如果想要手动指定的话.在docker run的时候可以添加参数-h HOSTNAME或者 --hostname=HOSTNAME设定容器的主机名,但它在容器外部看不到，既不会在 docker container ls 中显示，也不会在其他的容器的 /etc/hosts 看到。--dns=IP_ADDRESS 添加 DNS 服务器到容器的/etc/resolv.conf 中，让容器用这个服务器来解析所有不在 /etc/hosts 中的主机名。--dns-search=DOMAIN设定容器的搜索域，当设定搜索域为 .example.com时，在搜索一个名为 host 的主机时，DNS 不仅搜索 host，还会搜索 host.example.com 高级网络配置略，参考链接 Docker ComposeDocker Compose 是 Docker 官方编排（Orchestration）项目之一，负责快速的部署分布式应用 我们知道通过Dockerfile可以实现单独的一个应用容器.实际,一个项目可能需要多个容器相互配合来完成.比如一个动态网站,除了页面还有数据库等等. compose两个重要的概念: - 服务(service) : 一个应用容器，实际上可以包括若干运行相同镜像的容器实例 - 项目(project) : 一组关联容器组成的完整业务单元 安装二进制安装 123sudo curl -L https://github.com/docker/compose/releases/download/1.17.1/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-composesudo chmod +x /usr/local/bin/docker-compose pip安装sudo pip install -U docker-compose 容器中执行 123curl -L https://github.com/docker/compose/releases/download/1.8.0/run.sh &gt; /usr/local/bin/docker-composechmod +x /usr/local/bin/docker-compose 使用1234├── docker_compose│ ├── app.py│ ├── docker-compose.yml│ └── Dockerfile app.py 12345678910111213from flask import Flaskfrom redis import Redisapp = Flask(__name__)redis = Redis(host=&apos;redis&apos;, port=6379)@app.route(&apos;/&apos;)def hello(): count = redis.incr(&apos;hits&apos;) return &apos;Hello World! 该页面已被访问 &#123;&#125; 次。\n&apos;.format(count)if __name__ == &quot;__main__&quot;: app.run(host=&quot;0.0.0.0&quot;, debug=True) Dockerfile 12345FROM python:3.6-alpineADD . /codeWORKDIR /codeRUN pip install redis flaskCMD [&quot;python&quot;, &quot;app.py&quot;] docker-compose.yml 12345678910version: &apos;3&apos;services: web: build: . ports: - &quot;5000:5000&quot; redis: image: &quot;redis:alpine&quot; 然后执行docker-compose up 即可 命令参数说明docker-compose - `-f, --file FILE` 指定使用的 Compose 模板文件，默认为 `docker-compose.yml`，可以多次指定。 - `-p, --project-name NAME` 指定项目名称，默认将使用所在目录名称作为项目名。 - `--x-networking` 使用 Docker 的可拔插网络后端特性 - `--x-network-driver DRIVER` 指定网络后端的驱动，默认为 bridge - `--verbose` 输出更多调试信息 - `-v, --version` 打印版本并退出 docker-compose build用来创建或重新创建服务使用的镜像docker-compose build service_a创建一个镜像名叫service_a docker-compose kill用于通过容器发送SIGKILL信号强行停止服务 docker-compose logs显示service的日志信息 docker-compose pause/unpausedocker-compose pause #暂停服务docker-compose unpause #恢复被暂停的服务 docker-compose port用于查看服务中的端口与物理机的映射关系docker-compose port nginx_web 80查看服务中80端口映射到物理机上的那个端口 dokcer-compose ps用于显示当前项目下的容器注意，此命令与docker ps不同作用，此命令会显示停止后的容器（状态为Exited），只征对某个项目。 docker-compose pull用于拉取服务依赖的镜像 docker-compose restart用于重启某个服务中的所有容器docker-compose restart service_name只有正在运行的服务可以使用重启命令，停止的服务是不可以重启 docker-compose rm删除停止的服务（服务里的容器）12-f #强制删除-v #删除与容器相关的卷（volumes） docker-compose run用于在服务中运行一个一次性的命令。这个命令会新建一个容器，它的配置和srvice的配置相同。但两者之间还是有两点不同之处121、run指定的命令会直接覆盖掉service配置中指定的命令2、run命令启动的容器不会创建在service配置中指定的端口，如果需要指定使用--service-ports指定 docker-compose start/stopdocker-compose start 启动运行某个服务的所有容器docker-compose stop 启动运行某个服务的所有容器 docker-compose scale指定某个服务启动的容器个数 实例一1234567[root@docker web-nginx]# tree.├── docker-compose.yml├── nginx│ └── nginx.conf└── webserver └── index.html nginx.conf 1234567891011121314151617181920212223242526272829303132333435363738#user nginx;worker_processes 1;error_log /var/log/nginx_error.log warn;pid /var/run/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log /var/log/nginx_access.log main; client_max_body_size 10m; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on;server &#123; listen 80; server_name localhost; location / &#123; root /webserver; index index.html index.htm; &#125;&#125; #include /usr/local/nginx/conf.d/*.conf;&#125; index.html 12345678910&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;welcome to nginx web stie&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h2&gt;compose test1---1&lt;/h2&gt;&lt;/body&gt;&lt;/html&gt; docker-compose.yml 1234567891011121314version: &quot;3&quot; #指定语法版本services: #定义服务 nginx: container_name: web-nginx #容器名字 image: centos_nginx:v5 #依赖镜像 restart: always ports: #端口映射 - 80:80 volumes: #映射文件到容器.第一个是web的,在nginx通过root指定路径.第二个是配置文件. #如果不想指定web,可直接映射到nginx默认html路径.nginx配置不需要指定路径了 #- ./webserver:/usr/local/nginx/html - ./webserver:/webserver - ./nginx/nginx.conf:/usr/local/nginx/conf/nginx.conf 实例二创建自定义网络testdocker network create --subnet=172.88.0.0/16 test网络名test和ip会在docker-compose中使用,用来指定网络和IP,同时IP与nginx负载有关 目录结构12345678910111213141516├── docker-compose.yml├── etc│ └── localtime├── nginx│ ├── Dockerfile│ ├── nginx-1.12.2.tar.gz│ └── nginx.conf├── tomcat│ ├── apache-tomcat-8.5.24.tar.gz│ ├── Dockerfile│ └── jdk-8u45-linux-x64.tar.gz└── webserver ├── tomcatA │ └── index.jsp └── tomcatB └── index.jsp nginxnginx.conf 12345678910111213141516171819202122232425262728293031323334353637383940414243#user nginx;worker_processes 1;error_log /var/log/nginx_error.log warn;pid /var/run/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; upstream tomcat &#123; server 172.88.0.11:8080; server 172.88.0.22:8080; &#125; include mime.types; default_type application/octet-stream; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log /var/log/nginx_access.log main; client_max_body_size 10m; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; server &#123; listen 80; server_name tomcat; location / &#123; #root /webserver; proxy_pass http://tomcat; &#125; &#125; #include /usr/local/nginx/conf.d/*.conf;&#125; Dcokerfile 1234567891011121314151617181920212223242526FROM centosMAINTAINER zili.liADD nginx-1.12.2.tar.gz /usr/local/srcRUN buildDeps=&apos;gcc gcc-c++ glib make autoconf openssl openssl-devel libxslt-devel gd gd-devel GeoIP GeoIP-devel pcre pcre-devel wget curl&apos; \ &amp;&amp; yum -y install $buildDeps \ &amp;&amp; useradd -M -s /sbin/nologin nginxVOLUME [&quot;/usr/local/nginx/html&quot;]WORKDIR /usr/local/src/nginx-1.12.2RUN ./configure --user=nginx --group=nginx --prefix=/usr/local/nginx --with-file-aio --with-http_ssl_module --with-http_realip_module --with-http_addition_module --with-http_xslt_module --with-http_image_filter_module --with-http_geoip_module --with-http_sub_module --with-http_dav_module --with-http_flv_module --with-http_mp4_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_auth_request_module --with-http_random_index_module --with-http_secure_link_module --with-http_degradation_module --with-http_stub_status_module \ &amp;&amp; make \ &amp;&amp; make install \ &amp;&amp; rm -rf /usr/local/src/nginx-1.12.2ENV PATH /usr/local/nginx/sbin:$PATH EXPOSE 80ENTRYPOINT [&quot;nginx&quot;]CMD [&quot;-g&quot;,&quot;daemon off;&quot;] tomcatDcokerfile 1234567891011121314FROM centosADD jdk-8u45-linux-x64.tar.gz /usr/localENV RUN_AS_USER=rootENV JAVA_HOME /usr/local/jdk1.8.0_45ENV CLASS_HOME=/usr/local/jdk1.8.0_45/lib:$JAVA_HOME/jre/libENV CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib:$CLASSPATHENV PATH=$PATH:$JAVA_HOME/binADD apache-tomcat-8.5.24.tar.gz /usr/localEXPOSE 8080ENTRYPOINT [&quot;/usr/local/apache-tomcat-8.5.24/bin/catalina.sh&quot;, &quot;run&quot;] docker-composedocker-compose.yml 12345678910111213141516171819202122232425262728293031323334353637383940414243version: &quot;3&quot;services: nginx: hostname: nginx build: ./nginx restart: always ports: - 80:80 networks: test: ipv4_address: 172.88.0.88 volumes: - ./nginx/nginx.conf:/usr/local/nginx/conf/nginx.conf - ./etc/localtime:/etc/localtime depends_on: - tomcat1 - tomcat2 tomcat1: hostname: tomcat1 build: ./tomcat restart: always volumes: - ./webserver/tomcatA:/usr/local/apache-tomcat-8.5.24/webapps/ROOT - ./etc/localtime:/etc/localtime networks: test: ipv4_address: 172.88.0.11 tomcat2: hostname: tomcat2 build: ./tomcat restart: always volumes: - ./webserver/tomcatB/index.jsp:/usr/local/apache-tomcat-8.5.24/webapps/ROOT/index.jsp - ./etc/localtime:/etc/localtime networks: test: ipv4_address: 172.88.0.22networks: test: external: true docker-compose up docker machine安装 linux官网下载相关安装包,安装即可 . 12$ sudo curl -L https://github.com/docker/machine/releases/download/v0.13.0/docker-machine-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-machine$ sudo chmod +x /usr/local/bin/docker-machine 使用123456789docker-machine create \ --driver vmwarevsphere \ --vmwarevsphere-vcenter=xxx.xxx.xxx.xxx \ --vmwarevsphere-username=xxxxx \ --vmwarevsphere-password=xxxxxxx \ --vmwarevsphere-cpu-count=1 \ --vmwarevsphere-memory-size=512 \ --vmwarevsphere-disk-size=10240 \ TestDcokerMa driver vmwarevsphere我们的虚拟机 host 上安装的是 vmware 的产品 vSphere，因此需要给 Docker Machine 提供对应的驱动，这样才能够在上面安装新的虚拟机。--vmwarevsphere-vcenter=xxx.xxx.xxx.xxx--vmwarevsphere-username=root--vmwarevsphere-password=12345678上面三行分别指定了虚拟机 host 的 IP 地址、用户名和密码。 --vmwarevsphere-cpu-count=1--vmwarevsphere-memory-size=512--vmwarevsphere-disk-size=10240上面三行则分别指定了新创建的虚拟机占用的 cpu、内存和磁盘资源。TestDcokerMa最后一个参数则是新建虚拟机的名称。 详细使用参考官网​]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins pipeline]]></title>
    <url>%2F2018%2F05%2F09%2Fjenkins-pipeline%2F</url>
    <content type="text"><![CDATA[jenkins-pipeline.png 用写代码的形式配置jenkins项目支持两种语法格式Declarative Pipeline和Scripted Pipeline 新建文件Jenkinsfile 放于项目根目录下 pipeline学习中文版英文版 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113//Jenkinsfile (Declarative Pipeline)////author: lizili//pipeline &#123; agent any triggers &#123; //cron(&apos;H/10 * * * 1-5&apos;)// pollSCM(&apos;H/10 * * * 1-5&apos;) &#125; stages &#123; stage(&apos;Build&apos;) &#123; steps &#123; echo &apos;Building..&apos; //sh &apos;mvn clean install -f moni/pom.xml&apos;// &#125; &#125; stage(&apos;Test&apos;) &#123; steps &#123; echo &apos;Testing..&apos; //sh &apos;mvn clean verify sonar:sonar -f moni/pom.xml&apos;// &#125; &#125; stage(&apos;Deploy&apos;) &#123; when &#123; expression &#123; currentBuild.result == null || currentBuild.result == &apos;SUCCESS&apos; &#125; &#125; steps &#123; echo &apos;upload file to server....&apos; /* sh &quot;sshpass -p centos scp $WORKSPACE/moni/target/monitor.war root@192.168.1.55:/root/war&quot; echo &apos;Restart tomcat.....&apos; sh &quot;sshpass -p centos ssh root@192.168.1.55 &apos;/usr/bin/bash ~/deploy.sh deploy monitor 80 /usr/local/tomcat-7.0.85 $BUILD_NUMBER&apos;&quot; */ /* sshPublisher( publishers: [ sshPublisherDesc( configName: &apos;192_168_1_55&apos;, transfers: [ sshTransfer( excludes: &apos;&apos;, execCommand: &apos;~/deploy.sh deploy monitor 80 /usr/local/tomcat-7.0.85 $BUILD_NUMBER&apos;, execTimeout: 120000, flatten: false, makeEmptyDirs: false, noDefaultExcludes: false, patternSeparator: &apos;[, ]+&apos;, remoteDirectory: &apos;root/war/&apos;, remoteDirectorySDF: false, removePrefix: &apos;moni/target/&apos;, sourceFiles: &apos;moni/target/*.war&apos; ) ], usePromotionTimestamp: false, useWorkspaceInPromotion: false, verbose: false ) ] ) */ &#125; &#125; stage(&apos;mail&apos;)&#123; steps &#123; echo &apos;send mail&apos; /* mail body: &apos;$&#123;env.BUILD_ID&#125; on $&#123;env.JENKINS_URL&#125;&apos;, from: &apos;lizili@jingkunsystem.com&apos;, replyTo: &apos;&apos;, subject: &apos;project build FAILURE&apos;, to: &apos;lizili@jingkunsystem.com&apos; */ &#125; &#125; &#125; post &#123; /* always &#123; echo &apos;This will always run&apos; &#125; */ success &#123; echo &apos;send mail-BUILD-SUCCESS&apos; mail body: &quot;$&#123;env.BUILD_ID&#125; on $&#123;env.JENKINS_URL&#125;&quot;, from: &apos;lizili@jingkunsystem.com&apos;, replyTo: &apos;&apos;, subject: &quot;$&#123;env.JOB_BASE_NAME&#125; build SUCCESS&quot;, to: &apos;lizili@jingkunsystem.com&apos; &#125; failure &#123; echo &apos;send mail-BUILD-FAILURE&apos; mail body: &quot;$&#123;env.BUILD_ID&#125; on $&#123;env.JENKINS_URL&#125;&quot;, from: &apos;lizili@jingkunsystem.com&apos;, replyTo: &apos;&apos;, subject: &quot;$&#123;env.JOB_BASE_NAME&#125; build FAILURE&quot;, to: &apos;lizili@jingkunsystem.com&apos; &#125; /* unstable &#123; echo &apos;This will run only if the run was marked as unstable&apos; &#125; changed &#123; echo &apos;This will run only if the state of the Pipeline has changed&apos; echo &apos;For example, if the Pipeline was previously failing but is now successful&apos; &#125; */ &#125;&#125; 新建个流水线项目 - 流水线 - 定义: Pipeline script from SCM - SCM: 根据情况填写即可 - 脚本路径: Jenkinsfile]]></content>
      <categories>
        <category>运维工具</category>
        <category>jenkins</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins rollback]]></title>
    <url>%2F2018%2F05%2F08%2Fjenkins-rollback%2F</url>
    <content type="text"><![CDATA[回滚之前,确保自己的项目是有备份的 新建项目新建一个自由风格 general 参数化构建过程(运行时参数) 名称: ROLL_BACK (自定义) 项目: 项目名字(此项目名字要写存在的,即,要回滚的项目) 描述: 随便写 filter: 成功的构建. 其余不写. 构建添加执行shell模块这里注意的是:ROLL_BACK对应的就是项目名字 可以123tmp=$&#123;ROLL_BACK%/*&#125;BUILD_NUMBER=$&#123;tmp##*/&#125;ssh root@192.168.1.55 /root/deploy.sh rollback monitor 80 /usr/local/tomcat-7.0.85 $BUILD_NUMBER 脚本参考1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495#!/bin/bash#jenkins#jenkins需要做配置 send..ssh#Remote directory : tmp/ #这个相对路径取决于系统配置信息里面的ssh主机的 Remote Directory,建议tmp,因为备份在tmp #Exec command : ~/deploy.sh deploy cmdb $BUILD_NUMBER#tomcatt_home_bin=`find / -name catalina.sh`t_home=$&#123;t_home_bin%*/bin/*&#125;t_port=`cat $t_home/conf/server.xml | grep 'HTTP/1.1' | grep protocol | grep Connector |awk '&#123;print $2&#125;' | tr -cd "[0-9]"`#exportsource /etc/profilesource $HOME/.bashrc#how to use#./deploy.sh &lt;projectname&gt; [tomcat port] [tomcat home dir] $BUILD_NUMBER#default varACTION="$1"PROJECT="$2"TOMCAT_PORT=$t_portTOMCAT_HOME=$t_homeVERSION="$3"#dir exist?if [ ! -d "/tmp/war/bak/" ];thenmkdir -p /tmp/war/bak/fi#args numif [ $# -lt 3 ]; then echo "you must use like this : ./deploy.sh &lt;action&gt; &lt;projectname&gt; &lt;version&gt;" exitfi#search tomcatpid#tomcat_pid=`netstat -anp | grep $TOMCAT_PORT | awk '&#123;printf $7&#125;' | cut -d "/" -f 1`tomcat_p=`netstat -anp | grep $TOMCAT_PORT | awk '&#123;printf $7&#125;' | cut -d "/" -f 1`tomcat_pid=$&#123;tomcat_p#*-&#125;echo "current :" $tomcat_pidwhile [ -n "$tomcat_pid" ]do sleep 5 #进一步筛选 tomcat_pid=`ps -ef | grep $tomcat_pid |grep $TOMCAT_HOME | grep -v 'grep\|tail\|more\|bash\|less'| awk '&#123;print $2&#125;'` echo "scan tomcat pid :" $tomcat_pid if [ -n "$tomcat_pid" ]; then echo "kill tomcat :" $tomcat_pid kill -9 $tomcat_pid fidone#path for bakdirBAK_DIR=/tmp/war/bak/$PROJECTif [ ! -d "$BAK_DIR" ];then mkdir -p $BAK_DIRfiif [ $ACTION == 'deploy' ];then cp /tmp/$PROJECT.war "$BAK_DIR"/"$PROJECT"_"$VERSION".war #publish project echo "+++++++++++++++++++++++++++++++++++++++++++++++++++" echo "scan no tomcat pid,$PROJECT publishing...." sleep 10 rm -rf "$TOMCAT_HOME"/webapps/$PROJECT rm -rf "$TOMCAT_HOME"/webapps/$PROJECT.war #this path is define by jenkins-after build-ssh-Remote directory mv /tmp/$PROJECT.war "$TOMCAT_HOME"/webapps/$PROJECT.warfiif [ $ACTION == 'rollback' ];then #delete project rm -rf "$TOMCAT_HOME"/webapps/$PROJECT rm -rf "$TOMCAT_HOME"/webapps/$PROJECT.war cp "$BAK_DIR"/"$PROJECT"_"$VERSION".war "$TOMCAT_HOME"/webapps/$PROJECT.war #publish project echo "+++++++++++++++++++++++++++++++++++++++++++++++++++" echo "rollback to the project $PROJECT $VERSION" echo "+++++++++++++++++++++++++++++++++++++++++++++++++++" sleep 3fi#start tomcat"$TOMCAT_HOME"/bin/startup.shecho "+++++++++++++++++++++++++++++++++++++++++++++++++++"echo "tomcat is starting,please try to access $PROJECT conslone url"#del warecho "+++++++++++++++++++++++++++++++++++++++++++++++++++"echo `date +%Y%m%d` "delete invalid war"find $BAK_DIR -mtime +7 -name "*.war";find $BAK_DIR -mtime +7 -name "*.war" -exec rm -rf &#123;&#125; \;echo "+++++++++++++++++++++++++++++++++++++++++++++++++++"echo "host address:" `/sbin/ifconfig -a|grep inet|grep -v 127.0.0.1|grep -v inet6 | awk '&#123;print $2&#125;' | tr -d "addr:"`echo "+++++++++++++++++++++++++++++++++++++++++++++++++++"]]></content>
      <categories>
        <category>运维工具</category>
        <category>jenkins</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins+sonarqube]]></title>
    <url>%2F2018%2F04%2F18%2Fjenkins-sonarqube%2F</url>
    <content type="text"><![CDATA[SonarQube是一个用于代码质量管理的开源平台 环境准备系统版本:centos7x64 应用 版本 java 1.8.0_xx mysql 5.6+ sonarqube 6.7LTS JENKINS 2.117 jenkins安装插件SonarQube ,插件对jenkins有版本要求. mysql编译安装,建议阅读 jenkins安装,建议阅读 sonarqube 安装下载安装包: 官方下载 unzip sonarqube-6.7.zip -d /usr/local/ 由于es的原因,不能用root用户启动,所以要新建用户12useradd sonarchown -R sonar /usr/local/sonarqube-6.7/ 配置环境变量 123#sonarqubeexport SONAR_HOME=/usr/local/sonarqube-6.7export PATH=$&#123;SONAR_HOME&#125;/bin:$&#123;PATH&#125; 数据库配置如果不用mysql 可直接启动即可.系统默认使用内置数据库 create database sonar character set utf8 collate utf8_general_ci;授权GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;youpassword&#39; WITH GRANT OPTION;flush privileges 编辑sonar配置vim conf/sonar.properties 123456789sonar.jdbc.username= rootsonar.jdbc.password= xxxxx#..3306/sonar..? 这里的sonar 是dbnamesonar.jdbc.url= jdbc:mysql://192.168.1.56:3306/sonar?useUnicode=true&amp;characterEncoding=utf8&amp;rewriteBatchedStatements=true&amp;useConfigs=maxPerformance&amp;useSSL=false#可选sonar.web.host=本机IP#默认为9000,可修改sonar.web.port=9000 启动sonarsu sonar ./bin/linux-x86-64/sonar.sh start 登录在浏览器输入：http:// IP：PORT 即可 admin/admin 安装插件: Administrator—&gt;Markeptlace Chinese Pack Checkstyle jenkins-SonarQube系统设置 —&gt; SonarQube servers —&gt; SonarQube installations - Name : 自定义 - Server URL : sonar地址 - Server authentication token : snoar中生成.(我的账户--安全--生成令牌) 方法一修改maven配置. 123456789101112131415161718&lt;settings&gt; &lt;pluginGroups&gt; #添加此行 &lt;pluginGroup&gt;org.sonarsource.scanner.maven&lt;/pluginGroup&gt; &lt;/pluginGroups&gt; &lt;profiles&gt; #添加以下,地址视情况而定 &lt;profile&gt; &lt;id&gt;sonar&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;properties&gt; &lt;sonar.host.url&gt; http://192.168.x.xx:9000 &lt;/sonar.host.url&gt; &lt;/properties&gt; &lt;/profile&gt; 登录 jenkins 在maven项目中. BUild —&gt;Goals and optionsclean install修改为:clean install org.sonarsource.scanner.maven:sonar-maven-plugin:3.3.0.603:sonar 再次执行即可看到项目console输出日志中对代码的分析12345678910111213141516......[INFO] --- sonar-maven-plugin:3.3.0.603:sonar (default-cli) @ user ---......[INFO] Working dir: /root/.jenkins/workspace/XXXXXXXX[INFO] Source paths: src/main/webapp, pom.xml, src/main/java[INFO] Source encoding: UTF-8, default locale: zh_CN[INFO] Index files[INFO] 421 files indexed[INFO] Quality profile for java: Sonar way[INFO] Quality profile for js: Sonar way[INFO] Quality profile for xml: Sonar way[INFO] Sensor JavaSquidSensor [java]...... 方法二添加插件.jenkins安装插件SonarQube 这里需要额外安装sonar-scanner 这个软件,如果不想自己安装,则在全局工具配置 —&gt; SonarQube Scanner 勾选自动安装.并定义个名字 项目配置: Pre Steps —&gt; add pre build step选择JDKAnalysis properties 输入如下 123456789101112#自定义,唯一. 最好和项目一致,这样后续可调用变量通过邮件发送URLsonar.projectKey=JKSTACKsonar.projectName=JKSTACKsonar.projectVersion=1.0sonar.language=javasonar.scm.disabled=truesonar.sourceEncoding=UTF-8#相对于项目而言的目录sonar.sources=moni/src/main/javasonar.java.binaries=moni/target/classes 其他参考.1234567891011121314151617181920212223242526272829303132333435363738#required metadata#projectKey项目的唯一标识，不能重复sonar.projectKey=zzzzzsonar.projectName=zzzzz sonar.projectVersion=1.0 sonar.sourceEncoding=UTF-8sonar.modules=java-module,javascript-module,html-module# Java modulejava-module.sonar.projectName=Java Modulejava-module.sonar.language=java# .表示projectBaseDir指定的目录java-module.sonar.sources=.java-module.sonar.projectBaseDir=srcsonar.binaries=classes# JavaScript modulejavascript-module.sonar.projectName=JavaScript Modulejavascript-module.sonar.language=jsjavascript-module.sonar.sources=jsjavascript-module.sonar.projectBaseDir=webRoot# Html modulehtml-module.sonar.projectName=Html Modulehtml-module.sonar.language=webhtml-module.sonar.sources=pageshtml-module.sonar.projectBaseDir=webRootsonar.projectKey=org.codehaus.sonar:php-sonar-runner-unit-testssonar.projectName=PHP project analyzed with the SonarQube Runner reusing PHPUnit reportssonar.projectVersion=1.0sonar.sources=srcsonar.tests=testssonar.language=phpsonar.sourceEncoding=UTF-8# Reusing PHPUnit reportssonar.php.coverage.reportPath=reports/phpunit.coverage.xmlsonar.php.tests.reportPath=reports/phpunit.xml]]></content>
      <categories>
        <category>运维工具</category>
        <category>jenkins</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins-Publish Over SSH Plugin]]></title>
    <url>%2F2018%2F04%2F11%2Fjenkins-Publish-Over-SSH-Plugin%2F</url>
    <content type="text"><![CDATA[jenkins通过SSH部署项目到tomcat下 安装插件名就是Publish Over SSH 安装过程不赘述. 配置系统管理–&gt;系统配置–&gt;Publish Over SSH 说明:Passphrase ：密码（key的密码，未设置则空）Path to key：key私钥路径/root/.ssh/id_rsa - 这个key是要手动生的,命令`ssh-keygen -t rsa`这里会提示是否对key加密.也就是`Passphrase` - 免密设置`ssh-copy-id 192.168.xx.xx` Key：私钥内容复制到这里Disable exec：禁止运行命令, 不勾选 SSH Servers配置,有多台可以加多台 - SSH Server Name：标识的名字（随便取,建议IP） - Hostname：需要连接ssh的主机名或ip地址（建议ip） - Username：用户名 - Remote Directory：远程目录(后续有些相对目录的指定就是以此为基准的) - Use password authentication, or use a different (√) 私有配置的高级： - Port：端口（默认22） - Timeout (ms)：超时时间（毫秒）默认即可 - Disable exec：禁止运行命令 - Test Configuration：测试连接 至此,相关的基础配置已完毕. 使用点进一个maven项目构建环境处Build - Root POM : moni/pom.xml (pom文件是在项目根目录下,如果分支就一个项目则不需要写项目名) - Goals and options : clean install 在构建后操作选项点击增加构建后操作步骤,选择send build artifacts over SSH 会增加相关选项界面. SSH Publishers - SSH Server - NAME (选择刚刚配置的那个即可) - Transfers - Source files : moni/target/*.war(上传的文件,相对于工作区的路径,可写多个，默认用,分隔) - Remove prefix：moni/target/（只能指定Transfer Set Source files中的目录,不易出,web路径会变） - Remote directory：远程目录,这个是基于配置中的那个而言的相对路径 - Exec command：~/deploy.sh monitor 80 /usr/local/tomcat-7.0.85(也可直接写脚本内容,后会有个脚本参考,具体参数看根据项目而定) - 高级部分 - Exclude files：排除文件（传输目录的时候很有用，使用通配符，例如：**/*.log,**/*.tmp,.git/） 其他:略 脚本参考来自网友,稍加修改,出处不知.前提要在目标主机新建文件夹mkdir -p ~/war/bak然后将脚本scp到目标主机,具体位置,根据上一步中Exec command：~/deploy.sh monitor 80 /usr/local/tomcat-7.0.85 而定. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495#!/bin/bash#jenkins#jenkins需要做配置 send..ssh#Remote directory : tmp/ #这个相对路径取决于系统配置信息里面的ssh主机的 Remote Directory,建议tmp,因为备份在tmp #Exec command : ~/deploy.sh deploy cmdb $BUILD_NUMBER#tomcatt_home_bin=`find / -name catalina.sh`t_home=$&#123;t_home_bin%*/bin/*&#125;t_port=`cat $t_home/conf/server.xml | grep 'HTTP/1.1' | grep protocol | grep Connector |awk '&#123;print $2&#125;' | tr -cd "[0-9]"`#exportsource /etc/profilesource $HOME/.bashrc#how to use#./deploy.sh &lt;projectname&gt; [tomcat port] [tomcat home dir] $BUILD_NUMBER#default varACTION="$1"PROJECT="$2"TOMCAT_PORT=$t_portTOMCAT_HOME=$t_homeVERSION="$3"#dir exist?if [ ! -d "/tmp/war/bak/" ];thenmkdir -p /tmp/war/bak/fi#args numif [ $# -lt 3 ]; then echo "you must use like this : ./deploy.sh &lt;action&gt; &lt;projectname&gt; &lt;version&gt;" exitfi#search tomcatpid#tomcat_pid=`netstat -anp | grep $TOMCAT_PORT | awk '&#123;printf $7&#125;' | cut -d "/" -f 1`tomcat_p=`netstat -anp | grep $TOMCAT_PORT | awk '&#123;printf $7&#125;' | cut -d "/" -f 1`tomcat_pid=$&#123;tomcat_p#*-&#125;echo "current :" $tomcat_pidwhile [ -n "$tomcat_pid" ]do sleep 5 #进一步筛选 tomcat_pid=`ps -ef | grep $tomcat_pid |grep $TOMCAT_HOME | grep -v 'grep\|tail\|more\|bash\|less'| awk '&#123;print $2&#125;'` echo "scan tomcat pid :" $tomcat_pid if [ -n "$tomcat_pid" ]; then echo "kill tomcat :" $tomcat_pid kill -9 $tomcat_pid fidone#path for bakdirBAK_DIR=/tmp/war/bak/$PROJECTif [ ! -d "$BAK_DIR" ];then mkdir -p $BAK_DIRfiif [ $ACTION == 'deploy' ];then cp /tmp/$PROJECT.war "$BAK_DIR"/"$PROJECT"_"$VERSION".war #publish project echo "+++++++++++++++++++++++++++++++++++++++++++++++++++" echo "scan no tomcat pid,$PROJECT publishing...." sleep 10 rm -rf "$TOMCAT_HOME"/webapps/$PROJECT rm -rf "$TOMCAT_HOME"/webapps/$PROJECT.war #this path is define by jenkins-after build-ssh-Remote directory mv /tmp/$PROJECT.war "$TOMCAT_HOME"/webapps/$PROJECT.warfiif [ $ACTION == 'rollback' ];then #delete project rm -rf "$TOMCAT_HOME"/webapps/$PROJECT rm -rf "$TOMCAT_HOME"/webapps/$PROJECT.war cp "$BAK_DIR"/"$PROJECT"_"$VERSION".war "$TOMCAT_HOME"/webapps/$PROJECT.war #publish project echo "+++++++++++++++++++++++++++++++++++++++++++++++++++" echo "rollback to the project $PROJECT $VERSION" echo "+++++++++++++++++++++++++++++++++++++++++++++++++++" sleep 3fi#start tomcat"$TOMCAT_HOME"/bin/startup.shecho "+++++++++++++++++++++++++++++++++++++++++++++++++++"echo "tomcat is starting,please try to access $PROJECT conslone url"#del warecho "+++++++++++++++++++++++++++++++++++++++++++++++++++"echo `date +%Y%m%d` "delete invalid war"find $BAK_DIR -mtime +7 -name "*.war";find $BAK_DIR -mtime +7 -name "*.war" -exec rm -rf &#123;&#125; \;echo "+++++++++++++++++++++++++++++++++++++++++++++++++++"echo "host address:" `/sbin/ifconfig -a|grep inet|grep -v 127.0.0.1|grep -v inet6 | awk '&#123;print $2&#125;' | tr -d "addr:"`echo "+++++++++++++++++++++++++++++++++++++++++++++++++++"]]></content>
      <categories>
        <category>运维工具</category>
        <category>jenkins</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql5.7源码安装]]></title>
    <url>%2F2018%2F03%2F26%2Fmysql5-7%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[源码安装mysql 5.7环境centos7 x86_64MySQL官网下载地址 选择源码下载的时候会有两个版本,其中一个版本带有Includes Boost Headers字段.暂不知区别,因为两个都需要安装Boost库.我选择的不带此字段的. boost 5.7.19下载地址 版本要求5.7+ 准备环境12345tar zxvf boost_1_59_0.tar.gzcp -r boost_1_59_0 /usr/local/boosttar zxvf mysql-boost-5.7.19.tar.gz cd mysql-5.7.19/ 安装常用组件和依赖yum -y install gcc gcc-c++ ncurses ncurses-devel bison libgcrypt perl make cmake 创建用户12groupadd mysqluseradd mysql -r -g mysql #-r 系统用户, -g 指定所属组 安装新建安装目录mkdir -p /usr/local/mysqlmkdir /usr/local/mysql/{data,logs,pids} 设置目录权限chown -R mysql:mysql /usr/local/mysql 安装1234cmake . -DCMAKE_INSTALL_PREFIX=/usr/local/mysql -DMYSQL_DATADIR=/usr/local/mysql/data -DDEFAULT_CHARSET=utf8 -DDEFAULT_COLLATION=utf8_general_ci -DMYSQL_TCP_PORT=3306 -DMYSQL_USER=mysql -DWITH_MYISAM_STORAGE_ENGINE=1 -DWITH_INNOBASE_STORAGE_ENGINE=1 -DWITH_ARCHIVE_STORAGE_ENGINE=1 -DWITH_BLACKHOLE_STORAGE_ENGINE=1 -DWITH_MEMORY_STORAGE_ENGINE=1 -DENABLE_DOWNLOADS=1 -DDOWNLOAD_BOOST=1 -DWITH_BOOST=/usr/local/boostmakemake install mysql编译安装时间挺长,请耐心等待. 配置导入环境变量vim /etc/profile添加如下export PATH=/usr/local/mysql/bin:/usr/local/mysql/lib:$PATH 更新环境配置source /etc/profile 复制mysql服务123cd /usr/local/mysql/cp -a support-files/mysql.server /etc/init.d/mysqldchmod a+x /etc/init.d/mysqld 初始化DB–initialize 表示默认生成一个安全的密码–initialize-insecure 表示不生成密码 1mysqld --initialize-insecure --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data 开机启动mysqld123chkconfig --add mysqldchkconfig mysqld onchkconfig --list | grep mysqld #可查看mysqld是否为开机启动 my.cnfvim /etc/my.cnf参考如下123456789101112131415161718192021222324252627282930313233[mysqld]datadir=/usr/local/mysql/datasocket=/usr/local/mysql/mysql.sockcharacter-set-server=utf8max_connections=1000[mysqld_safe]log-error=/usr/local/mysql/logs/mysqld.logpid-file=/usr/local/mysql/pids/mysqld.pid# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0# Settings user and group are ignored when systemd is used.# If you need to run mysqld under a different user or group,# customize your systemd unit file for mariadb according to the# instructions in http://fedoraproject.org/wiki/Systemd[client]default-character-set=utf8socket=/usr/local/mysql/mysql.sock[mysql]default-character-set=utf8socket=/usr/local/mysql/mysql.sock## include all files from the config directory#!includedir /etc/my.cnf.d 详解my.cnf123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303# For advice on how to change settings please see# http://dev.mysql.com/doc/refman/5.7/en/server-configuration-defaults.html# *** DO NOT EDIT THIS FILE. It‘s a template which will be copied to the# *** default location during install, and will be replaced if you# *** upgrade to a newer version of MySQL.[mysqld]# Remove leading # and set to the amount of RAM for the most important data# cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%.# innodb_buffer_pool_size = 128M# Remove leading # to turn on a very important data integrity option: logging# changes to the binary log between backups.# log_bin# These are commonly set, remove the # and set as required.# basedir = .....# datadir = .....# port = .....# server_id = .....# socket = .....# Remove leading # to set options mainly useful for reporting servers.# The server defaults are faster for transactions and fast SELECTs.# Adjust sizes as needed, experiment to find the optimal values.# join_buffer_size = 128M# sort_buffer_size = 2M# read_rnd_buffer_size = 2M sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES 其实，这些项都是命令行的参数，在官网上可以从这个页面https://dev.mysql.com/doc/refman/5.7/en/option-files.html为入口，找到需要配置的项按需要进行配置。下面这个是来自http://www.fx114.net/qa-220-164752.aspx提供的my.cnf示例：[client]port = 3306socket = /tmp/mysql.sock[mysqld]###############################基础设置######################################Mysql服务的唯一编号 每个mysql服务Id需唯一server-id = 1#服务端口号 默认3306port = 3306#mysql安装根目录basedir = /opt/mysql#mysql数据文件所在位置datadir = /opt/mysql/data#临时目录 比如load data infile会用到tmpdir = /tmp#设置socke文件所在目录socket = /tmp/mysql.sock#主要用于MyISAM存储引擎,如果多台服务器连接一个数据库则建议注释下面内容skip-external-locking#只能用IP地址检查客户端的登录，不用主机名skip_name_resolve = 1#事务隔离级别，默认为可重复读，mysql默认可重复读级别（此级别下可能参数很多间隙锁，影响性能）transaction_isolation = READ-COMMITTED#数据库默认字符集,主流字符集支持一些特殊表情符号（特殊表情符占用4个字节）character-set-server = utf8mb4#数据库字符集对应一些排序等规则，注意要和character-set-server对应collation-server = utf8mb4_general_ci#设置client连接mysql时的字符集,防止乱码init_connect=‘SET NAMES utf8mb4‘#是否对sql语句大小写敏感，1表示不敏感lower_case_table_names = 1#最大连接数max_connections = 400#最大错误连接数max_connect_errors = 1000#TIMESTAMP如果没有显示声明NOT NULL，允许NULL值explicit_defaults_for_timestamp = true#SQL数据包发送的大小，如果有BLOB对象建议修改成1Gmax_allowed_packet = 128M#MySQL连接闲置超过一定时间后(单位：秒)将会被强行关闭#MySQL默认的wait_timeout 值为8个小时, interactive_timeout参数需要同时配置才能生效interactive_timeout = 1800wait_timeout = 1800#内部内存临时表的最大值 ，设置成128M。#比如大数据量的group by ,order by时可能用到临时表，#超过了这个值将写入磁盘，系统IO压力增大tmp_table_size = 134217728max_heap_table_size = 134217728#禁用mysql的缓存查询结果集功能#后期根据业务情况测试决定是否开启#大部分情况下关闭下面两项query_cache_size = 0query_cache_type = 0#####################用户进程分配到的内存设置BEGIN###############################每个session将会分配参数设置的内存大小#用于表的顺序扫描，读出的数据暂存于read_buffer_size中，当buff满时或读完，将数据返回上层调用者#一般在128kb ~ 256kb,用于MyISAM#read_buffer_size = 131072#用于表的随机读取，当按照一个非索引字段排序读取时会用到，#一般在128kb ~ 256kb,用于MyISAM#read_rnd_buffer_size = 262144#order by或group by时用到#建议先调整为2M，后期观察调整sort_buffer_size = 2097152#一般数据库中没什么大的事务，设成1~2M，默认32kbbinlog_cache_size = 524288########################用户进程分配到的内存设置END#############################在MySQL暂时停止响应新请求之前的短时间内多少个请求可以被存在堆栈中#官方建议back_log = 50 + (max_connections / 5),封顶数为900back_log = 130############################日志设置###########################################数据库错误日志文件log_error = error.log#慢查询sql日志设置slow_query_log = 1slow_query_log_file = slow.log#检查未使用到索引的sqllog_queries_not_using_indexes = 1#针对log_queries_not_using_indexes开启后，记录慢sql的频次、每分钟记录的条数log_throttle_queries_not_using_indexes = 5#作为从库时生效,从库复制中如何有慢sql也将被记录log_slow_slave_statements = 1#慢查询执行的秒数，必须达到此值可被记录long_query_time = 8#检索的行数必须达到此值才可被记为慢查询min_examined_row_limit = 100#mysql binlog日志文件保存的过期时间，过期后自动删除expire_logs_days = 5############################主从复制设置######################################开启mysql binlog功能log-bin=mysql-bin#binlog记录内容的方式，记录被操作的每一行binlog_format = ROW#对于binlog_format = ROW模式时，减少记录日志的内容，只记录受影响的列binlog_row_image = minimal#master status and connection information输出到表mysql.slave_master_info中master_info_repository = TABLE#the slave‘s position in the relay logs输出到表mysql.slave_relay_log_info中relay_log_info_repository = TABLE#作为从库时生效,想进行级联复制，则需要此参数log_slave_updates#作为从库时生效,中继日志relay-log可以自我修复relay_log_recovery = 1#作为从库时生效,主从复制时忽略的错误slave_skip_errors = ddl_exist_errors#####################redo log和binlog的关系设置BEGIN##########################(步骤1) prepare dml相关的SQL操作，然后将redo log buff中的缓存持久化到磁盘#(步骤2)如果前面prepare成功，那么再继续将事务日志持久化到binlog#(步骤3)如果前面成功，那么在redo log里面写上一个commit记录#当innodb_flush_log_at_trx_commit和sync_binlog都为1时是最安全的，#在mysqld服务崩溃或者服务器主机crash的情况下，binary log只有可能丢失最多一个语句或者一个事务。#但是都设置为1时会导致频繁的io操作，因此该模式也是最慢的一种方式。#当innodb_flush_log_at_trx_commit设置为0，mysqld进程的崩溃会导致上一秒钟所有事务数据的丢失。#当innodb_flush_log_at_trx_commit设置为2，只有在操作系统崩溃或者系统掉电的情况下，上一秒钟所有事务数据才可能丢失。#commit事务时,控制redo log buff持久化磁盘的模式 默认为1innodb_flush_log_at_trx_commit = 2#commit事务时,控制写入mysql binlog日志的模式 默认为0#innodb_flush_log_at_trx_commit和sync_binlog都为1时，mysql最为安全但性能上压力也是最大sync_binlog = 1####################redo log和binlog的关系设置END########################################################Innodb设置######################################数据块的单位8k，默认是16k，16kCPU压力稍小，8k对select的吞吐量大#innodb_page_size的参数值也影响最大索引长度，8k比16k的最大索引长度小#innodb_page_size = 8192#一般设置物理存储的60% ~ 70%innodb_buffer_pool_size = 1G#5.7.6之后默认16M#innodb_log_buffer_size = 16777216#该参数针对unix、linux，window上直接注释该参数.默认值为NULL#O_DIRECT减少操作系统级别VFS的缓存和Innodb本身的buffer缓存之间的冲突innodb_flush_method = O_DIRECT#此格式支持压缩, 5.7.7之后为默认值innodb_file_format = Barracuda#CPU多核处理能力设置，假设CPU是2颗4核的，设置如下#读多，写少可以设成2:6的比例innodb_write_io_threads = 4innodb_read_io_threads = 4#提高刷新脏页数量和合并插入数量，改善磁盘I/O处理能力#默认值200（单位：页）#可根据磁盘近期的IOPS确定该值innodb_io_capacity = 500#为了获取被锁定的资源最大等待时间，默认50秒，超过该时间会报如下错误:# ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transactioninnodb_lock_wait_timeout = 30#调整buffer pool中最近使用的页读取并dump的百分比,通过设置该参数可以减少转储的page数innodb_buffer_pool_dump_pct = 40#设置redoLog文件所在目录, redoLog记录事务具体操作内容innodb_log_group_home_dir = /opt/mysql/redolog/#设置undoLog文件所在目录, undoLog用于事务回滚操作innodb_undo_directory = /opt/mysql/undolog/#在innodb_log_group_home_dir中的redoLog文件数, redoLog文件内容是循环覆盖写入。innodb_log_files_in_group = 3#MySql5.7官方建议尽量设置的大些，可以接近innodb_buffer_pool_size的大小#之前设置该值较大时可能导致mysql宕机恢复时间过长，现在恢复已经加快很多了#该值减少脏数据刷新到磁盘的频次#最大值innodb_log_file_size * innodb_log_files_in_group &lt;= 512GB,单文件&lt;=256GBinnodb_log_file_size = 1024M#设置undoLog文件所占空间可以回收#5.7之前的MySql的undoLog文件一直增大无法回收innodb_undo_log_truncate = 1innodb_undo_tablespaces = 3innodb_undo_logs = 128#5.7.7默认开启该参数 控制单列索引长度最大达到3072#innodb_large_prefix = 1#5.7.8默认为4个, Inodb后台清理工作的线程数#innodb_purge_threads = 4#通过设置配置参数innodb_thread_concurrency来限制并发线程的数量，#一旦执行线程的数量达到这个限制，额外的线程在被放置到对队列中之前，会睡眠数微秒，#可以通过设定参数innodb_thread_sleep_delay来配置睡眠时间#该值默认为0,在官方doc上，对于innodb_thread_concurrency的使用，也给出了一些建议:#(1)如果一个工作负载中，并发用户线程的数量小于64，建议设置innodb_thread_concurrency=0；#(2)如果工作负载一直较为严重甚至偶尔达到顶峰，建议先设置innodb_thread_concurrency=128,###并通过不断的降低这个参数，96, 80, 64等等，直到发现能够提供最佳性能的线程数#innodb_thread_concurrency = 0#强所有发生的死锁错误信息记录到error.log中，之前通过命令行只能查看最近一次死锁信息innodb_print_all_deadlocks = 1############################其他设置########################################[mysqldump]quickmax_allowed_packet = 128M[mysql]no-auto-rehash[myisamchk]key_buffer_size = 20Msort_buffer_size = 256kread_buffer = 2Mwrite_buffer = 2M[mysqlhotcopy]interactive-timeout[mysqld_safe]#增加每个进程的可打开文件数量open-files-limit = 28192 启动服务文件创建根据自己配置而定.12touch /usr/local/mysql/logs/mysqld.logtouch /usr/local/mysql/pids/mysqld.pid 文件权限修改.chown -R mysql:mysql /usr/local/mysql 启动service mysqld start 或 /etc/init.d/mysqld start 查看运行状态service mysqld status 或 /etc/init.d/mysqld status 连接数据库mysql -u root #默认root为空密码.直接回车即可use mysql #切到mysql表查看用户信息,5.7取消了password,换成了authentication_stringselect host,user,authentication_string from user; 设置root密码UPDATE user SET authentication_string=PASSWORD(&#39;newpassword&#39;) WHERE user=&#39;root&#39;;flush privileges; reboot重启]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[haproxy-Exchange]]></title>
    <url>%2F2018%2F03%2F21%2Fhaproxy-Exchange%2F</url>
    <content type="text"><![CDATA[使用haproxy负载exchange,可搭配keepalive做高可用 keepalive 建议阅读 exchange负载官方文档 下载下载地址 安装解压并cdmake TARGET=linux2628 ARCH=x86_64 PREFIX=/usr/local/haproxymake install PREFIX=/usr/local/haproxy 复制启动脚本到sbincp /usr/local/haproxy/sbin/haproxy /usr/sbin/ 复制启动脚本到init.dcp ./examples/haproxy.init /etc/init.d/haproxychmod 755 /etc/init.d/haproxy 创建haproxy账号useradd -r haproxy配置文件可指定进程用户 haproxy配置文件mkdir /etc/haproxyvim /etc/haproxy/haproxy.cfg负载exchange配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192defaults log 127.0.0.1 local3 info #配合rsyslog option dontlognull option redispatch option contstats retries 3 timeout connect 5s timeout http-keep-alive 1s timeout http-request 15s timeout queue 30s timeout tarpit 1m backlog 10000 balance roundrobin mode tcp option tcplog log global timeout client 300s timeout server 300s default-server inter 3s rise 2 fall 3frontend ft_exchange_HTTP bind 10.0.2.32:80 name web maxconn 10000 default_backend bk_exchange_HTTPbackend bk_exchange_HTTP server mail01 10.0.2.51:80 maxconn 10000 check server mail02 10.0.2.52:80 maxconn 10000 check backupfrontend ft_exchange_SSL bind 10.0.2.32:443 name ssl maxconn 10000 default_backend bk_exchange_SSLbackend bk_exchange_SSL server mail01 10.0.2.51:443 maxconn 10000 check server mail02 10.0.2.52:443 maxconn 10000 check backupfrontend ft_exchange_SMTP bind 10.0.2.32:25 name smtp maxconn 10000 default_backend bk_exchange_SMTPbackend bk_exchange_SMTP server mail01 10.0.2.51:25 maxconn 10000 check server mail02 10.0.2.52:25 maxconn 10000 check backupfrontend ft_exchange_SMTP_Secure bind 10.0.2.32:587 name smtpssl maxconn 10000 default_backend bk_exchange_SMTP_Securebackend bk_exchange_SMTP_Secure server mail01 10.0.2.51:587 maxconn 10000 check server mail02 10.0.2.52:587 maxconn 10000 check backupfrontend ft_exchange_IMAP bind 10.0.2.32:143 name imap maxconn 10000 default_backend bk_exchange_IMAPbackend bk_exchange_IMAP server mail01 10.0.2.51:143 maxconn 10000 check server mail02 10.0.2.52:143 maxconn 10000 check backupfrontend ft_exchange_IMAP_Secure bind 10.0.2.32:993 name imapssl maxconn 10000 default_backend bk_exchange_IMAP_Securebackend bk_exchange_IMAP_Secure server mail01 10.0.2.51:993 maxconn 10000 check server mail02 10.0.2.52:993 maxconn 10000 check backupfrontend ft_exchange_POP3 bind 10.0.2.32:110 name pop3 maxconn 10000 default_backend bk_exchange_POP3backend bk_exchange_POP3 server mail01 10.0.2.51:110 maxconn 10000 check server mail02 10.0.2.52:110 maxconn 10000 check backupfrontend ft_exchange_POP3_Secure bind 10.0.2.32:995 name pop3ssl maxconn 10000 default_backend bk_exchange_POP3_Securebackend bk_exchange_POP3_Secure server mail01 10.0.2.51:995 maxconn 10000 check server mail02 10.0.2.52:995 maxconn 10000 check backup 开启日志vim /etc/rsyslog.conf 123456#去掉注释$ModLoad imudp$UDPServerRun 514#添加如下local3.* /var/log/haproxy.log 启动服务systemctl restart rsyslog / haproxyservice rsyslog restart / haproxy]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>haproxy</tag>
        <tag>exchange</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix snmp trap]]></title>
    <url>%2F2018%2F03%2F18%2Fzabbix-snmp-trap%2F</url>
    <content type="text"><![CDATA[了解snmp trap之前,先了解snmp以及MIB.snmp trap 是 SNMP 的一部分,简单来说就是被管理设备主动发送消息给管理设备. zabbix开启 snmp trap 比较简单,官方提供了perl脚本.官方文档 获取脚本前置条件,也可源码安装,按个人喜好yum install -y net-snmp-utils net-snmp-perl net-snmp 下载源码下载地址解压tar -zxvf zabbix-VERSION.tar.gz复制脚本并给予权限12cp ./zabbix-VERSION/misc/snmptrap/zabbix_trap_receiver.pl /usr/binchmod +x /usr/bin/zabbix_trap_receiver.pl 配置trapvi /etc/snmp/snmptrapd.conf修改配置如下12authCommunity execute publicperl do &quot;/usr/bin/zabbix_trap_receiver.pl&quot;; 开启server的trapper功能vi /etc/zabbix/zabbix_server.conf修改配置如下123StartSNMPTrapper=1SNMPTrapperFile=/tmp/zabbix_traps.tmp #此路径和脚本中的要一致,否则server无法读取发送过来的信息 重启服务/etc/init.d/zabbix-server restart 添加mib库默认情况下snmp内置了一下mib库文件/usr/share/snmp/mibs如果有需要可添加第三方mib文件到此目录下.并新建/etc/snmp/snmp.conf添加mib库信息,格式如下12#mibs +库名mibs +JUNIPER-MIB:JUNIPER-FABRIC-CHASSIS:BGP4-MIB 启动centos7systemctl enable snmptrapdsystemctl restart snmptrapd.service小记:snmptrapd -C -c /etc/snmp/snmptrapd.conf 指定配置文件启动 web使用现在就可以在web端进行操作了.添加开启了snmptrap的主机即可 创建监控项目可以针对单个主机,也可创建模板然后关联主机. 名称: 自定义 类型: snmp trap key: snmptrap.fallback(表示所有没有被正则匹配到的,都会到这个下面) 123456官网有明显的解释以及案例比如新建个监控项 名称为 :Name: Unmatched SNMP trap received from &#123;HOST.NAME&#125; key为 : snmptrap.fallback那么表达式就可以写成 类似 &#123;snmptrap.fallback.nodata(300)&#125;=0表示五分钟没有数据就触发告警 信息类型: 日志主要就这几点. 重点讲下这个key 除了snmptrap.fallback,还有snmptrap[regexp]这个支持正则匹配,由于监控的是日志,获取的也是所有的日志信息,所有要取想要的值就要进行正则匹配.给出官网例子,便于理解12345678910111213Example 1Key: snmptrap[&quot;SNMPv2-MIB::coldStart&quot;]Instead of OID (numeric or textual), you can use any word / phrase from a trap text:Key: snmptrap[&quot;No route to host&quot;]in this case, Zabbix catches all SNMP traps from a corresponding address that contains &quot;No route to host&quot;.Note that you can create item for each trap (example above) or a single item for multiple traps.-------------------------Example 2Key: snmptrap[&quot;cpqRackPowerSubsystem(NotRedundant|LineVoltageProblem|OverloadCondition)&quot;]in this case, Zabbix catches all SNMP traps from a corresponding address that contains &quot;cpqRackPowerSubsystemNotRedundant&quot; or &quot;cpqRackPowerSubsystemLineVoltageProblem&quot; or &quot;cpqRackPowerSubsystemOverloadCondition&quot;. 其实就是说,可以进行正则匹配,匹配到,server就会捕获相应的snmp trap信息.感觉上就像是个日志监控 再给个官网例子1234Name: Link status trap for &#123;#SNMPVALUE&#125;Type: SNMP trapKey: snmptrap[&quot;(IF-MIB::linkDown|IF-MIB::linkUp)(.|[[:space:]])*&#123;#SNMPVALUE&#125;&quot;]Type of information: Log 可以看出,这个key就是去匹配链路的up/down的.也给出了触发器的表达式12Name: Interface &#123;#SNMPVALUE&#125; on &#123;HOST.NAME&#125; is down Expression: &#123;Template SNMP Interfaces:snmptrap[&quot;(IF-MIB::linkDown|IF-MIB::linkUp)(.|[[:space:]])*&#123;#SNMPVALUE&#125;&quot;].str(linkDown)&#125;=1 可以看出,匹配到了linkDown 就返回1 然后触发告警.str返回两个结果,1和0 1代匹配,0表示未匹配 整个流程大体就是这样,具体的监控项还是要熟悉mib,然后来定义.]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内网仓库搭建]]></title>
    <url>%2F2018%2F03%2F18%2F%E5%86%85%E7%BD%91%E4%BB%93%E5%BA%93%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[应对服务器不能去外网的情况 不同版本的系统,配置等都不一样,过程无二 yum通过iso将对应系统iso挂载到系统(vmware去配置中添加CD) 创建mount文件路径并将CD挂载到系统mkdir /mnt/yum-isomount /dev/cdrom /mnt/yum-iso/ 创建目录,并将iso复制到系统,用来制作yum源mkdir /yum cp -a /mnt/yum-iso/ /yum/ 备份原有的yum仓库配置cd /etc/yum.repos.d/mkdir bkmv *.repo bk/ 创建本地yum仓库配置 vi local-iso.repo123456[centos7-iso]name=CentOS-$releasever - Mediabaseurl=file:///yum/yum-iso/gpgcheck=0enabled=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7 清理缓存,制作本地缓存yum clean allyum makecaches 自定义yum源安装软件yum -y install createrepo 创建yum源文件目录mkdir -p /yum/yum-custom/packages将搜集的源放置相应目录cp 源文件 /yum/yum-custom/packages/创建repo,会生成repodata目录createrepo -u -d /yum/yum-custom/配置repocd /etc/yum.repos.d/vi local.repo123456[centos7-custom]name=CentOS-$releasever - Mediabaseurl=file:///yum/yum-custom/gpgcheck=0enabled=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7 清理缓存,制作本地缓存yum clean allyum makecaches 局域网yum源搭建ftp服务器yum -y install vsftpd配置ftpvi /etc/vsftpd/vsftpd.conf anon_root=/yum/(yum目录权限drwxr-xr-x)启动ftpsystemctl start vsftpd systemctl enable vsftpd 其他主机使用此仓库,添加仓库配置文件 vim /etc/yum.repos.d/local-ftp.repo 123456[centos7-ftp]name=CentOS-$releasever - Mediabaseurl=ftp://192.168.1.96/yum-customgpgcheck=0enabled=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7 apt-get等后续 镜像yum主要是导入公网yum制作本地仓库 通过同步科大开源镜像到本地,制作局域网仓库 注:镜像源的选择有很多,前提其支持rsync. 安装同步工具 yum -y install rsync搭建服务器 yum -y install httpd - web服务器的选择有很多,apache,nginx,ftp等等 编辑同步脚本,注意本地路径和远程一致,方便后续repo文件的书写,其分类很清晰写个定时任务,闲时同步即可12345678910111213141516#!/usr/bin/bash#centos7 x86_64rsync -av rsync://mirrors.ustc.edu.cn/centos/7/os/x86_64/Packages/ /var/www/html/centos/7/os/x86_64/Packages/ &gt; /var/www/html/log/os7p.log 2&gt;&amp;1rsync -av rsync://mirrors.ustc.edu.cn/centos/7/os/x86_64/repodata/ /var/www/html/centos/7/os/x86_64/repodata/ &gt; /var/www/html/log/os7r.log 2&gt;&amp;1rsync -av rsync://mirrors.ustc.edu.cn/centos/7/extras/x86_64/Packages/ /var/www/html/centos/7/extras/x86_64/Packages/ &gt; /var/www/html/log/ex7p.log 2&gt;&amp;1rsync -av rsync://mirrors.ustc.edu.cn/centos/7/extras/x86_64/repodata/ /var/www/html/centos/7/extras/x86_64/repodata/ &gt; /var/www/html/log/ex7r.log 2&gt;&amp;1rsync -av rsync://mirrors.ustc.edu.cn/centos/7/updates/x86_64/Packages/ /var/www/html/centos/7/updates/x86_64/Packages/ &gt; /var/www/html/log/up7p.log 2&gt;&amp;1rsync -av rsync://mirrors.ustc.edu.cn/centos/7/updates/x86_64/repodata/ /var/www/html/centos/7/updates/x86_64/repodata/ &gt; /var/www/html/log/up7r.log 2&gt;&amp;1#centos6 x86_64rsync -av rsync://mirrors.ustc.edu.cn/centos/6/os/x86_64/Packages/ /var/www/html/centos/6/os/x86_64/Packages/ &gt; /var/www/html/log/os6p.log 2&gt;&amp;1rsync -av rsync://mirrors.ustc.edu.cn/centos/6/os/x86_64/repodata/ /var/www/html/centos/6/os/x86_64/repodata/ &gt; /var/www/html/log/os6r.log 2&gt;&amp;1rsync -av rsync://mirrors.ustc.edu.cn/centos/6/extras/x86_64/Packages/ /var/www/html/centos/6/extras/x86_64/Packages/ &gt; /var/www/html/log/ex6p.log 2&gt;&amp;1rsync -av rsync://mirrors.ustc.edu.cn/centos/6/extras/x86_64/repodata/ /var/www/html/centos/6/extras/x86_64/repodata/ &gt; /var/www/html/log/ex6r.log 2&gt;&amp;1rsync -av rsync://mirrors.ustc.edu.cn/centos/6/updates/x86_64/Packages/ /var/www/html/centos/6/updates/x86_64/Packages/ &gt; /var/www/html/log/up6p.log 2&gt;&amp;1rsync -av rsync://mirrors.ustc.edu.cn/centos/6/updates/x86_64/repodata/ /var/www/html/centos/6/updates/x86_64/repodata/ &gt; /var/www/html/log/up6r.log 2&gt;&amp;1 我只同步了三个主要的包,不到30G.(同步前注意自己的磁盘空间) 编辑jk.repo文件.(网址为服务器网址) 12345678910111213141516[base]name=CentOS-$releasever - Base - jkbaseurl=http://192.168.1.96/centos/$releasever/os/$basearch/gpgcheck=0#released updates[updates]name=CentOS-$releasever - Updates - jkbaseurl=http://192.168.1.96/centos/$releasever/updates/$basearch/gpgcheck=0#additional packages that may be useful[extras]name=CentOS-$releasever - Extras - jkbaseurl=httpd://192.168.1.96/centos/$releasever/extras/$basearch/gpgcheck=0]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>yum</tag>
        <tag>apt-get</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nexus]]></title>
    <url>%2F2018%2F03%2F15%2Fnexus%2F</url>
    <content type="text"><![CDATA[nexus官网下载地址 2.4 Nexus介绍maven的仓库只有两大类：1.本地仓库 2.远程仓库，在远程仓库中又分成了3种： 安装java并配置相关java环境变量123456#java1.8export RUN_AS_USER=rootexport JAVA_HOME=/usr/local/jdk1.8.0_45export CLASS_HOME=/usr/local/jdk1.8.0_45/lib:$JAVA_HOME/jre/libexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib:$CLASSPATHexport PATH=$PATH:$JAVA_HOME/bin 启动PATH/bin/nexus start/stop/run(有日志输出) 开机启动ln -s PATH/bin/nexus /etc/init.d/nexuschkconfig nexus onchkconfig –list nexus 检查 访问默认url: ip:8081/nexus账号: admin密码: admin123 仓库介绍1 中央仓库2 私服3 其它公共库。 私服是一种特殊的远程仓库，它是架设在局域网内的仓库服务，私服代理广域网上的远程仓库，供局域网内的Maven用户使用。当Maven需要下载构件的时候，它从私服请求，如果私服上不存在该构件，则从外部的远程仓库下载，缓存在私服上之后，再为Maven的下载请求提供服务。我们还可以把一些无法从外部仓库下载到的构件上传到私服上。 Nexus 的仓库分为这么几类： hosted 宿主仓库：主要用于部署无法从公共仓库获取的构件（如 oracle 的 JDBC 驱动）以及自己或第三方的项目构件； proxy 代理仓库：代理公共的远程仓库； virtual 虚拟仓库：用于适配 Maven 1； group 仓库组：Nexus 通过仓库组的概念统一管理多个仓库，这样我们在项目中直接请求仓库组即可请求到仓库组管理的多个仓库。 component介绍123456789101112component name的一些说明：- maven-central：maven中央库，默认从https://repo1.maven.org/maven2/拉取jar- maven-releases：私库发行版jar- maven-snapshots：私库快照（调试版本）jar- maven-public：仓库分组，把上面三个仓库组合在一起对外提供服务，在本地maven基础配置settings.xml中使用。component type的一些说明：- hosted：类型的仓库，内部项目的发布仓库- releases：内部的模块中release模块的发布仓库- snapshots：发布内部的SNAPSHOT模块的仓库- 3rd party：第三方依赖的仓库，这个数据通常是由内部人员自行下载之后发布上去- proxy：类型的仓库，从远程中央仓库中寻找数据的仓库 上传jar包配置setting12345&lt;server&gt; &lt;id&gt;jk_jar&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt;&lt;password&gt;123xxxxx&lt;/password&gt; &lt;/server&gt; 12345678910mvn deploy:deploy-file -DgroupId=com.jingkunsystem -DartifactId=zabbix4j -Dversion=0.1.2 -Dpackaging=jar -Dfile=/jk_jar/zabbix4j-0.1.2.jar -Durl=http://192.168.1.111:8081/repository/jk_jar/ -DrepositoryId=jk_jarDgroupId和DartifactId构成了该jar包在pom.xml的坐标，项目就是依靠这两个属性定位。自己起名字也行。Dfile表示需要上传的jar包的绝对路径。Durl私服上仓库的位置，打开nexus——&gt;repositories菜单，可以看到该路径。DrepositoryId服务器的表示id，在nexus的configuration可以看到。Dversion表示版本信息解压该包，会发现一个叫MANIFEST.MF的文件，这个文件就有描述该包的版本信息。比如Manifest-Version: 1.0可以知道该包的版本了。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>nexus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rpm打包]]></title>
    <url>%2F2018%2F02%2F28%2Frpm%E6%89%93%E5%8C%85%2F</url>
    <content type="text"><![CDATA[RPM（Redhat Package Manager）是用于Redhat、CentOS、Fedora等Linux 分发版（distribution）的常见的软件包管理器。因为它允许分发已编译的软件，所以用户只用一个命令就可以安装软件. 安装12yum install rpm-buildyum install rpmdevtools 使用rpmdev-setuptree命令,可在$HOme下生产一个标注的工作空间’rpmbuild’结构如下1234567$ tree rpmbuildrpmbuild├── BUILD├── RPMS├── SOURCES├── SPECS└── SRPMS 如果未安装rpmdevtools 手动创建也是可以的mkdir -p ~/rpmbuild/{BUILD,RPMS,SOURCES,SPECS,SRPMS} 目录 目录名 说明 macros中的宏名 ~/rpmbuild/ rpmbuild文件夹 %_topdir ~/rpmbuild/BUILD 编译rpm包的临时目录 %_builddir ~/rpmbuild/BUILDROOT 编译后生成的软件临时安装目录 %_buildrootdir ~/rpmbuild/RPMS 最终生成的可安装rpm包的所在目录 %_rpmdir ~/rpmbuild/SOURCES 所有源代码和补丁文件的存放目录 %_sourcedir ~/rpmbuild/SPECS 存放SPEC文件的目录(重要) %_specdir ~/rpmbuild/SRPMS 软件最终的rpm源码格式存放路径(暂时忽略掉，别挂在心上) %_srcrpmdir 流程 源代码放在%_sourcedir下,一般是.tar.gz之类,或文件 编译,在%_builddir中进行,源码包解压后复制到此目录即可 安装,把软件包应该包含的内容（比如二进制文件、配置文件、man文档等）复制到%_buildrootdir中，并按照实际安装后的目录结构组装，比如二进制命令可能会放在/usr/bin下，那么就在%_buildrootdir下也按照同样的目录结构放置 配置,安装前,中,后,的一些工作,以及卸载前的工作. 检测,软件是否正常运行. 可选 生成rpm包,放到%_rpmdir下 以上流程均是通过编写SPEC文件进行操作. 阶段 读取的目录 写入的目录 具体动作 %prep %_sourcedir %_builddir 读取位于 %_sourcedir 目录的源代码和 patch 。之后，解压源代码至 %_builddir 的子目录并应用所有 patch %build %_builddir %_builddir 编译位于 %_builddir 构建目录下的文件。通过执行类似 ./configure &amp;&amp; make 的命令实现 %install %_builddir %_buildrootdir 读取位于 %_builddir 构建目录下的文件并将其安装至 %_buildrootdir 目录。这些文件就是用户安装 RPM 后，最终得到的文件。注意一个奇怪的地方: 最终安装目录 不是 构建目录。通过执行类似 make install 的命令实现 %check %_builddir %_builddir 检查软件是否正常运行。通过执行类似 make test 的命令实现。很多软件包都不需要此步。 bin %_buildrootdir %_rpmdir 读取位于 %_buildrootdir 最终安装目录下的文件，以便最终在 %_rpmdir 目录下创建 RPM 包。在该目录下，不同架构的 RPM 包会分别保存至不同子目录， noarch 目录保存适用于所有架构的 RPM 包。这些 RPM 文件就是用户最终安装的 RPM 包。 src %_sourcedir %_srcrpmdir 创建源码 RPM 包（简称 SRPM，以.src.rpm 作为后缀名），并保存至 %_srcrpmdir 目录。SRPM 包通常用于审核和升级软件包。 SPECzabbix agentd rpm包构建参考123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115%define zabbix_user zabbix #自定义宏，名字为zabbix_user值为zabbix,%&#123;zabbix_user&#125;引用Name: zabbix #软件包的名字，后面可用%&#123;name&#125;引用Version: 3.0.14 #软件的实际版本号，可使用%&#123;version&#125;引用Release: 1%&#123;?dist&#125; #发布序列号，标明第几次打包 Summary: zabbix_agentd #软件包内容概要Group: zabbix #软件包分组License: GPL#授权许可方式URL: blog.dl1548.com#软件的主页#源代码包，可以有Source0,Source1等源,对应%install下Source0: zabbix-3.0.14.tar.gzSource1: discover_disk.plSource2: tcp_conn_status.shSource3: zbx_parse_iostat_values.shSource4: tcp-status-params.confSource5: zbx_parse_iostat_values.confBuildRequires: net-tools#gcc, gcc-c++ #制作rpm包时，所依赖的基本库Requires: net-tools#gcc, gcc-c++ #安装rpm包时，所依赖的软件包#BuildRoot: %&#123;_tmpdir&#125;/%&#123;name&#125;-%&#123;version&#125;-%&#123;release&#125;#构建包的临时文件路径.centos5 不写会报错%description #定义rpm包的描述信息Zabbix agentdcreata by jingkunsystem-lizili%pre #rpm包安装前执行的脚本grep zabbix /etc/passwd &gt; /dev/nullif [ $? != 0 ] then useradd zabbix -M -s /sbin/nologinfi[ -d /usr/local/zabbix ]||rm -rf /usr/local/zabbix*rm -rf /etc/zabbix*%post #rpm包安装后执行的脚本sed -i &quot;/BASEDIR=\/usr\/local/c\BASEDIR=\/usr\/local\/%&#123;name&#125;&quot; /etc/init.d/zabbix_agentd%preun #rpm卸载前执行的脚本/etc/init.d/zabbix_agentd stop%postun #rpm卸载后执行的脚本userdel zabbixrm -rf /usr/local/zabbix*%prep%setup -q %build #定义编译软件包时的操作./configure --prefix=/usr/local/%&#123;name&#125; --enable-agentmake -j8 %&#123;?_smp_mflags&#125;%install #定义安装软件包，使用默认值即可test -L %&#123;buildroot&#125;/usr/local/%&#123;name&#125; &amp;&amp; rm -f %&#123;buildroot&#125;/usr/local/%&#123;name&#125;install -d %&#123;buildroot&#125;/etc/profile.dinstall -d %&#123;buildroot&#125;/etc/init.dmake install DESTDIR=%&#123;buildroot&#125;#其他脚本install -p -D -m 0755 %&#123;SOURCE1&#125; %&#123;buildroot&#125;/usr/local/%&#123;name&#125;/lib/discover_disk.plinstall -p -D -m 0755 %&#123;SOURCE2&#125; %&#123;buildroot&#125;/usr/local/%&#123;name&#125;/lib/tcp_conn_status.shinstall -p -D -m 0755 %&#123;SOURCE3&#125; %&#123;buildroot&#125;/usr/local/%&#123;name&#125;/lib/zbx_parse_iostat_values.sh#其他配置文件install -p -D -m 0755 %&#123;SOURCE4&#125; %&#123;buildroot&#125;/usr/local/%&#123;name&#125;/etc/zabbix_agentd.conf.d/tcp-status-params.confinstall -p -D -m 0755 %&#123;SOURCE5&#125; %&#123;buildroot&#125;/usr/local/%&#123;name&#125;/etc/zabbix_agentd.conf.d/zbx_parse_iostat_values.confecho &apos;export PATH=/etc/zabbix/bin:/etc/zabbix/sbin:$PATH&apos; &gt;&gt; %&#123;buildroot&#125;/etc/profile.d/%&#123;name&#125;.shcp %&#123;_builddir&#125;/%&#123;name&#125;-%&#123;version&#125;/misc/init.d/fedora/core/zabbix_agentd %&#123;buildroot&#125;/etc/init.d/zabbix_agentd%files%defattr (-,root,root,0755) #定义rpm包安装时创建的相关目录及文件#在该选项中%defattr (-,root,root)一定要注意。它是指定安装文件的属性，分别是(mode,owner,group)，-表示默认值，对文本文件是0644，可执行文件是0755。/usr/local/%&#123;name&#125;/*/usr/local/zabbix/lib/*/usr/local/zabbix/etc/zabbix_agentd.conf.d/*/etc/init.d/zabbix_agentd/etc/profile.d/%&#123;name&#125;.sh%changelog #主要用于软件的变更日志。该选项可有可无%clean rm -rf %&#123;buildroot&#125; #清理临时文件 打包在SPECS文件夹下执行.rpmbuild -bb xxx.spec即可 1234567-ba 既生成src.rpm又生成二进制rpm -bs 只生成src的rpm -bb 只生二进制的rpm -bp 执行到pre -bc 执行到 build段 -bi 执行install段 -bl 检测有文件没包含 可以先rpmbuild -bp,再-bc 再-bi如果没问题rpmbuild -bb/ba生成二进制包或两个都生成 脚本参考(主要针对centos7 内核)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#/usr/bin/bash#ip= ip addr |grep inet |egrep -v &quot;inet6|127.0.0.1&quot; |awk &apos;&#123;print $2&#125;&apos; |awk -F &quot;/&quot; &apos;&#123;print $1&#125;&apos;# get server ipecho -e &quot;\n NOTICE! Check the package net-tools is installed \n &quot;read -p &quot;zabbix server ip：&quot; zabbix_serverif [ ! -n &quot;$zabbix_server&quot; ]; then echo &quot;you have not input server ip, exit&quot; exit 1fi# get agent ipread -p &quot;local ip: &quot; local_ipif [ ! -n &quot;$local_ip&quot; ]; then echo &quot;you have not input local ip, exit&quot; exit 1fiecho &quot;start to install...&quot;sleep 1#version centos7#cat /etc/*release | egrep -i &quot;centos|rhel|red hat|redhat&quot;echo &quot;check os version...&quot;sleep 1#version centos7cat /etc/*release | grep -q -i &quot;centos\|rhel\|red hat\|redhat&quot;if [[ $? -eq 0 ]];then cat /etc/*release | grep -q -i &quot;7\.&quot; if [[ $? -eq 0 ]];then sleep 1 rpm -ivh zabbix-3.0.14-1.el7.centos.x86_64.rpm echo &quot;modify the agentd configuration&quot; sleep 1 sed -i &quot;/^Server=/c\Server=$&#123;zabbix_server&#125;&quot; /usr/local/zabbix/etc/zabbix_agentd.conf sed -i &quot;/^ServerActive=/c\ServerActive=$&#123;zabbix_server&#125;&quot; /usr/local/zabbix/etc/zabbix_agentd.conf sed -i &quot;/^Hostname=/c\Hostname=$&#123;local_ip&#125;&quot; /usr/local/zabbix/etc/zabbix_agentd.conf sed -i &quot;/Timeout=3/c\Timeout=30&quot; /usr/local/zabbix/etc/zabbix_agentd.conf sed -i &quot;260i\Include=/usr/local/zabbix/etc/zabbix_agentd.conf.d/*.conf&quot; /usr/local/zabbix/etc/zabbix_agentd.conf systemctl daemon-reload /etc/init.d/zabbix_agentd start chkconfig zabbix_agentd on echo &quot;SUCCESSFUL !&quot; exit fifi]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>rpm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ldap-zbx单点登录]]></title>
    <url>%2F2018%2F01%2F21%2Fldapsearch%2F</url>
    <content type="text"><![CDATA[LDAP认证系统可再多系统间实现单点登录，免去多账户的烦恼。 由于zabbix要实现单点登录，因此而学习了下。zbx本身支持ldap认证，但要求zbx本身账户内用户存在并和LDAP用户名一致，所以要取出LDAP用户并插入zbx 配置官方描述zabbix管理–认证–LDAP，填写如下 描述 内容 LDAP主机(LDAP host) ldap://192.168.1.99 端口(Port) 389 基于DN(Base DN) DC=zbx,DC=comLDAP 搜索属性(Search attribute) sAMAccountName 绑定 DN(Bind DN) cn=Admin,ou=zabbix,dc=zbx,dc=com 绑定密码(Bind password) 不进行任何操作 测试认证(Test authentication) [必需为一个正确的LDAP用户] 登录(Login) 默认为当前登录用户 用户密码(User password) 当前用户密码 安装yum -y install openldap-clients 使用查找某用户信息 12345678910111213141516171819202122[root@zabbix ~]# ldapsearch -x -W -D &quot;cn=administrator,cn=users,dc=zbx,dc=com&quot; -b &quot;cn=administrator,cn=users,dc=zbx,dc=com&quot; -h 192.168.1.xxEnter LDAP Password: # extended LDIF## LDAPv3# base &lt;cn=administrator,cn=users,dc=zbx,dc=com&gt; with scope subtree# filter: (objectclass=*)# requesting: ALL## Administrator, Users, zbx.comdn: CN=Administrator,CN=Users,DC=zbx,DC=comobjectClass: topobjectClass: personobjectClass: organizationalPersonobjectClass: usercn: Administratordescription:: 566h55CG6K6h566X5py6KOWfnynnmoTlhoXnva7luJDmiLc=distinguishedName: CN=Administrator,CN=Users,DC=zbx,DC=cominstanceType: 4...... 查找ou下的用户信息123456[root@zabbix openldap]# ldapsearch -H ldap://192.168.1.xx -x -D &quot;cn=Admin,ou=zabbix,dc=zbx,dc=com&quot; -b &quot;ou=zabbix,dc=zbx,dc=com&quot; -W -LLL | grep sAMAccountName Enter LDAP Password: sAMAccountName: zabbix-groupsAMAccountName: test01sAMAccountName: Admin[root@zabbix openldap]# 脚本可自己编写脚本，执行相关命令，处理返回结果等。但是太过于繁杂。目前py有模块可用，python-ldap此次脚本测试为LDAP是MS的AD环境。安装模块环境：Debian/Ubuntu:sudo apt-get install libsasl2-dev python-dev libldap2-dev libssl-devRedHat/CentOS:yum -y install python-devel libevent-devel openldap-devel安装模块pip install gevent python-ldap 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[root@zabbix ~]# cat get_ldap.py #coding: utf-8import ldapclass LdapToZbx(): def __init__(self,ldap_url,domain_name,admin_user,admin_pwd): self.ldap_url = ldap_url self.domain_name = domain_name self.admin_user = admin_user self.admin_pwd = admin_pwd ldap_user = '%s@%s' %(admin_user,domain_name) self.con = ldap.initialize(ldap_url) #初始连接 self.con.protocol_version = ldap.VERSION3 #LDAP 版本 try: self.con.simple_bind_s(ldap_user,admin_pwd) except ldap.LDAPError,err: self.ldap_error = 'Connect to %s failed, Error:%s.' %(ldap_url,err.message['desc']) print self.ldap_error def get_ou_guid(self,baseDN): searchFilter = '(&amp;(objectClass=OrganizationalUnit))' results = self.con.search_s(baseDN,ldap.SCOPE_SUBTREE,searchFilter,['distinguishedName','objectGUID']) #return results for i in results: if i[0] == baseDN: return i[1]['objectGUID'] #SCOPE_BASE (基数：查询指定DN，也就是在DN中指定的那个，就只查这DN的) #SCOPE_ONELEVEL (一级：查询指定DN下的一级子目录，不会查子目录的子目录) #SCOPE_SUBTREE (子树：查询指定DN下的所有目录，包括指定DN) def search_ou_user(self,baseDN): user_list=[] searchFilter = '(&amp;(objectClass=person))' #只查找objectClass=person的 results = self.con.search_s(baseDN,ldap.SCOPE_SUBTREE,searchFilter) if results is not None: for person in results: username = person[1]['sAMAccountName'][0] user_list.append(username) return user_listif __name__ == "__main__": ldap_url = 'ldap://192.168.1.xx:389' domain_name = u'zbx.com' admin_user = u'administrator' admin_pwd = u'xxxxxxx' baseDN = u'ou=zabbix,dc=zbx,dc=com' ldap_user = LdapToZbx(ldap_url,domain_name,admin_user,admin_pwd) user = ldap_user.search_ou_user(baseDN) print user#执行结果[root@zabbix ~]# python get_ldap.py ['test01', 'Admin'] 后续调用zbx接口，将用户插入进去，即可完成LDAP单点登录。安装requests 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157#coding: utf-8import urllibimport requestsimport jsonclass Zbx(): #auth=None zbx_host='ipaddr' api_url="http://%s/zabbix/api_jsonrpc.php"%zbx_host __user="username" __password="password" def __init__(self,zbx_host=zbx_host,api_url=api_url,user=__user,password=__password): self.user=user self.password=password self.zbx_host=password self.api_url=api_url #登录，获取auth def login(self): data = &#123;"jsonrpc":"2.0","method":"user.login","params":&#123;"user":self.user,"password":self.password&#125;,"id":0&#125; headers=&#123;"Content-Type": "application/json"&#125; try: req = requests.post(self.api_url,data=json.dumps(data),headers=headers,timeout=3) self.auth = req.json()["result"] #print(self.auth) return self.auth except: return "Get auth error" #获取指定组id def get_usrgrpid(self,groupname): self.login() data = &#123; "jsonrpc": "2.0", "method": "usergroup.get", "params": &#123; "output": "extend", "filter":&#123; "name":groupname &#125;, "status": 0 &#125;, "auth": self.auth, "id": 1 &#125; try: req = requests.post(self.api_url, data=json.dumps(data), headers=&#123;"Content-Type": "application/json-rpc"&#125;, timeout=5) res_json=req.json() #print res_json return res_json['result'][0]['usrgrpid'] except Exception as exc: return 'connect error' return 1 #创建用户 def create_user(self,username,groupname): self.login() group_id=self.get_usrgrpid(groupname) data=&#123; "jsonrpc": "2.0", "method": "user.create", "params": &#123; "alias": username, "passwd": "", "usrgrps": [ &#123; "usrgrpid": group_id &#125; ], &#125;, "auth": self.auth, "id": 1 &#125; try: req = requests.post(self.api_url, data=json.dumps(data), headers=&#123;"Content-Type": "application/json-rpc"&#125;, timeout=5) res_json=req.json() except Exception as exc: return 'connect error' return 1 #获取用户列表 def get_userlist(self): user_list=[] self.login() data=&#123; "jsonrpc": "2.0", "method": "user.get", "params": &#123; "output": "extend" &#125;, "auth": self.auth, "id": 1 &#125; try: req = requests.post(self.api_url, data=json.dumps(data), headers=&#123;"Content-Type": "application/json-rpc"&#125;, timeout=5) res_json=req.json() get_info = res_json['result'] #get_info = res_json['result'][0]['alias'] i = 0 while i &lt; get_info.__len__(): user_list.append(get_info[i]['alias']) i+=1 if 'guest' in user_list: user_list.remove('guest') return user_list except Exception as exc: return 'connect error' return 1 #获取用户ID def get_userid(self,username): self.login() data=&#123; "jsonrpc": "2.0", "method": "user.get", "params": &#123; "output": "extend", "filter":&#123; "alias":username &#125;, &#125;, "auth": self.auth, "id": 1 &#125; try: req = requests.post(self.api_url, data=json.dumps(data), headers=&#123;"Content-Type": "application/json-rpc"&#125;, timeout=5) res_json=req.json() userid = res_json['result'][0]['userid'] return userid except Exception as exc: return 'connect error' return 1 #删除用户 def del_user(self,username): self.login() data=&#123; "jsonrpc": "2.0", "method": "user.delete", "params": [ self.get_userid(username), ], "auth": self.auth, "id": 1 &#125; try: req = requests.post(self.api_url, data=json.dumps(data), headers=&#123;"Content-Type": "application/json-rpc"&#125;, timeout=5) except Exception as exc: return 'connect error' return 1 调用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#!/usr/bin/python#coding: utf-8from moudle import get_ldapfrom moudle import zbximport time#ldap相关信息，根据实际情况修改ldap_url = 'ldap://192.xxx.1.x:389'domain_name = u'zbx.com'ldap_user = u'xxxxx'ldap_pwd = u'xxxxxxxxxx'#ou的层级 1：没有层级，直接写。2：有层级则从内到外开始写多个ou.注意大小写baseDN = 'OU=zabbix,DC=zbx,DC=com'#获取ldap user列表ldap_conn = get_ldap.LdapToZbx(ldap_url,domain_name,ldap_user,ldap_pwd)ldap_user_list = ldap_conn.search_ou_user(baseDN)#print ldap_user_list#zabbix相关信息,根据实际情况修改azbx_host='192.xxx.1.xxx'api_url="http://%s/zabbix/api_jsonrpc.php"%zbx_hostzbx_user="Admin"zbx_pwd="xxxxxxxxxxx"groupname = 'ldap' #新加zabbix用户分配到的组zbx = zbx.Zbx(zbx_host,api_url,zbx_user,zbx_pwd)zbx_user_list = zbx.get_userlist()#print zbx_user_list#创建用户for username in ldap_user_list: if username not in zbx_user_list: try: zbx.create_user(username,groupname) date=time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())) print date + " add user " + username except Exception as e: print 'connect error'#删除用户for username in zbx_user_list: if username not in ldap_user_list: try: zbx.del_user(username) date=time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())) print date + " remove user " + username except Exception as e: print 'connect error' ImportError: No module named &#39;requests.packages.urllib3&#39; 执行pip install requests --force --upgrade or pip install requests urllib3 --force --upgrade 其他当ldap挂了的时候,可通过修改数据库进行切换本地认证.当然,也可以通过,直接修改数据库进行认证的切换. 1234567891011121314151617181920212223242526mysql&gt; use zabbix;Database changedmysql&gt; show tables;#用户和认证的信息涉及到四个表，分别是表config、users、users_groups、usrgrp#只用config表来配置认证切换mysql&gt; desc config;#认证类型由 authentication_type，字段决定，值可以为0,1和2#0 代表Internal,1代表LDAP，2代表HTTP.mysql&gt; update config set authentication_type=0;#即可切换为系统认证方式mysql&gt; flush privileges;#穿插:修改用管理员密码的命令#查询Admin用户的ID:mysql&gt; select * from users;#修改admin密码mysql&gt; update users set passwd=&apos;zabbix&apos; where userid=????;#切换LDAP信息,更换相关信息等.use zabbix;update config set authentication_type=1,ldap_host=&apos;ldap://192.168.1.xx&apos;,ldap_port=&apos;389&apos;,ldap_base_dn=&apos;DC=zbx,DC=com&apos;,ldap_bind_dn=&apos;cn=Admin,ou=zabbix,dc=zbx,dc=com&apos;,ldap_search_attribute=&apos;sAMAccountName&apos;,ldap_bind_password=&apos;xxxxxxxxx&apos;;]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>ldap</tag>
        <tag>python</tag>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ipmi]]></title>
    <url>%2F2018%2F01%2F21%2Fipmi%2F</url>
    <content type="text"><![CDATA[IPMI(Intelligent Platform Management Interface) 是独立于物理服务器CPU，电源，存储等独立工作的管理工具。其需要进入BISO先行设置。IPMI可监控服务器的物理状态，如温度、电压、电扇、电源等，以及一些远程管控等默认端口是623，UDP协议 安装centos环境下yum -y install ipmitool也可以下载ipmitool-version.tar.gz 解压后./configure &amp;&amp; make &amp;&amp; make installservice ipmi start执行 内核加载,另：虚机不存在12345[root@localhost ~]# modprobe ipmi_watchdog[root@localhost ~]# modprobe ipmi_poweroff[root@localhost ~]# modprobe ipmi_devintf[root@localhost ~]# modprobe ipmi_si[root@localhost ~]# modprobe ipmi_msghandler 查资料显示服务器 第一块网卡 第一个口 接交换机，默认这个口集成了IPMI，目前dell如此。其他厂商可能会有变，使用前请确认，并去BIOS开启。网口启动与否并不影响使用。 使用远程获取服务器监控信息时，需要加上远程服务器的地址：ipmitool -I lanplus -H ipaddress -U username -P password command-H表示后面跟的是服务器的地址-U表示后面跟着用户名-P表示后面跟着用户密码command命令 参数1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283$ ipmitool -husage: ipmitool [options...] &lt;command&gt; -h This help -V Show version information -v Verbose (can use multiple times) -c Display output in comma separated format -d N Specify a /dev/ipmiN device to use (default=0) -I intf Interface to use -H hostname Remote host name for LAN interface -p port Remote RMCP port [default=623] -U username Remote session username -f file Read remote session password from file -z size Change Size of Communication Channel (OEM) -S sdr Use local file for remote SDR cache -D tty:b[:s] Specify the serial device, baud rate to use and, optionally, specify that interface is the system one -a Prompt for remote password -Y Prompt for the Kg key for IPMIv2 authentication -e char Set SOL escape character -C ciphersuite Cipher suite to be used by lanplus interface -k key Use Kg key for IPMIv2 authentication -y hex_key Use hexadecimal-encoded Kg key for IPMIv2 authentication -L level Remote session privilege level [default=ADMINISTRATOR] Append a &apos;+&apos; to use name/privilege lookup in RAKP1 -A authtype Force use of auth type NONE, PASSWORD, MD2, MD5 or OEM -P password Remote session password -E Read password from IPMI_PASSWORD environment variable -K Read kgkey from IPMI_KGKEY environment variable -m address Set local IPMB address -b channel Set destination channel for bridged request -t address Bridge request to remote target address -B channel Set transit channel for bridged request (dual bridge) -T address Set transit address for bridge request (dual bridge) -l lun Set destination lun for raw commands -o oemtype Setup for OEM (use &apos;list&apos; to see available OEM types) -O seloem Use file for OEM SEL event descriptions -N seconds Specify timeout for lan [default=2] / lanplus [default=1] interface -R retry Set the number of retries for lan/lanplus interface [default=4]Interfaces: open Linux OpenIPMI Interface [default] imb Intel IMB Interface lan IPMI v1.5 LAN Interface lanplus IPMI v2.0 RMCP+ LAN Interface serial-terminal Serial Interface, Terminal Mode serial-basic Serial Interface, Basic Mode Commands: raw Send a RAW IPMI request and print response i2c Send an I2C Master Write-Read command and print response spd Print SPD info from remote I2C device lan Configure LAN Channels chassis Get chassis status and set power state power Shortcut to chassis power commands event Send pre-defined events to MC mc Management Controller status and global enables sdr Print Sensor Data Repository entries and readings sensor Print detailed sensor information fru Print built-in FRU and scan SDR for FRU locators gendev Read/Write Device associated with Generic Device locators sdr sel Print System Event Log (SEL) pef Configure Platform Event Filtering (PEF) sol Configure and connect IPMIv2.0 Serial-over-LAN tsol Configure and connect with Tyan IPMIv1.5 Serial-over-LAN isol Configure IPMIv1.5 Serial-over-LAN user Configure Management Controller users channel Configure Management Controller channels session Print session information dcmi Data Center Management Interface sunoem OEM Commands for Sun servers kontronoem OEM Commands for Kontron devices picmg Run a PICMG/ATCA extended cmd fwum Update IPMC using Kontron OEM Firmware Update Manager firewall Configure Firmware Firewall delloem OEM Commands for Dell systems shell Launch interactive IPMI shell exec Run list of commands from file set Set runtime variable for shell and exec hpm Update HPM components using PICMG HPM.1 file ekanalyzer run FRU-Ekeying analyzer using FRU files ime Update Intel Manageability Engine Firmware 常用电源操作1234ipmitool -I lanplus -H 192.168.1.231 -U username -P password chassis power offipmitool -I lanplus -H 192.168.1.231 -U username -P password chassis power resetipmitool -I lanplus -H 192.168.1.231 -U username -P password chassis power onipmitool -I lanplus -H 192.168.1.231 -U username -P password chassis power status 版本查看ipmitool -V设备信息ipmitool -I lanplus -H 192.168.1.231 -U lenovo -P lenovo chassis status 命令选项 描述 ipmitool -I lanplus -H myserver.example.com -P mypass chassis power on 打开服务器的电源 ipmitool -I lanplus -H myserver.example.com -P mypass chassis power off 关闭服务器的电源 ipmitool -I lanplus -H myserver.example.com -P mypass chassis status 检查服务器状态 ipmitool -I lanplus -H myserver.example.com -P mypass chassis power cycle 关闭服务器的电源，然后重新打开 ipmitool -I lanplus -H myserver.example.com -P mypass sol activate 激活 SOL 系统控制台 ipmitool -I lanplus -H myserver.example.com -P mypass sol deactivate 取消激活 SOL 系统控制台 ipmitool -I lanplus -H myserver.example.com -P mypass sel list 返回错误日志 ipmitool -I lanplus -H myserver.example.com -P mypass sdr list 列示所有传感器的状态 ipmitool -I lanplus -H myserver.example.com -P mypass sol set retry-interval value 设置缺省重试时间间隔值（以毫秒计） ipmitool -I lanplus -H myserver.example.com -P mypass fru print 打印 FRU 信息 ipmitool -I lanplus -H myserver.example.com -P mypass user list 列示 IPMI 用户 详细查询SDR(Print Sensor Data Repository entries and readings)传感器数据 1234567891011121314151617181920212223242526272829303132333435363738394041424344[root@centos-01 ~]# ipmitool -I lanplus -H 192.168.1.231 -U lenovo -P lenovo sdr listCPU1 Status | 0x00 | okCPU2 Status | 0x00 | okCPU1 Temp | 42 degrees C | okCPU2 Temp | 57 degrees C | okDIMM Zone1 Temp | 33 degrees C | okDIMM Zone2 Temp | 30 degrees C | okDIMM Zone3 Temp | 28 degrees C | okDIMM Zone4 Temp | 31 degrees C | okPCH Temp | 48 degrees C | okPSU Inlet Temp | 31 degrees C | okPCI Zone1 Temp | 36 degrees C | okPCI Zone2 Temp | 32 degrees C | okInlet Amb Temp | 17 degrees C | ok3.3V Standby | 3.23 Volts | ok5V Standby | 5.00 Volts | ok3.3V | 3.23 Volts | ok5V | 5.00 Volts | ok12V | 11.96 Volts | ok3V Battery | 3.12 Volts | ok12V Standby | 11.70 Volts | okPower Reading | 228 Watts/hour | okPSU1 Status | 0x00 | okPSU2 Status | 0x00 | okPower Unit | 0x00 | ok12V Ch A Fault | 0x00 | ok12V Ch B Fault | 0x00 | ok12V Ch C Fault | 0x00 | ok12V Ch D Fault | 0x00 | ok12V Ch E Fault | 0x00 | ok12V Ch F Fault | 0x00 | okWatchdog | 0x00 | okMemory ECC | Not Readable | nsBIOS Event | Not Readable | nsPCI Riser1 Temp | 32 degrees C | okPCI Riser2 Temp | no reading | nsFAN1 | 3840 RPM | okFAN2 | 3840 RPM | okFAN3 | 3780 RPM | okFAN4 | 3840 RPM | okFAN5 | 3840 RPM | okFAN6 | 3780 RPM | okSys Pwr Monitor | 0x00 | ok[root@centos-01 ~]# -v 查询详细 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[root@centos-01 ~]# ipmitool -I lanplus -H 192.168.1.231 -U lenovo -P lenovo -v sdr listRunning Get PICMG Properties my_addr 0x20, transit 0, target 0x20Error response 0xc1 from Get PICMG ProperitiesRunning Get VSO Capabilities my_addr 0x20, transit 0, target 0x20Invalid completion code received: Invalid commandDiscovered IPMB address 0x0Sensor ID : CPU1 Status (0x1) Entity ID : 3.1 (Processor) Sensor Type (Discrete): Processor (0x07) Sensor Reading : 0h Event Message Control : Per-threshold States Asserted : Processor [Presence detected] Assertion Events : Processor [Presence detected] Assertions Enabled : Processor [Thermal Trip] OEM : 0Sensor ID : CPU2 Status (0x2) Entity ID : 3.2 (Processor) Sensor Type (Discrete): Processor (0x07) Sensor Reading : 0h Event Message Control : Per-threshold States Asserted : Processor [Presence detected] Assertion Events : Processor [Presence detected] Assertions Enabled : Processor [Thermal Trip] OEM : 0Sensor ID : CPU1 Temp (0x9) Entity ID : 3.1 (Processor) Sensor Type (Threshold) : Temperature (0x01) Sensor Reading : 46 (+/- 0) degrees C Status : ok Nominal Reading : 35.000 Upper critical : 75.000 Upper non-critical : 70.000 Positive Hysteresis : Unspecified Negative Hysteresis : Unspecified Minimum sensor range : Unspecified Maximum sensor range : Unspecified Event Message Control : Per-threshold Readable Thresholds : unc ucr Settable Thresholds : Threshold Read Mask : unc ucr Assertion Events : Assertions Enabled : unc+ ucr+ Deassertions Enabled : unc+ ucr+ 这里要注意Sensor ID 可根据其查询相关信息 12345678910111213[root@centos-01 ~]# ipmitool -I lanplus -H 192.168.1.231 -U lenovo -P lenovo sdr get "CPU1 Status"Sensor ID : CPU1 Status (0x1) Entity ID : 3.1 (Processor) Sensor Type (Discrete): Processor (0x07) Sensor Reading : 0h Event Message Control : Per-threshold States Asserted : Processor [Presence detected] Assertion Events : Processor [Presence detected] Assertions Enabled : Processor [Thermal Trip] OEM : 0 另外注意Entity ID ，也可根据查询相关信息 123[root@centos-01 ~]# ipmitool -I lanplus -H 192.168.1.231 -U lenovo -P lenovo sdr entity 3.1CPU1 Status | 01h | ok | 3.1 | Presence detectedCPU1 Temp | 09h | ok | 3.1 | 43 degrees C 这些命令可以通过帮助进行查看 123456789101112131415161718192021222324252627282930313233343536373839[root@centos-01 ~]# ipmitool -I lanplus -H 192.168.1.231 -U lenovo -P lenovo sdr helpusage: sdr &lt;command&gt; [options] list | elist [option] all All SDR Records full Full Sensor Record compact Compact Sensor Record event Event-Only Sensor Record mcloc Management Controller Locator Record fru FRU Locator Record generic Generic Device Locator Record type [option] &lt;Sensor_Type&gt; Retrieve the state of specified sensor. Sensor_Type can be specified either as a string or a hex value. list Get a list of available sensor types get &lt;Sensor_ID&gt; Retrieve state of the first sensor matched by Sensor_ID info Display information about the repository itself entity &lt;Entity_ID&gt;[.&lt;Instance_ID&gt;] Display all sensors associated with an entity dump &lt;file&gt; Dump raw SDR data to a file fill &lt;option&gt; sensors Creates the SDR repository for the current configuration nosat Creates the SDR repository for the current configuration, without satellite scan file &lt;file&gt; Load SDR repository from a file range &lt;range&gt; Load SDR repository from a provided list or range. Use &apos;,&apos; for list or &apos;-&apos; for range, eg. 0x28,0x32,0x40-0x44[root@centos-01 ~]#]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>ipmi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pysnmp使用]]></title>
    <url>%2F2018%2F01%2F01%2Fpysnmp%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[pysnmp ,python的一个库文件,可通过它获取设备snmp信息,从而提取想要的资料.建议,使用前,先了解下snmp,MIB,oid等 pysnmp官网 安装使用 pip 就可以了. 官方例子获取信息SNMP GET官方例子12345678910111213141516171819202122232425262728293031323334"""SNMPv1++++++Send SNMP GET request using the following options: * with SNMPv1, community 'public' * over IPv4/UDP * to an Agent at demo.snmplabs.com:161 * for two instances of SNMPv2-MIB::sysDescr.0 MIB object,Functionally similar to:| $ snmpget -v1 -c public demo.snmplabs.com SNMPv2-MIB::sysDescr.0"""#from pysnmp.hlapi import *errorIndication, errorStatus, errorIndex, varBinds = next( getCmd(SnmpEngine(), CommunityData('public', mpModel=0), UdpTransportTarget(('demo.snmplabs.com', 161)), ContextData(), ObjectType(ObjectIdentity('SNMPv2-MIB', 'sysDescr', 0))))if errorIndication: print(errorIndication)elif errorStatus: print('%s at %s' % (errorStatus.prettyPrint(), errorIndex and varBinds[int(errorIndex) - 1][0] or '?'))else: for varBind in varBinds: print(' = '.join([x.prettyPrint() for x in varBind])) 执行后的结果SNMPv2-MIB::sysDescr.&quot;0&quot; = SunOS zeus.snmplabs.com 4.1.3_U1 1 sun4m 方法解释大概说下作用,如开头所说,建议先了解下snmp,MIB,oid等 getCmd() 通过此方法来执行SNMP命令.返回由errorIndication, errorStatus, errorIndex, varBinds组成的一个tuple一共有四个方法bulkCmd getCmd nextCmd setCmd都有各自的用法. SnmpEngine() 创建了个SNMP引擎,用来保障后续的操作. CommunityData() 实例化SNMP协议以及communitySNMP协议分为v1 v2c v3 v3暂时不管.CommunityData()需要两个参数用来实例化其中 0代表v1, 1代表v2c v3是另外的方法UsmUserData UdpTransportTarget 其实还有个 Udp6TransportTarget 针对IPv6的它用来设置传输目标 ContextData(),由于SNMP的消息头是v3的,这个类是用来初始snmp上下文的, ObjectType 理解为一个容器对象,使ObjectIdentity和SNMP信息更像是key:valueMIB库ASN1 里都是MIB信息,格式类似123456789sysUpTime OBJECT-TYPE SYNTAX TimeTicks MAX-ACCESS read-only STATUS current DESCRIPTION &quot;The time (in hundredths of a second) since the network management portion of the system was last re-initialized.&quot; ::= &#123; system 3 &#125; 这些信息由ObjectIdentity转换为1.3.6.1....,然后再由ObjectType 将其和值对应.使结果更为友好,使用prettyPrint()打印出 ObjectIdentity MIB对象标识,格式化处理MIB对象为OID,反之亦然.所以也可直接输出OID 以上步骤基本就可以按需求提出SNMP信息了. 简便方法使用模块pysnmp.entity.rfc3413.oneliner.cmdgen 1234567891011121314151617181920212223from pysnmp.entity.rfc3413.oneliner import cmdgendef info(self,oid,ip,commu): cmdGen = cmdgen.CommandGenerator() errorIndication, errorStatus, errorIndex, varBindTable = cmdGen.nextCmd( cmdgen.CommunityData(commu), cmdgen.UdpTransportTarget((ip, 161)), oid, ) if errorIndication: print(errorIndication) else: if errorStatus: print('%s at %s' % ( errorStatus.prettyPrint(), errorIndex and varBindTable[-1][int(errorIndex)-1][0] or '?' ) ) else: for varBindTableRow in varBindTable: for name, val in varBindTableRow: return ('%s = %s' % (name.prettyPrint(), val.prettyPrint())) 简单例子12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879#!/usr/bin/env python#coding: utf-8#author: lizili#from pysnmp.hlapi import *from pysnmp.entity.rfc3413.oneliner import cmdgenimport jsonclass GetSnmp(): #oid列表 def make_list(self,*oid): oid_list = [] for o in oid: oid_list.append(o) return oid_list #获取snmp信息 def info(self,oid,ip,commu): cmdGen = cmdgen.CommandGenerator() errorIndication, errorStatus, errorIndex, varBindTable = cmdGen.nextCmd( cmdgen.CommunityData(commu), cmdgen.UdpTransportTarget((ip, 161)), oid, ) if errorIndication: print(errorIndication) else: if errorStatus: print('%s at %s' % ( errorStatus.prettyPrint(), errorIndex and varBindTable[-1][int(errorIndex)-1][0] or '?' ) ) else: var_dict=&#123;&#125; for varBindTableRow in varBindTable: for name, val in varBindTableRow: var_dict[name.prettyPrint()]=str(val.prettyPrint()) return var_dict #循环oid表，提取整理信息 def get_info(self,oid,ip,commu='public'): info_dict=&#123;&#125; for o in oid: info = self.info(o,ip,commu) info_dict[o]=info info_json=json.dumps(info_dict,indent=4) return info_jsonif __name__ == "__main__": sysName = "1.3.6.1.2.1.1.5" sysDescr = "1.3.6.1.2.1.1.1" ifNumber = "1.3.6.1.2.1.2.1" ifDescr = "1.3.6.1.2.1.2.2.1.2" ifInOctet = "1.3.6.1.2.1.2.2.1.10" ifOutOctet = "1.3.6.1.2.1.2.2.1.16" ifInUcastPkts = "1.3.6.1.2.1.2.2.1.11" ifOutUcastPkts = "1.3.6.1.2.1.2.2.1.17" ipNetToMediaPhysAddress = "1.3.6.1.2.1.4.22.1.2" ipOperStatus = "1.3.6.1.2.1.2.2.1.8" #实例化类 test = GetSnmp() #生成list oid_list = test.make_list( # sysName, # sysDescr, # ifNumber, # ifDescr, # ifInOctet, # ifOutOctet, # ifInUcastPkts, # ifOutUcastPkts, ipNetToMediaPhysAddress, ipOperStatus, ) #输出信息 info = test.get_info(oid_list,"192.168.1.235") print info]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pysnmp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[supervisor]]></title>
    <url>%2F2017%2F12%2F25%2Fsupervisor%2F</url>
    <content type="text"><![CDATA[Supervisor进程管理,只能管理非daemon的进程，不能管理守护进程。 Supervisor进程管理,只能管理非daemon的进程，不能管理守护进程。 安装yum12yum -y install epel-releaseyum -y install supervisor 默认主配置文件在/etc/supervisor.conf 12345678910111213141516171819[root@master ~]# sed -n &apos;/^;/!&#123;/^$/!p&#125;&apos; /etc/supervisord.conf [unix_http_server]file=/var/run/supervisor/supervisor.sock ; (the path to the socket file)[supervisord]logfile=/var/log/supervisor/supervisord.log ; (main log file;default $CWD/supervisord.log)logfile_maxbytes=50MB ; (max main logfile bytes b4 rotation;default 50MB)logfile_backups=10 ; (num of main logfile rotation backups;default 10)loglevel=info ; (log level;default info; others: debug,warn,trace)pidfile=/var/run/supervisord.pid ; (supervisord pidfile;default supervisord.pid)nodaemon=false ; (start in foreground if true;default false)minfds=1024 ; (min. avail startup file descriptors;default 1024)minprocs=200 ; (min. avail process descriptors;default 200)[rpcinterface:supervisor]supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface[supervisorctl]serverurl=unix:///var/run/supervisor/supervisor.sock ; use a unix:// URL for a unix socket[include]files = supervisord.d/*[root@master ~]# 默认项目配置文件/etc/supervisord.d/下 easy_install12yum install python-setuptoolseasy_install supervisor 文件路径mkdir -m 755 -p /etc/supervisor/创建主配置文件echo_supervisord_conf &gt; /etc/supervisor/supervisord.conf项目配置文件目录,主配置文件中,将此路径include.mkdir -m 755-p /etc/supervisor/conf.d 进程配置(例)以redis为例,当然,redis本身是支持开启后台启动的.这里为了测试12345678910111213141516[root@master supervisord.d]# pwd/etc/supervisord.d[root@master supervisord.d]# lsredis.conf[root@master supervisord.d]# cat redis.conf [program:redis]command = redis-server;指定redis 日志路径,路径要提前准备好,不然无法启动.stdout_logfile=/tmp/supervisor-log/redis.logautostart=trueautorestart=truestartsecs=5priority=1stopasgroup=truekillasgroup=true[root@master supervisord.d]# 交互终端,可看到当前运行的进程.并操作123456789101112131415[root@master ~]# supervisorctl redis RUNNING pid 1947, uptime 0:14:54supervisor&gt; helpdefault commands (type help &lt;topic&gt;):=====================================add clear fg open quit remove restart start stop update avail exit maintail pid reload reread shutdown status tail versionsupervisor&gt; help stopstop &lt;name&gt; Stop a processstop &lt;gname&gt;:* Stop all processes in a groupstop &lt;name&gt; &lt;name&gt; Stop multiple processes or groupsstop all Stop all processessupervisor&gt; bash管理123456supervisorctl statussupervisorctl stop redissupervisorctl start redissupervisorctl restart redissupervisorctl rereadsupervisorctl update supervisor主配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254[unix_http_server] file=/tmp/supervisor.sock ; socket文件的路径，supervisorctl用XML_RPC和supervisord通信就是通过它进行 的。如果不设置的话，supervisorctl也就不能用了 不设置的话，默认为none。 非必须设置 ;chmod=0700 ; 这个简单，就是修改上面的那个socket文件的权限为0700 不设置的话，默认为0700。 非必须设置;chown=nobody:nogroup ; 这个一样，修改上面的那个socket文件的属组为user.group 不设置的话，默认为启动supervisord进程的用户及属组。非必须设置;username=user ; 使用supervisorctl连接的时候，认证的用户 不设置的话，默认为不需要用户。 非必须设置;password=123 ; 和上面的用户名对应的密码，可以直接使用明码，也可以使用SHA加密 如：&#123;SHA&#125;82ab876d1387bfafe46cc1c8a2ef074eae50cb1d 默认不设置。。。非必须设置;[inet_http_server] ; 侦听在TCP上的socket，Web Server和远程的supervisorctl都要用到他 不设置的话，默认为不开启。非必须设置;port=127.0.0.1:9001 ; 这个是侦听的IP和端口，侦听所有IP用 :9001或*:9001。 这个必须设置，只要上面的[inet_http_server]开启了，就必须设置它;username=user ; 这个和上面的uinx_http_server一个样。非必须设置;password=123 ; 这个也一个样。非必须设置[supervisord] ;这个主要是定义supervisord这个服务端进程的一些参数的 这个必须设置，不设置，supervisor就不用干活了logfile=/tmp/supervisord.log ; 这个是supervisord这个主进程的日志路径，注意和子进程的日志不搭嘎。 默认路径$CWD/supervisord.log，$CWD是当前目录。。非必须设置logfile_maxbytes=50MB ; 这个是上面那个日志文件的最大的大小，当超过50M的时候，会生成一个新的日 志文件。当设置为0时，表示不限制文件大小 默认值是50M，非必须设置。 logfile_backups=10 ; 日志文件保持的数量，上面的日志文件大于50M时，就会生成一个新文件。文件 数量大于10时，最初的老文件被新文件覆盖，文件数量将保持为10 当设置为0时，表示不限制文件的数量。 默认情况下为10。。。非必须设置loglevel=info ; 日志级别，有critical, error, warn, info, debug, trace, or blather等 默认为info。。。非必须设置项pidfile=/tmp/supervisord.pid ; supervisord的pid文件路径。 默认为$CWD/supervisord.pid。。。非必须设置nodaemon=false ; 如果是true，supervisord进程将在前台运行 默认为false，也就是后台以守护进程运行。。。非必须设置minfds=1024 ; 这个是最少系统空闲的文件描述符，低于这个值supervisor将不会启动。 系统的文件描述符在这里设置cat /proc/sys/fs/file-max 默认情况下为1024。。。非必须设置minprocs=200 ; 最小可用的进程描述符，低于这个值supervisor也将不会正常启动。 ulimit -u这个命令，可以查看linux下面用户的最大进程数 默认为200。。。非必须设置;umask=022 ; 进程创建文件的掩码 默认为022。。非必须设置项;user=chrism ; 这个参数可以设置一个非root用户，当我们以root用户启动supervisord之后。 我这里面设置的这个用户，也可以对supervisord进行管理 默认情况是不设置。。。非必须设置项;identifier=supervisor ; 这个参数是supervisord的标识符，主要是给XML_RPC用的。当你有多个 supervisor的时候，而且想调用XML_RPC统一管理，就需要为每个 supervisor设置不同的标识符了 默认是supervisord。。。非必需设置;directory=/tmp ; 这个参数是当supervisord作为守护进程运行的时候，设置这个参数的话，启动 supervisord进程之前，会先切换到这个目录 默认不设置。。。非必须设置;nocleanup=true ; 这个参数当为false的时候，会在supervisord进程启动的时候，把以前子进程 产生的日志文件(路径为AUTO的情况下)清除掉。有时候咱们想要看历史日志，当 然不想日志被清除了。所以可以设置为true 默认是false，有调试需求的同学可以设置为true。。。非必须设置;childlogdir=/tmp ; 当子进程日志路径为AUTO的时候，子进程日志文件的存放路径。 默认路径是这个东西，执行下面的这个命令看看就OK了，处理的东西就默认路径 python -c &quot;import tempfile;print tempfile.gettempdir()&quot; 非必须设置;environment=KEY=&quot;value&quot; ; 这个是用来设置环境变量的，supervisord在linux中启动默认继承了linux的 环境变量，在这里可以设置supervisord进程特有的其他环境变量。 supervisord启动子进程时，子进程会拷贝父进程的内存空间内容。 所以设置的 这些环境变量也会被子进程继承。 小例子：environment=name=&quot;haha&quot;,age=&quot;hehe&quot; 默认为不设置。。。非必须设置;strip_ansi=false ; 这个选项如果设置为true，会清除子进程日志中的所有ANSI 序列。什么是ANSI 序列呢？就是我们的\n,\t这些东西。 默认为false。。。非必须设置; the below section must remain in the config file for RPC; (supervisorctl/web interface) to work, additional interfaces may be; added by defining them in separate rpcinterface: sections[rpcinterface:supervisor] ;这个选项是给XML_RPC用的，当然你如果想使用supervisord或者web server 这 个选项必须要开启的supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface [supervisorctl] ;这个主要是针对supervisorctl的一些配置 serverurl=unix:///tmp/supervisor.sock ; 这个是supervisorctl本地连接supervisord的时候，本地UNIX socket 路径，注意这个是和前面的[unix_http_server]对应的 默认值就是unix:///tmp/supervisor.sock。。非必须设置;serverurl=http://127.0.0.1:9001 ; 这个是supervisorctl远程连接supervisord的时候，用到的TCP socket路径 注意这个和前面的[inet_http_server]对应 默认就是http://127.0.0.1:9001。。。非必须项 ;username=chris ; 用户名 默认空。。非必须设置;password=123 ; 密码 默认空。。非必须设置;prompt=mysupervisor ; 输入用户名密码时候的提示符 默认supervisor。。非必须设置;history_file=~/.sc_history ; 这个参数和shell中的history类似，我们可以用上下键来查找前面执行过的命令 默认是no file的。。所以我们想要有这种功能，必须指定一个文件。。。非 必须设置; The below sample program section shows all possible program subsection values,; create one or more &apos;real&apos; program: sections to be able to control them under; supervisor.;[program:theprogramname] ;这个就是咱们要管理的子进程了，&quot;:&quot;后面的是名字，最好别乱写和实际进程 有点关联最好。这样的program我们可以设置一个或多个，一个program就是 要被管理的一个进程;command=/bin/cat ; 这个就是我们的要启动进程的命令路径了，可以带参数 例子：/home/test.py -a &apos;hehe&apos; 有一点需要注意的是，我们的command只能是那种在终端运行的进程，不能是 守护进程。这个想想也知道了，比如说command=service httpd start。 httpd这个进程被linux的service管理了，我们的supervisor再去启动这个命令 这已经不是严格意义的子进程了。 这个是个必须设置的项;process_name=%(program_name)s ; 这个是进程名，如果我们下面的numprocs参数为1的话，就不用管这个参数 了，它默认值%(program_name)s也就是上面的那个program冒号后面的名字， 但是如果numprocs为多个的话，那就不能这么干了。想想也知道，不可能每个 进程都用同一个进程名吧。 ;numprocs=1 ; 启动进程的数目。当不为1时，就是进程池的概念，注意process_name的设置 默认为1 。。非必须设置;directory=/tmp ; 进程运行前，会前切换到这个目录 默认不设置。。。非必须设置;umask=022 ; 进程掩码，默认none，非必须;priority=999 ; 子进程启动关闭优先级，优先级低的，最先启动，关闭的时候最后关闭 默认值为999 。。非必须设置;autostart=true ; 如果是true的话，子进程将在supervisord启动后被自动启动 默认就是true 。。非必须设置;autorestart=unexpected ; 这个是设置子进程挂掉后自动重启的情况，有三个选项，false,unexpected 和true。如果为false的时候，无论什么情况下，都不会被重新启动， 如果为unexpected，只有当进程的退出码不在下面的exitcodes里面定义的退 出码的时候，才会被自动重启。当为true的时候，只要子进程挂掉，将会被无 条件的重启;startsecs=1 ; 这个选项是子进程启动多少秒之后，此时状态如果是running，则我们认为启 动成功了 默认值为1 。。非必须设置;startretries=3 ; 当进程启动失败后，最大尝试启动的次数。。当超过3次后，supervisor将把 此进程的状态置为FAIL 默认值为3 。。非必须设置;exitcodes=0,2 ; 注意和上面的的autorestart=unexpected对应。。exitcodes里面的定义的 退出码是expected的。;stopsignal=QUIT ; 进程停止信号，可以为TERM, HUP, INT, QUIT, KILL, USR1, or USR2等信号 默认为TERM 。。当用设定的信号去干掉进程，退出码会被认为是expected 非必须设置;stopwaitsecs=10 ; 这个是当我们向子进程发送stopsignal信号后，到系统返回信息 给supervisord，所等待的最大时间。 超过这个时间，supervisord会向该 子进程发送一个强制kill的信号。 默认为10秒。。非必须设置;stopasgroup=false ; 这个东西主要用于，supervisord管理的子进程，这个子进程本身还有 子进程。那么我们如果仅仅干掉supervisord的子进程的话，子进程的子进程 有可能会变成孤儿进程。所以咱们可以设置可个选项，把整个该子进程的 整个进程组都干掉。 设置为true的话，一般killasgroup也会被设置为true。 需要注意的是，该选项发送的是stop信号 默认为false。。非必须设置。。;killasgroup=false ; 这个和上面的stopasgroup类似，不过发送的是kill信号;user=chrism ; 如果supervisord是root启动，我们在这里设置这个非root用户，可以用来 管理该program 默认不设置。。。非必须设置项;redirect_stderr=true ; 如果为true，则stderr的日志会被写入stdout日志文件中 默认为false，非必须设置;stdout_logfile=/a/path ; 子进程的stdout的日志路径，可以指定路径，AUTO，none等三个选项。 设置为none的话，将没有日志产生。设置为AUTO的话，将随机找一个地方 生成日志文件，而且当supervisord重新启动的时候，以前的日志文件会被 清空。当 redirect_stderr=true的时候，sterr也会写进这个日志文件;stdout_logfile_maxbytes=1MB ; 日志文件最大大小，和[supervisord]中定义的一样。默认为50;stdout_logfile_backups=10 ; 和[supervisord]定义的一样。默认10;stdout_capture_maxbytes=1MB ; 这个东西是设定capture管道的大小，当值不为0的时候，子进程可以从stdout 发送信息，而supervisor可以根据信息，发送相应的event。 默认为0，为0的时候表达关闭管道。。。非必须项;stdout_events_enabled=false ; 当设置为ture的时候，当子进程由stdout向文件描述符中写日志的时候，将 触发supervisord发送PROCESS_LOG_STDOUT类型的event 默认为false。。。非必须设置;stderr_logfile=/a/path ; 这个东西是设置stderr写的日志路径，当redirect_stderr=true。这个就不用 设置了，设置了也是白搭。因为它会被写入stdout_logfile的同一个文件中 默认为AUTO，也就是随便找个地存，supervisord重启被清空。。非必须设置;stderr_logfile_maxbytes=1MB ; 这个出现好几次了，就不重复了;stderr_logfile_backups=10 ; 这个也是;stderr_capture_maxbytes=1MB ; 这个一样，和stdout_capture一样。 默认为0，关闭状态;stderr_events_enabled=false ; 这个也是一样，默认为false;environment=A=&quot;1&quot;,B=&quot;2&quot; ; 这个是该子进程的环境变量，和别的子进程是不共享的;serverurl=AUTO ; ; The below sample eventlistener section shows all possible; eventlistener subsection values, create one or more &apos;real&apos;; eventlistener: sections to be able to handle event notifications; sent by supervisor.;[eventlistener:theeventlistenername] ;这个东西其实和program的地位是一样的，也是suopervisor启动的子进 程，不过它干的活是订阅supervisord发送的event。他的名字就叫 listener了。我们可以在listener里面做一系列处理，比如报警等等 楼主这两天干的活，就是弄的这玩意;command=/bin/eventlistener ; 这个和上面的program一样，表示listener的可执行文件的路径;process_name=%(program_name)s ; 这个也一样，进程名，当下面的numprocs为多个的时候，才需要。否则默认就 OK了;numprocs=1 ; 相同的listener启动的个数;events=EVENT ; event事件的类型，也就是说，只有写在这个地方的事件类型。才会被发送 ;buffer_size=10 ; 这个是event队列缓存大小，单位不太清楚，楼主猜测应该是个吧。当buffer 超过10的时候，最旧的event将会被清除，并把新的event放进去。 默认值为10。。非必须选项;directory=/tmp ; 进程执行前，会切换到这个目录下执行 默认为不切换。。。非必须;umask=022 ; 淹没，默认为none，不说了;priority=-1 ; 启动优先级，默认-1，也不扯了;autostart=true ; 是否随supervisord启动一起启动，默认true;autorestart=unexpected ; 是否自动重启，和program一个样，分true,false,unexpected等，注意 unexpected和exitcodes的关系;startsecs=1 ; 也是一样，进程启动后跑了几秒钟，才被认定为成功启动，默认1;startretries=3 ; 失败最大尝试次数，默认3;exitcodes=0,2 ; 期望或者说预料中的进程退出码，;stopsignal=QUIT ; 干掉进程的信号，默认为TERM，比如设置为QUIT，那么如果QUIT来干这个进程 那么会被认为是正常维护，退出码也被认为是expected中的;stopwaitsecs=10 ; max num secs to wait b4 SIGKILL (default 10);stopasgroup=false ; send stop signal to the UNIX process group (default false);killasgroup=false ; SIGKILL the UNIX process group (def false);user=chrism ;设置普通用户，可以用来管理该listener进程。 默认为空。。非必须设置;redirect_stderr=true ; 为true的话，stderr的log会并入stdout的log里面 默认为false。。。非必须设置;stdout_logfile=/a/path ; 这个不说了，好几遍了;stdout_logfile_maxbytes=1MB ; 这个也是;stdout_logfile_backups=10 ; 这个也是;stdout_events_enabled=false ; 这个其实是错的，listener是不能发送event;stderr_logfile=/a/path ; 这个也是;stderr_logfile_maxbytes=1MB ; 这个也是;stderr_logfile_backups ; 这个不说了;stderr_events_enabled=false ; 这个也是错的，listener不能发送event;environment=A=&quot;1&quot;,B=&quot;2&quot; ; 这个是该子进程的环境变量 默认为空。。。非必须设置;serverurl=AUTO ; override serverurl computation (childutils); The below sample group section shows all possible group values,; create one or more &apos;real&apos; group: sections to create &quot;heterogeneous&quot;; process groups.;[group:thegroupname] ;这个东西就是给programs分组，划分到组里面的program。我们就不用一个一个去操作了 我们可以对组名进行统一的操作。 注意：program被划分到组里面之后，就相当于原来 的配置从supervisor的配置文件里消失了。。。supervisor只会对组进行管理，而不再 会对组里面的单个program进行管理了;programs=progname1,progname2 ; 组成员，用逗号分开 这个是个必须的设置项;priority=999 ; 优先级，相对于组和组之间说的 默认999。。非必须选项; The [include] section can just contain the &quot;files&quot; setting. This; setting can list multiple files (separated by whitespace or; newlines). It can also contain wildcards. The filenames are; interpreted as relative to this file. Included files *cannot*; include files themselves.;[include] ;这个东西挺有用的，当我们要管理的进程很多的时候，写在一个文件里面 就有点大了。我们可以把配置信息写到多个文件中，然后include过来;files = relative/directory/*.ini]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>supervisor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix tripper和zabbix_sender]]></title>
    <url>%2F2017%2F12%2F24%2Fzabbix-tripper%E5%92%8Czabbix-sender%2F</url>
    <content type="text"><![CDATA[zabbix获取key值有超时时间，如果自定义的key脚本一般需要执行很长时间，这根本没法去做监控，所以使用zabbix监控类型zabbix trapper，需要配合zabbix_sender给它传递数据 zabbix_sender安装各版本客户端安装centos5rpm -ivh http://mirrors.aliyun.com/zabbix/zabbix/3.0/rhel/5/x86_64/zabbix-sender-3.0.5-1.el5.x86_64.rpmcentos6rpm -ivh http://mirrors.aliyun.com/zabbix/zabbix/3.0/rhel/6/x86_64/zabbix-sender-3.0.5-1.el6.x86_64.rpmcentos7rpm -ivh http://mirrors.aliyun.com/zabbix/zabbix/3.0/rhel/7/x86_64/zabbix-sender-3.0.5-1.el7.x86_64.rpm zabbix_sender格式格式zabbix_sender [-Vhv] {[-zpsI] -ko | [-zpI] -T -i &lt;file&gt; -r} [-c &lt;file&gt;] 1234567891011-c --config &lt;file&gt; #配置文件绝对路径-z --zabbix-server &lt;server&gt; # zabbix server的IP地址-p --port &lt;server port&gt; #zabbix server端口.默认10051-s --host &lt;hostname&gt; # 主机名，zabbix里面配置的主机名（不是服务器的hostname），不能使用ip地址-I --source-address &lt;IP address&gt; #源IP-k --key &lt;key&gt; # 监控项的key-o --value &lt;key value&gt; #key值-i --input-file &lt;input file&gt; # 从文件里面读取hostname、key、value 一行为一条数据，使用空格作为分隔符，如果主机名带空格，那么请使用双引号包起来-T --with-timestamps #一行一条数据，空格作为分隔符: &lt;hostname&gt; &lt;key&gt; &lt;timestamp&gt; &lt;value&gt;，#配合 --input-file option，timestamp为unix时间戳-r --real-time #将数据实时提交给服务器-v --verbose #详细模式, -vv 更详细 123456例一:zabbix_sender -z server -s host -k key -o value例二：zabbix_sender -c config-file -k key -o value例三：zabbix_sender -z server -i file 实例zabbix_sender -z 10.1.93.218 -s 10.1.27.31 -k mytrip -o 66612345678[root@elk zabbix]# zabbix_sender -z 10.1.93.218 -s 10.1.27.31 -k mytrip -o 666info from server: &quot;processed: 1; failed: 0; total: 1; seconds spent: 0.000089&quot;sent: 1; skipped: 0; total: 1-z 10.1.93.218 : zabbix server-s 10.2.27.31 : 主机名,和web页面中要一致-k mytrip :定义的key ,和web页面中要一致-o 666 : value,发送的值. 也可一通过某些命令来获取值发送获取当前登录用户数zabbix_sender -z 10.1.93.218 -s 10.1.27.31 -k mytrip -o $(w|sed -n &#39;1,2!p&#39;| wc -l) 还可以通过读取文本123456789-i # 从文件里面读取hostname、key、value 一行为一条数据使用空格作为分隔符，如果主机名带空格，那么请使用双引号包起来zabbix_sender -z 10.1.93.218 -i a.txtcat a.txt#cat f.txt10.1.27.31 mytrip 110.1.27.31 mytrip2 2 web页面zabbix server方面123456主机: - 主机名称要和 -s 一致监控项: - 创建监控项 - 类型:(zabbix tripper / 采集器) - 键值: 要和 -k 一致 zabbix_sender 可通过crontab来定时执行.可直接写,也可写成脚本后执行,建议分类编辑为脚本.]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix自定义key]]></title>
    <url>%2F2017%2F12%2F23%2Fzabbix%E8%87%AA%E5%AE%9A%E4%B9%89key%2F</url>
    <content type="text"><![CDATA[当zabbix的key不能满足需求的时候,可以通过自定义key来解决.在客户端配置文件zabbix_angentd.conf里面配置UserParameter. 参数格式UserParameter=key[*],command 参数 描述 Key 唯一. [*]表示里面可以传递多个参数 Command 需要执行的脚本，key的[]里面的参数一一对应$1到$9，一共9个参数。$0表示脚本命令. 首先去配置文件中,开启includeInclude=/etc/zabbix/zabbix_agentd.d/*.conf然后去目录下新建配置文件1234567891011#新建配置文件[root@elk zabbix_agentd.d]# lsmykey.conf userparameter_mysql.conf#编辑配置文件[root@elk zabbix_agentd.d]# cat mykey.conf UserParameter = mykey,/etc/zabbix/script/test.sh#编辑脚本(路径自定义)[root@elk zabbix_agentd.d]# cat /etc/zabbix/script/test.sh #!/usr/bin/env bashecho &apos;1234324&apos; 重启服务systemctl restart zabbix-agent.service 添加监控项去前端web页面,相关主机上创建监控项即可,键值使用定义的key,如这里的mykey.信息类型根据实际情况指定 其他1234UserParameter=ping[*],echo $1web键值输入ping[0] - 将一直返回0ping[aaa] - 将一直返回 &apos;aaa&apos; 12345统计一个文件中有多少行被匹配?UserParameter=wc[*],grep -c &quot;$2&quot; $1如下方法将会返回文件中出现指定字符的行数wc[/etc/passwd,root]wc[/etc/services,zabbix]]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins安装和部署项目]]></title>
    <url>%2F2017%2F11%2F09%2Fjenkins%E5%AE%89%E8%A3%85%E5%92%8C%E9%83%A8%E7%BD%B2%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[大致说下jenkins自动化的流程:123456程序员---------&gt;远程仓库 提交至 | 远程主机 | 提取 ↑ | | 部署 ↓ 构建[编译,打包] | Jenkins -------------------&gt;Jenkins Server 安装git(根据环境选择是否安装)推荐阅读 安装maven(根据环境选择是否安装)maven用于构建,如果你的环境不需要构建可以不安装选择版本下载wget http://mirrors.hust.edu.cn/apache/maven/maven-3/3.5.2/binaries/apache-maven-3.5.2-bin.tar.gz 解压tar -zxvf 安装包 -C /usr/localcd /usr/localmv apache-maven-3.5.2 /usr/local/maven #可选 添加环境变量/etc/profile 或者~/.bash_profile123456#maven目录export M2_HOME=/usr/local/maven#maven的bin目录export M2=$M2_HOME/bin#将bin加到PATH变量中export PATH=$M2:$PATH 配置生效source /etc/profile查看mvn -version1234567[root@jenkins /]# mvn -versionApache Maven 3.5.2 (138edd61fd100ec658bfa2d307c43b76940a5d7d; 2017-10-18T15:58:13+08:00)Maven home: /usr/local/mavenJava version: 1.8.0_151, vendor: Oracle CorporationJava home: /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.151-1.b12.el7_4.x86_64/jreDefault locale: zh_CN, platform encoding: UTF-8OS name: &quot;linux&quot;, version: &quot;3.10.0-327.el7.x86_64&quot;, arch: &quot;amd64&quot;, family: &quot;unix&quot; 安装jenkins(根据环境必须安装)官网下载以下摘自官方12345678#下载仓库源,导入公钥sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.reposudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key#安装yum -y install jenkins#运行(/usr/lib/jenkins)java -jar jenkins.war 访问http://ipaddress:8080/若出现如下内容 Unlock JenkinsTo ensure Jenkins is securely set up by the administrator, a password has been written to the log (not sure where to find it?) and this file on the server:/root/.jenkins/secrets/initialAdminPasswordPlease copy the password from either location and paste it below.Administrator password 根据提示,复制密码解锁即可. 通过tomcat启动安装tomcathttp://tomcat.apache.org/下载软件包12345tar -zxvf apache-tomcat-7.0.75.tar.gz mv apache-tomcat-7.0.75 /usr/local/tomcatmv /usr/lib/jenkins/jenkins.war /usr/local/tomcat/webapps#启动/usr/local/tomcat/bin/startup.sh 访问http://ipaddress:8080/ jenkins 注意构建,部署需要两个插件(常用于java) Deploy to container Plugin 和 Maven Integration plugin使用git的要安装Git Plugin 进入jenkins,警告如下 Your container doesn’t use UTF-8 to decode URLs. If you use non-ASCII characters as a job name etc, this will cause problems. See Containers and Tomcat i18n for more details. 去tomcat的conf/下修改serverl.xml1234&lt;Connector port="8080" protocol="HTTP/1.1" URIEncoding="UTF-8" #添加此参数 connectionTimeout="20000" redirectPort="8443" /&gt; jenkins环境至此搭建完毕. 熟悉jenkins系统设置 包括一些全局设置,工具的设置,证书创建,插件管理等等全局工具设置JKD,GIT,MAVEN等,我的路径都是在/usr/local/.. git要注意,写path../git/bin/git 安全设置如果要用api ,把访问控制的Allow anonymous read access.不然会报错. 认证配置Credentials —&gt;System —&gt; Global credentials (unrestricted) —&gt; Add Credentials一般写用户名，密码描述即可．ＩＤ会自动生成且唯一 插件管理Deploy to Containers - 发布应用到tomcat(一般使用ssh)Maven Integration - maven 集成Publish Over SSH — 该插件远程ssh登录server执行命令 Git Plugin — 该插件允许使用GIT作为一个构建SCM(源代码控制管理系统)，但必须使用Git 1.3.3及以上Subversion Plugin — 该插件增加对svn(通过SVNKit)的支持。Role-based Authorization Strategy jenkins 用户权限管理 系统管理-Configure Global Security-授权策略-Role-Based Strategy，勾选Role-Based Strategy保存 以及其他按需安装的插件 部署静态页面部署到httpd温习下流程: 程序员提交代码到远程仓库. jenkins 从远程仓库下载代码. jenkins 构建(编译/打包) jenkins 部署 完毕 代码的下载(git)要用到git plug插件(svn要用到Subversion Plug-in),部署到远端服务器需要Publish Over SSH(httpd,nginx等).如果要部署到tomcat,jboss建议使用Deploy to container Plugin,当然ssh(通过脚本)也可以 新建一个自由风格的项目 命名为free(名字自定义) General页面,点开高级选项卡,手动指定此项目的工作空间 1/usr/local/jenkins/workspace/free #自定义路径 源码管理 页面选择代码托管方式 一般会有三个选择 None,Git,Subversion.根据情况选择.我选择GIT.根据情况填写仓库URL以及添加秘钥.(秘钥可以在Credentials 下先添加,这里选择.)此时jenkins和git打通. 构建 页面选择增加构建步骤–execute shell用来执行脚本 12cd /usr/local/jenkins/workspace/free; #切换到项目工作空间tar cf free.tar *; #执行shell 打包文件 构建后操作页面增加构建后步骤–send build artifacts over SSH(通过SSH将构建的东西发送到远端主机) 这个选择需要安装上文提到的ssh插件. name: 这个选择需要去系统管理–系统设置–Publish over SSH 中添加ssh服务器.(name:自定义.hostname:主机地址.username:用户名,Remote Directory:远端主机目录,不建议填写,建议在项目下填写.点开高级,输入密码.点击test configuration,显示返回成功即可) Transfer Set Source files :*.tar 注意这个路径是针对工作空间而言的相对路径. Remote directory : 远端主机目录 /var/www/html/ Exec command: 传输后执行的命令,针对远端主机的123cd /var/www/html/;tar xvf free.tar; 保存,执行构建任务即可. 邮件提醒插件安装 Email Extension Plugin Jenkins Location 中设置默认 系统管理员邮件地址 在系统管理 &gt; `系统设置 中找到 Extended E-mail Notification 1234567SMTP server : smtp.qiye.163.comDefault user E-mail suffix : @company.comDefault Content Type: HTML...Default Recipients : 设置默认收件人Default Content 参考如下文 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset="UTF-8"&gt;&lt;title&gt;$&#123;ENV, var="JOB_NAME"&#125;-第$&#123;BUILD_NUMBER&#125;次构建日志&lt;/title&gt;&lt;/head&gt;&lt;body leftmargin="8" marginwidth="0" topmargin="8" marginheight="4" offset="0"&gt; &lt;table width="95%" cellpadding="0" cellspacing="0" style="font-size: 11pt; font-family: Tahoma, Arial, Helvetica, sans-serif"&gt; &lt;tr&gt; &lt;td&gt;&lt;br /&gt; &lt;b&gt;&lt;font color="#0B610B"&gt;构建信息&lt;/font&gt;&lt;/b&gt; &lt;hr size="2" width="100%" align="center" /&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;ul&gt; &lt;li&gt;项目名称 ： $&#123;PROJECT_NAME&#125;&lt;/li&gt; &lt;li&gt;构建编号 ： 第$&#123;BUILD_NUMBER&#125;次构建&lt;/li&gt; &lt;li&gt;触发原因： $&#123;CAUSE&#125;&lt;/li&gt; &lt;li&gt;构建日志： &lt;a href="$&#123;BUILD_URL&#125;console"&gt;$&#123;BUILD_URL&#125;console&lt;/a&gt;&lt;/li&gt; &lt;li&gt;构建 Url ： &lt;a href="$&#123;BUILD_URL&#125;"&gt;$&#123;BUILD_URL&#125;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;工作目录 ： &lt;a href="$&#123;PROJECT_URL&#125;ws"&gt;$&#123;PROJECT_URL&#125;ws&lt;/a&gt;&lt;/li&gt; &lt;li&gt;项目 Url ： &lt;a href="$&#123;PROJECT_URL&#125;"&gt;$&#123;PROJECT_URL&#125;&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;b&gt;&lt;font color="#0B610B"&gt;变更集&lt;/font&gt;&lt;/b&gt; &lt;hr size="2" width="100%" align="center" /&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;$&#123;JELLY_SCRIPT,template="html"&#125;&lt;br/&gt; &lt;hr size="2" width="100%" align="center" /&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt;&lt;/body&gt;&lt;/html&gt; 然后回到项目中． 在构建后操作中Editable Email Notification 高级 –&gt; Triggers –&gt; Add Trigger —&gt; Recipient List这里写收件人,多个逗号分割 保存即可]]></content>
      <categories>
        <category>运维工具</category>
        <category>jenkins</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx日志变量]]></title>
    <url>%2F2017%2F10%2F22%2Fnginx%E6%97%A5%E5%BF%97%E5%8F%98%E9%87%8F%2F</url>
    <content type="text"><![CDATA[关于nginx日志变量所代表的含义解释. nginx日志变量(log_format)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960$args #请求中的参数值$query_string #同 $args$arg_NAME #GET请求中NAME的值$is_args #如果请求中有参数，值为&quot;?&quot;，否则为空字符串$uri #请求中的当前URI(不带请求参数，参数位于$args)，可以不同于浏览器传递的$request_uri的值，它可以通过内部重定向，或者使用index指令进行修改，$uri不包含主机名，如&quot;/foo/bar.html&quot;。$document_uri #同 $uri$document_root #当前请求的文档根目录或别名$host #优先级：HTTP请求行的主机名&gt;&quot;HOST&quot;请求头字段&gt;符合请求的服务器名.请求中的主机头字段，如果请求中的主机头不可用，则为服务器处理请求的服务器名称$hostname #主机名$https #如果开启了SSL安全模式，值为&quot;on&quot;，否则为空字符串。$binary_remote_addr #客户端地址的二进制形式，固定长度为4个字节$body_bytes_sent #传输给客户端的字节数，响应头不计算在内；这个变量和Apache的mod_log_config模块中的&quot;%B&quot;参数保持兼容$bytes_sent #传输给客户端的字节数$connection #TCP连接的序列号$connection_requests #TCP连接当前的请求数量$content_length #&quot;Content-Length&quot; 请求头字段$content_type #&quot;Content-Type&quot; 请求头字段$cookie_name #cookie名称$limit_rate #用于设置响应的速度限制$msec #当前的Unix时间戳$nginx_version #nginx版本$pid #工作进程的PID$pipe #如果请求来自管道通信，值为&quot;p&quot;，否则为&quot;.&quot;$proxy_protocol_addr #获取代理访问服务器的客户端地址，如果是直接访问，该值为空字符串$realpath_root #当前请求的文档根目录或别名的真实路径，会将所有符号连接转换为真实路径$remote_addr #客户端地址$remote_port #客户端端口$remote_user #用于HTTP基础认证服务的用户名$request #代表客户端的请求地址$request_body #客户端的请求主体：此变量可在location中使用，将请求主体通过proxy_pass，fastcgi_pass，uwsgi_pass和scgi_pass传递给下一级的代理服务器$request_body_file #将客户端请求主体保存在临时文件中。文件处理结束后，此文件需删除。如果需要之一开启此功能，需要设置client_body_in_file_only。如果将次文件传 递给后端的代理服务器，需要禁用request body，即设置proxy_pass_request_body off，fastcgi_pass_request_body off，uwsgi_pass_request_body off，or scgi_pass_request_body off$request_completion #如果请求成功，值为&quot;OK&quot;，如果请求未完成或者请求不是一个范围请求的最后一部分，则为空$request_filename #当前连接请求的文件路径，由root或alias指令与URI请求生成$request_length #请求的长度 (包括请求的地址，http请求头和请求主体)$request_method #HTTP请求方法，通常为&quot;GET&quot;或&quot;POST&quot;$request_time #处理客户端请求使用的时间,单位为秒，精度毫秒； 从读入客户端的第一个字节开始，直到把最后一个字符发送给客户端后进行日志写入为止。$request_uri #这个变量等于包含一些客户端请求参数的原始URI，它无法修改，请查看$uri更改或重写URI，不包含主机名，例如：&quot;/cnphp/test.php?arg=freemouse&quot;$scheme #请求使用的Web协议，&quot;http&quot; 或 &quot;https&quot;$server_addr #服务器端地址，需要注意的是：为了避免访问linux系统内核，应将ip地址提前设置在配置文件中$server_name #服务器名$server_port #服务器端口$server_protocol #服务器的HTTP版本，通常为 &quot;HTTP/1.0&quot; 或 &quot;HTTP/1.1&quot;$status #HTTP响应代码$time_iso8601 #服务器时间的ISO 8610格式$time_local #服务器时间（LOG Format 格式）$cookie_NAME #客户端请求Header头中的cookie变量，前缀&quot;$cookie_&quot;加上cookie名称的变量，该变量的值即为cookie名称的值$http_NAME #匹配任意请求头字段；变量名中的后半部分NAME可以替换成任意请求头字段，如在配置文件中需要获取http请求头：&quot;Accept-Language&quot;，$http_accept_language即可$http_cookie$http_host #请求地址，即浏览器中你输入的地址（IP或域名）$http_referer #url跳转来源,用来记录从那个页面链接访问过来的$http_user_agent #用户终端浏览器等信息$http_x_forwarded_for #客户端地址(有反向代理时使用)$sent_http_NAME #可以设置任意http响应头字段；变量名中的后半部分NAME可以替换成任意响应头字段，如需要设置响应头Content-length，$sent_http_content_length即可$sent_http_cache_control$sent_http_connection$sent_http_content_type$sent_http_keep_alive$sent_http_last_modified$sent_http_location$sent_http_transfer_encoding 默认日志格式12345log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot;;#main为日志格式名 可以根据自己的情况定义不同的log格式.然后在日志的 path后调用access_log logs/it_access.log main; 当日志文件中记录的值为”-“时，表示为空 . 自定义的格式1log_format logstash &apos;$remote_addr|$http_host|$request|$http_referer|$status |$http_user_agent|$request_time|$remote_user&apos;; 个人定义了个logstash需要的日志格式.,这样就可以在logstash中进行match匹配正则了如下:1234567filter&#123; grok&#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;IP:clientIP&#125;\|%&#123;IP:serverIP&#125;\|%&#123;DATA:req_addr&#125;\|%&#123;DATA:req_url&#125;\|%&#123;DATA:req_status&#125;\|%&#123;DATA:req_browder&#125;\|%&#123;DATA:req_duration&#125;\|%&#123;DATA:req_user&#125;&quot; &#125; &#125;&#125;]]></content>
      <categories>
        <category>web</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[logstash配置文件]]></title>
    <url>%2F2017%2F10%2F22%2Flogstash%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[logstash以文件启动–配置文件编写 备忘 redis配置主要分三大块,input,filter,output,三块为同一级12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#这里的key值,来源filebeat采集时output的定义.input &#123; redis &#123; host =&gt; '10.1.27.31' data_type =&gt; 'list' key =&gt; 'network' &#125; redis &#123; host =&gt; '10.1.27.31' data_type =&gt; 'list' key =&gt; 'nginx-202' &#125;&#125;#这里的type来源于filebeat采集时input中的定义(document_type)filter &#123; if [type] == '93.218-zabbix' &#123; grok&#123; match =&gt; &#123; "message" =&gt; "%&#123;IP:clientIP&#125;\|%&#123;IP:serverIP&#125;\|%&#123;DATA:req_addr&#125;\|%&#123;DATA:req_url&#125;\|%&#123;DATA:req_status&#125;\|%&#123;DATA:req_browder&#125;\|%&#123;DATA:req_duration&#125;\|%&#123;DATA:req_user&#125;" &#125; &#125; &#125;#这里的match要根据日志格式进行匹配,这个主要是Nginx的日志#Nginx中对日志进行了自定的格式化.nginx参考格式#'$remote_addr|$http_host|$request|$http_referer|$status|$http_user_agent|$request_time|$remote_user'; if [type] == '93.218-it' &#123; grok&#123; match =&gt; &#123; "message" =&gt; "%&#123;IP:clientIP&#125;\|%&#123;IP:serverIP&#125;\|%&#123;DATA:req_addr&#125;\|%&#123;DATA:req_status&#125;\|%&#123;DATA:req_browder&#125;\|%&#123;DATA:req_duration&#125;\|%&#123;DATA:req_user&#125;" &#125; &#125; &#125;#同上,参考格式#'$remote_addr|$http_host|$request|$status|$http_user_agent|$request_time|$remote_user';&#125;#通过type判断,定义不同的index,kibana就能建立不同的mapoutput &#123; if [type] == '93.218-zabbix' &#123; elasticsearch &#123; hosts =&gt; '10.1.27.31' codec =&gt; 'json' index =&gt; '93.218-zabbix-%&#123;+YYYY.MM.dd&#125;' &#125; &#125; if [type] == '93.218-it' &#123; elasticsearch &#123; hosts =&gt; '10.1.27.31' codec =&gt; 'json' index =&gt; '93.218-it-%&#123;+YYYY.MM.dd&#125;' &#125; &#125;&#125; 过滤做好之后,可根据match的字段进行匹配,看自己想看的结果,以及后续的画图等]]></content>
      <categories>
        <category>运维工具</category>
        <category>elk</category>
      </categories>
      <tags>
        <tag>elk</tag>
        <tag>logstash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rsyslog网络日志收集]]></title>
    <url>%2F2017%2F10%2F18%2Frsyslog%E7%BD%91%E7%BB%9C%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%2F</url>
    <content type="text"><![CDATA[网络设备的日志较分散,集中管理一下,看日志就方便多了 软件rsyslogcentos7 默认安装 编辑参数1234vim /etc/sysconfig/rsyslog修改如下SYSLOGD_OPTIONS=&quot;-m 0 -r&quot;-m 0表示不在日志中添加时间戳消息，-r 表示允许接收外来日 修改配置1234567891011121314151617181920212223242526272829vim /etc/rsyslog.conf修改如下# Provides UDP syslog reception$ModLoad imudp #去掉注释$UDPServerRun 514#去掉注释# Provides TCP syslog reception$ModLoad imtcp#去掉注释$InputTCPServerRun 514#去掉注释#### GLOBAL DIRECTIVES #####添加日志接收模板：$template IpTemplate,&quot;/net-log/%FROMHOST-IP%_%$YEAR%-%$MONTH%-%$DAY%.log&quot;:FROMHOST-IP, !isequal, &quot;127.0.0.1&quot; ?IpTemplate #本地的不保存#*.* ?IpTemplate #表示所有的日志都通过模板进行保存&amp; ~###$template IpTemplate 指令让rsyslog进程把日志文件写入到/net-log下指定的log文件中，指定的log文件使用客户端的IP地址命名。&amp; ~表示的是重定向规则，告知rsyslog进程无需进一步处理日志消息，无需写入本地日志文件。#如果要把不同服务器发送过来的日志保存到不同的文件, 可以这样操作: #精确分类:fromhost-ip, isequal, “1.1.1.1″ /var/log/a.log :FROMHOST-IP, isequal, “2.2.2.2″ /var/log/2.log #根据网段分类:FROMHOST-IP, startswith, “3.3.3.” /var/log/c.log :FROMHOST-IP, startswith, “4.4.4.” /var/log/d.log 重启服务123systemctl restart rsyslog #查看进程状态。netstat -tulpn | grep rsyslog 配置交换机123全局模式中： logging &lt;ip-address|ipv6-address|hostname&gt; logging on]]></content>
      <categories>
        <category>运维工具</category>
        <category>elk</category>
      </categories>
      <tags>
        <tag>elk</tag>
        <tag>rsyslog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[filebeat客户端]]></title>
    <url>%2F2017%2F10%2F16%2Ffilebeat%E5%AE%A2%E6%88%B7%E7%AB%AF%2F</url>
    <content type="text"><![CDATA[Filebeat是一个日志文件托运工具，在你的服务器上filebeat后，它会监控日志目录或者指定的日志文件，追踪读取这些文件（追踪文件的变化，不停的读)并且转发这些信息到elasticsearch/logstarsh/redis/kafka/等等中 version : 5.6 日志的搜集,选择filebeat还是logstash 根据个人情况,filebeat相对来说更轻便 安装filebeat官网说明前提ELK已部署完毕.个人实验是输出到redis1234567DEB:curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.6.3-amd64.debsudo dpkg -i filebeat-5.6.3-amd64.debRPM:curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.6.3-x86_64.rpmsudo rpm -vi filebeat-5.6.3-x86_64.rpm filebeat.yml配置默认路径在 /etc/filebeat/filebeat.yml模板中有各种说明,输出到各种环境的配置,12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#以redis为例- input_type: log # Paths that should be crawled and fetched. Glob based paths. paths: - /usr/local/nginx-1.12.1/logs/*.log # - /usr/local/nginx-1.12.1/logs/*/*.log #子目录的log也会采集多日志,不同源采集:filebeat.prospectors:- input_type: log paths: - /net-log/10.4.32.1*.log fields: log_source: 10.4.32.1 fields_under_root: true document_type: 10.4.32.1- input_type: log paths: - /net-log/127.0.0.1*.log fields: log_source: 127.0.0.1 fields_under_root: true document_type: 127.0.0.1#fields_under_root: true #此配置使field字典的数据以顶级格式出现,#如果字段已存在,则覆盖.#document_type: 127.0.0.1,定义了type值,此值可在logstash以文件启动的配置中,if[&apos;type&apos;] == 或者 if value in [&apos;type&apos;] 进行判断归类.以为filter - paths: - /home/b/*.log fields: log_source: b#--------------------------------redis---------------------output.redis: hosts: [&quot;10.1.27.24&quot;] #必须 #password: &quot;your pwd&quot; db: 0 key: &quot;nginx&quot; #必须 timeout: 10##key值的作用key值会传递给redis/es/logstash等,所以key的定义可以起到一定日志分类的作用.logstash可以根据key值决定取出哪些值.存到es或其他存储中 参考(logstash文件启动配置)12345678910111213141516171819202122logstash的简单配置input &#123; redis &#123; host =&gt; &apos;10.1.27.24&apos; data_type =&gt; &apos;list&apos; key =&gt; &apos;nginx&apos; &#125;&#125;filter&#123; #if [] ... grok&#123; ... &#125;&#125;output &#123;#这里可以加判断,if &apos;a&apos; in [type]&#123;.....index =&gt; &apos;a-...&apos;&#125;#这样可以对日志更细致的划分,索引建立的更细致 elasticsearch &#123; hosts =&gt; &apos;10.1.27.23&apos; codec =&gt; &apos;json&apos; index =&gt; &apos;nginx-%&#123;+YYYY.MM.dd&#125;&apos; &#125; 输出到各环境的配置kafka,redis,es,logstash等 启动filebeat123rpm安装：sudo /etc/init.d/filebeat start]]></content>
      <categories>
        <category>运维工具</category>
        <category>elk</category>
      </categories>
      <tags>
        <tag>elk</tag>
        <tag>filebeat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elk部署]]></title>
    <url>%2F2017%2F10%2F14%2Felk%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[ELK并不是单个软件，它是一套解决方案。ELK由Elasticsearch、Logstash和Kibana三部分组件组成(封面图有个歧义,kinaba是从es中取数据的,为了方便理解传值,和logstash进行了连接.) Elasticsearch是个开源分布式搜索引擎Logstash开源的工具，它可以对你的日志进行收集、分析，并将其存储供以后使用kibana 开源和免费的工具，它可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面 默认端口号： elasticsearch：9200 9300 logstash : 9301 kinaba : 5601 流程图 下载相关软件包本次实验我使用的包版本如下：elasticsearch-5.6.2.tar.gz，kibana-5.6.2-linux-x86_64.tar.gz ，logstash-5.6.2.tar.gz，注意安装包版本于java版本的兼容行，这里使用的是java1.8+，centos7。 logstash安装logstash1234567891011121314#安装java，logstash运行依赖java，直接yum安装yum -y install java-1.8.0java -version#显示如下，安装成功openjdk version "1.8.0_144"OpenJDK Runtime Environment (build 1.8.0_144-b01)OpenJDK 64-Bit Server VM (build 25.144-b01, mixed mode)#解压logstash包tar -zxvf logstash-5.6.2.tar.gz -C /usr/local/#配置环境变量，方便敲命令echo "export PATH=\$PATH:/usr/local/logstash-5.6.2/bin" &gt; /etc/profile.d/logstash.sh. /etc/profile 运行logstash1234567891011121314logstash -e 'input&#123;stdin&#123;&#125;&#125;output&#123;stdout&#123;codec=&gt;rubydebug&#125;&#125;'#等待数秒后，随便输入字符串，将会得到如下json格式返回test&#123; "@version" =&gt; "1", "host" =&gt; "0.0.0.0", "@timestamp" =&gt; 2017-10-10T05:34:17.427Z, "message" =&gt; "test"&#125;#常用参数解释-e :指定logstash的配置信息，可以用于快速测试;-f :指定logstash的配置文件；可以用于生产环境; 以配置文件运行logstash123456[root@master config]# cat simple.conf input &#123; stdin &#123;&#125; &#125;output &#123; stdout &#123; codec=&gt; rubydebug &#125;&#125;logstash -f simple.conf 输出到redisredis要提前准备12345678910# cat logstash_to_redis.confinput &#123; stdin &#123; &#125; &#125;output &#123; stdout &#123; codec =&gt; rubydebug &#125; redis &#123; host =&gt; &apos;REDIS IP &apos; data_type =&gt; &apos;list&apos; key =&gt; &apos;logstash:redis&apos; &#125;&#125; 安装redis下载redis学习地址123456789101112131415tar -zxvf redis-4.0.2.tar.gz -C /usr/local/cd redis-4.0.2make#如果要执行make test 那么需要安装tcl#yum -y install tclmake install##如若报错zmalloc.h:50:31: error: jemalloc/jemalloc.h: No such file or directoryzmalloc.h:55:2: error: #error &quot;Newer version of jemalloc required&quot;make[1]: *** [adlist.o] Error 1make[1]: Leaving directory `/data0/src/redis-version/src&apos;make: *** [all] Error 2#解决办法是：make MALLOC=libc 运行redis12345678910111213141516#修改配置/usr/local/redis-version/redis.conf#修改 daemonize 为 yes #设置后台启动bind 为 0.0.0.0 #设置允许远程的地址cd srcredis-server ../redis.conf#查看进行(默认为6379端口)ps -aux | grep redis #通过客户端登录/usr/local/redis-version/src/redis-cli 127.0.0.1:6379&gt; pingPONG测试redis正常 输入到redis12345678910111213141516171819202122[root@master config]# cat redis.conf input &#123; stdin &#123; &#125; &#125;output &#123; stdout &#123; codec =&gt; rubydebug &#125; redis &#123; host =&gt; &apos;10.1.27.24&apos; data_type =&gt; &apos;list&apos; key =&gt; &apos;logstash:redis&apos; &#125;&#125;#运行 logstash -f redis.conf输入test，返回如下&#123; &quot;@version&quot; =&gt; &quot;1&quot;, &quot;host&quot; =&gt; &quot;0.0.0.0&quot;, &quot;@timestamp&quot; =&gt; 2017-10-10T06:25:42.830Z, &quot;message&quot; =&gt; &quot;test&quot;&#125;去redis查看[root@slave redis-4.0.2]# ./src/redis-cli monitor #这个要在logstash前打开OK1507616746.341355 [0 10.1.27.23:59337] &quot;rpush&quot; &quot;logstash:redis&quot; &quot;&#123;\&quot;@version\&quot;:\&quot;1\&quot;,\&quot;host\&quot;:\&quot;0.0.0.0\&quot;,\&quot;@timestamp\&quot;:\&quot;2017-10-10T06:25:42.830Z\&quot;,\&quot;message\&quot;:\&quot;test\&quot;&#125;&quot; 后台运行1nohup logstash -f /usr/local/logstash-version/config/conf.d/filename.conf &amp;&gt;/dev/null &amp; elasticsearch安装Elasticsearch默认不能用root用户启动123456789#添加用户和组groupadd esuseradd es -g es -p passwordchown -R es:es /usr/local/elasticsearch-5.6.2# 启动ES（3种方式）su - es/usr/local/elasticsearch-5.6.2/bin/elasticsearch/usr/local/elasticsearch-5.6.2/bin/elasticsearch -d #守护进程方式启动nohup /usr/local/elasticsearch-5.6.2/bin/elasticsearch &gt; /var/log/es.log 2&gt;&amp;1 &amp; #推荐 es报错解决方案 12345678910111213141516171819202122ERROR: [2] bootstrap checks failed[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536][2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]【1】无法创建文件，用户最大可创建文件数太小#切换到root用户vim /etc/security/limits.conf#添加以下内容* soft nofile 65536* hard nofile 131072* soft nproc 2048* hard nproc 4096#普通用户可以使用内存锁* soft memlock unlimited * hard memlock unlimited【2】虚拟内存太小#切换到rootvi /etc/sysctl.conf#添加内容：vm.max_map_count=655360#运行命令生效sysctl -p 检查es启动状态,并访问1234567891011121314151617181920212223[root@master ~]# netstat -tnlp |grep javatcp6 0 0 :::9200 :::* LISTEN 14610/java tcp6 0 0 :::9300 :::* LISTEN 14610/java#http://IPADDRESS:9200/&#123; "name" : "-fiwSlM", "cluster_name" : "elasticsearch", #默认的集群名 "cluster_uuid" : "biIeKipDSyKCRpS84bb0Ng", "version" : &#123; "number" : "5.6.2", "build_hash" : "57e20f3", "build_date" : "2017-09-23T13:16:45.703Z", "build_snapshot" : false, "lucene_version" : "6.6.1" &#125;, "tagline" : "You Know, for Search"&#125;此时目录下会多个data文件夹，默认的数据目录 elasticsearch配置文件详解[root@es-node-01 ~]# cat /usr/local/elasticsearch-6.6.2/config/elasticsearch.yml | grep ^[a-Z] 集群名,多个节点定义统一名字cluster.name: zili-es-cluster #节点名,自定义node.name: zilies-1 数据和日志目录.用户要有权限读写path.data: /usr/local/elasticsearch-6.6.2/datapath.logs: /usr/local/elasticsearch-6.6.2/logs 内存锁定.普通用户支持内存所需另外设置bootstrap.memory_lock: true 当前地址network.host: 192.168.1.130http.port: 9200 集群内主机discovery.zen.ping.unicast.hosts: [“192.168.1.130”, “192.168.1.131”,”192.168.1.132”] (集群总节点数量/2)+1discovery.zen.minimum_master_nodes: 2 http://192.168.1.130:9200/_cluster/health?pretty 可查看集群相关信息======================= 此链接为出处 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121elasticsearch-.yml（中文配置详解）# ======================== Elasticsearch Configuration =========================## NOTE: Elasticsearch comes with reasonable defaults for most settings.# Before you set out to tweak and tune the configuration, make sure you# understand what are you trying to accomplish and the consequences.## The primary way of configuring a node is via this file. This template lists# the most important settings you may want to configure for a production cluster.## Please see the documentation for further information on configuration options:# &lt;http://www.elastic.co/guide/en/elasticsearch/reference/current/setup-configuration.html&gt;## ---------------------------------- Cluster -----------------------------------## Use a descriptive name for your cluster:# 集群名称，默认是elasticsearch# cluster.name: my-application## ------------------------------------ Node ------------------------------------## Use a descriptive name for the node:# 节点名称，默认从elasticsearch-2.4.3/lib/elasticsearch-2.4.3.jar!config/names.txt中随机选择一个名称# node.name: node-1## Add custom attributes to the node:# # node.rack: r1## ----------------------------------- Paths ------------------------------------## Path to directory where to store the data (separate multiple locations by comma):# 可以指定es的数据存储目录，默认存储在es_home/data目录下# path.data: /path/to/data## Path to log files:# 可以指定es的日志存储目录，默认存储在es_home/logs目录下# path.logs: /path/to/logs## ----------------------------------- Memory -----------------------------------## Lock the memory on startup:# 锁定物理内存地址，防止elasticsearch内存被交换出去,也就是避免es使用swap交换分区# bootstrap.memory_lock: true#### 确保ES_HEAP_SIZE参数设置为系统可用内存的一半左右# Make sure that the `ES_HEAP_SIZE` environment variable is set to about half the memory# available on the system and that the owner of the process is allowed to use this limit.# # 当系统进行内存交换的时候，es的性能很差# Elasticsearch performs poorly when the system is swapping the memory.## ---------------------------------- Network -----------------------------------### 为es设置ip绑定，默认是127.0.0.1，也就是默认只能通过127.0.0.1 或者localhost才能访问# es1.x版本默认绑定的是0.0.0.0 所以不需要配置，但是es2.x版本默认绑定的是127.0.0.1，需要配置# Set the bind address to a specific IP (IPv4 or IPv6):## network.host: 192.168.0.1### 为es设置自定义端口，默认是9200# 注意：在同一个服务器中启动多个es节点的话，默认监听的端口号会自动加1：例如：9200，9201，9202...# Set a custom port for HTTP:## http.port: 9200## For more information, see the documentation at:# &lt;http://www.elastic.co/guide/en/elasticsearch/reference/current/modules-network.html&gt;## --------------------------------- Discovery ----------------------------------## 当启动新节点时，通过这个ip列表进行节点发现，组建集群# 默认节点列表：# 127.0.0.1，表示ipv4的回环地址。# [::1]，表示ipv6的回环地址## 在es1.x中默认使用的是组播(multicast)协议，默认会自动发现同一网段的es节点组建集群，# 在es2.x中默认使用的是单播(unicast)协议，想要组建集群的话就需要在这指定要发现的节点信息了。# 注意：如果是发现其他服务器中的es服务，可以不指定端口[默认9300]，如果是发现同一个服务器中的es服务，就需要指定端口了。# Pass an initial list of hosts to perform discovery when new node is started:# # The default list of hosts is ["127.0.0.1", "[::1]"]## discovery.zen.ping.unicast.hosts: ["host1", "host2"]## 通过配置这个参数来防止集群脑裂现象 (集群总节点数量/2)+1# Prevent the "split brain" by configuring the majority of nodes (total number of nodes / 2 + 1):## discovery.zen.minimum_master_nodes: 3## For more information, see the documentation at:# &lt;http://www.elastic.co/guide/en/elasticsearch/reference/current/modules-discovery.html&gt;## ---------------------------------- Gateway -----------------------------------## Block initial recovery after a full cluster restart until N nodes are started:# 一个集群中的N个节点启动后,才允许进行数据恢复处理，默认是1# gateway.recover_after_nodes: 3## For more information, see the documentation at:# &lt;http://www.elastic.co/guide/en/elasticsearch/reference/current/modules-gateway.html&gt;## ---------------------------------- Various -----------------------------------# 在一台服务器上禁止启动多个es服务# Disable starting multiple nodes on a single system:## node.max_local_storage_nodes: 1## 设置是否可以通过正则或者_all删除或者关闭索引库，默认true表示必须需要显式指定索引库名称# 生产环境建议设置为true，删除索引库的时候必须显式指定，否则可能会误删索引库中的索引库。# Require explicit names when deleting indices:## action.destructive_requires_name: true 集群名称，默认是elasticsearch 输入，http://192.168.80.200:9200/ logstash和elasticsearch结合 结合有两种方法，直接结合，通过redis结合 直接结合123456789#编写logstash配置文件# cat logstash-elasticsearch.conf input &#123; stdin &#123;&#125; &#125;output &#123; elasticsearch &#123; hosts =&gt; "IPADDRESS" &#125; #此处用hosts stdout &#123; codec=&gt; rubydebug &#125;｝#通过配置文件启动logstash即可 与redis结合 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# cat config/logstash-redis.confinput &#123; redis &#123; host =&gt; '10.1.27.24' #redis地址 data_type =&gt; 'list' key =&gt; 'logstash:redis' &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; '10.1.27.23' #hosts codec =&gt; 'json' &#125;&#125;#http://10.1.27.23:9200/_search?pretty#浏览器访问es地址，会发现redis的内容也会显示出来。&#123; "took" : 7, "timed_out" : false, "_shards" : &#123; "total" : 10, "successful" : 10, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 7, "max_score" : 1.0, "hits" : [ &#123; "_index" : "logstash-2017.10.11", "_type" : "logs", "_id" : "AV8JbX8-FBpUgNjayMTu", "_score" : 1.0, "_source" : &#123; "@version" : "1", "host" : "0.0.0.0", "@timestamp" : "2017-10-11T03:14:51.802Z", "message" : "ceshi" #此消息为直接结合的 &#125; &#125;, &#123; "_index" : "logstash-2017.10.11", "_type" : "redis-input", "_id" : "AV8KRKarFBpUgNjayMT2", "_score" : 1.0, "_source" : &#123; "@version" : "1", "host" : "0.0.0.0", "@timestamp" : "2017-10-11T07:09:29.575Z", "message" : "redisredisredisredisredisredis", #此内容为redis "type" : "redis-input" #这里可以看出，类型为配置里定义的类型名 &#125; &#125;, &#125; ] &#125;&#125; Kinaba安装kibana1# tar zxf kibana--VERSION -C /usr/local 配置1234567vim /usr/local/kibana-VERSION /config/kibana.yml#修改如下server.host: &quot;0.0.0.0&quot;elasticsearch_url: &quot;http://es的IP地址:9200&quot;#访问kibana地址http://10.1.27.23:5601 启动1/usr/local/kibana-VERSION-linux-x64/bin/kibana 点击Create 创建一个索引 然后点击左侧discovery 发现es的日志，选择时间段即可查看日志 ELK部署，完。 访问出现 换个浏览器访问]]></content>
      <categories>
        <category>运维工具</category>
        <category>elk</category>
      </categories>
      <tags>
        <tag>elk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[oracle-11g安装-linux]]></title>
    <url>%2F2017%2F09%2F22%2Foracle%E5%AE%89%E8%A3%85-linux%2F</url>
    <content type="text"><![CDATA[需要图形化 内存大小 swap空间需求 4G &lt; mem &lt;8G 2*mem 8G &lt; mem &lt;32G 1.5*mem 32G &lt; mem 32G 硬件环境系统需要图形化 内存内存: 大于4G grep MemTotal /proc/meminfoswap: grep SwapTotal /proc/meminfo 内存大小 swap空间需求 4G &lt; mem &lt;8G 2*mem 8G &lt; mem &lt;32G 1.5*mem 32G &lt; mem 32G 硬盘/tmp 空间大于1G df -h /tmp空间需求 安装模式 软件所需空间 数据文件所需空间 企业版 Enterprise Edition 4.35G 1.68G 标准版 Standard Edition 3.73G 1.48G 软件环境hosts123vim /etc/hosts#添加信息格式如下IP hostname #10.1.27.25 oracle 软件包12345678910111213141516171819202122232425262728293031binutilscompat-libcap1compat-libstdc++-33elfutils-libelfelfutils-libelf-develgcc-4.1.2 gcc-c++-4.1.2 glibc-2.5-24 glibc-2.5-24 (32 bit) glibc-common-2.5 glibc-devel-2.5 glibc-devel-2.5 (32 bit) glibc-headers-2.5 ksh-20060214 libaio-0.3.106libaio-0.3.106 (32 bit)libaio-devel-0.3.106 libaio-devel-0.3.106 (32 bit) libgcc-4.1.2libgcc-4.1.2 (32 bit) libstdc++-4.1.2 libstdc++-4.1.2 (32 bit) libstdc++-devel 4.1.2 make-3.81 numactl-devel-0.9.8.x86_64 sysstat-7.0.2 unixODBC-2.2.11 (32-bit) or laterunixODBC-devel-2.2.11 (64-bit) or laterunixODBC-2.2.11 (64-bit) or later 检查方法：#rpm -q 包名称 //不需要写后面的版本号安装方法：#rpm –ivh 包名称也可以通过yum安装 用户和组可在/etc/groups 查看12345groupadd oinstall –g 1000 #指定组IDgroupadd dba –g 1001groupadd oper –g 1002useradd -g oinstall -G dba oracle #oracle所属组和附加组passwd oracle #设置密码 核心参数vim /etc/sysctl.conf1234567891011121314151617181920添加以下内容：fs.aio-max-nr = 1048576fs.file-max = 6815744kernel.shmall = 2097152kernel.shmmax = 536870912kernel.shmmni = 4096kernel.sem = 250 32000 100 128 net.ipv4.ip_local_port_range = 9000 65500 net.core.rmem_default = 262144 net.core.rmem_max = 4194304 net.core.wmem_default = 262144 net.core.wmem_max = 1048586 #安装oracle 12C 内核有变动，值如下。shmmax 67286788096shmall 131419502. 使核心参数生效# /sbin/sysctl –p vim /etc/security/limits.conf123456#添加以下内容：oracle soft nproc 2047 oracle hard nproc 16384 oracle soft nofile 1024 oracle hard nofile 65536 oracle soft stack 10240 /etc/pam.d/login12添加以下内容：session required pam_limits.so vi /etc/profile12345678910添加以下内容：if [ $USER = &quot;oracle&quot; ]; then if [ $SHELL = &quot;/bin/ksh&quot; ]; then ulimit -p 16384 ulimit -n 65536 else ulimit -u 16384 ulimit -n 65536 fifi 配置说明原链接更为详细ulimit 1.只对当前tty（终端有效），若要每次都生效的话，可以把ulimit参数放到对应用户的.bash_profile里面或/etc/profile；2.ulimit命令本身就有分软硬设置，加-H就是硬，加-S就是软；3.默认显示的是软限制，如果运行ulimit命令修改的时候没有加上的话，就是两个参数一起改变.生效；123456789101112131415命令参数-H 设置硬件资源限制.-S 设置软件资源限制.-a 显示当前所有的资源限制.-c size:设置core文件的最大值.单位:blocks-d size:设置数据段的最大值.单位:kbytes-f size:设置创建文件的最大值.单位:blocks-l size:设置在内存中锁定进程的最大值.单位:kbytes-m size:设置可以使用的常驻内存的最大值.单位:kbytes-n size:设置内核可以同时打开的文件描述符的最大值.单位:n-p size:设置管道缓冲区的最大值.单位:kbytes-s size:设置堆栈的最大值.单位:kbytes-t size:设置CPU使用时间的最大上限.单位:seconds-v size:设置虚拟内存的最大值.单位:kbytesunlimited 是一个特殊值，用于表示不限制 /etc/security/limit.conf 和vim /etc/sysctl.conf一个是针对用户的,一个是针对系统的要使 limits.conf 文件配置生效，必须要确保 pam_limits.so 文件被加入到启动文件中,所以修改/etc/pam.d/login,并添加相关内容 创建目录123mkdir -p /u01/app/chown -R oracle:oinstall /u01/app/ chmod -R 775 /u01/app/ oracle用户环境变量vi /home/oracle/.bash_profile123456789101112export TMP=/tmpexport TMPDIR=$TMPexport ORACLE_BASE=/u01/app/oracleexport ORACLE_HOME=$ORACLE_BASE/product/11.2.0/db_1export ORACLE_SID=db11gexport ORACLE_TERM=xtermexport PATH=/usr/sbin:$PATHexport PATH=$ORACLE_HOME/bin:$PATHexport LD_LIBRARY_PATH=$ORACLE_HOME/lib:/lib64:/usr/lib64:/usr/local/lib64:/usr/X11R6/lib64/export CLASSPATH=$ORACLE_HOME/JRE:$ORACLE_HOME/jlib:$ORACLE_HOME/rdbms/jlibexport NLS_LANG=&quot;SIMPLIFIED CHINESE_CHINA.ZHS16GBK&quot;umask 022 下载解压包12链接: https://pan.baidu.com/s/1nvIGppJ密码: whna 安装oracle切换oracle 用户，进入解压路径下 database 目录，运行./runInstaller 命令，开始安装 Next—-&gt; Yes 选择”Skip Software updates”,点击”Next”按钮 选择”Install database software only”,点击”Next”按钮 选择”Single instance database installation”，点击”Next”按钮 将”Simplified Chinese”通过”&gt;”按钮添加到”Selected Languages”，点击”Next”按钮 选择”Enterprise Edition”,点击”Next”按钮 确认”Oracle Base”,”Software Location”路径,点击”Next”按钮 确认”Inventory Directory”路径和”oraInventory Group Name”用户组,点击”Next”按钮 确认 database 相关的用户组，第二行选择 oper 用户组，点击”Next”按钮 如果出现缺少pdksh-5.2.14 忽略即可.新的oracle都使用ksh包了,这个安装了就好 点击”Install”按钮，开始安装 等待安装完成(会提示登录root,执行脚本) 用 root 用户先执行orainstRoot.sh脚本，完成之后再用 root 用户执行 root.sh 脚本 点击”OK”按钮 点击”Close”按钮 –完成 创建监听使用 oracle 用户执行 netca 命令创建监听 选择”Listener configuration”,点击”Next”按钮 选择”Add”,点击”Next”按钮 Listener name(可默认) 点击”Next”按钮 选择tcp协议.点击”Next”按钮 选择”Use the standard port number of 1521”,点击”Next”按钮 选择”No”,点击”Next”按钮 点击”Next”按钮 点击”Finish”按钮 创建数据库使用 oracle 用户执行 dbca 命令创建数据库 点击”Next”按钮 选择”Create a Database” ，点击“Next” 按钮 选择”General Purpose or Transaction Processing”类型。生成环境按需求选择,一般选择”Custom Database”类型。 点击”Next”按钮 输入”Golbal Database Name”,”SID Prefix”:db11g 点击”Next”按钮 不勾选”Configure Enterprise Manager”,点击”Next”按钮 勾选use the same …输入 sys,system 统一密码:oracle 点击”Next”按钮 提示密码不符合 Oracle 推荐要求，忽略，点击”Yes”按钮 选择”Storage Type”为”File System”选择”使用 Oracle-Managed Files”,在”Database File Location”输入:{ORACLE_BASE}/oradata 点击”Next”按钮 不勾选”Specify Fast Recovery Area”和”Enable Archiving”,点击”Next”按钮 把复选框都去掉勾,点击”Next”按钮 在”Memory”选项卡选择”Typical” 自动分配内存 在”调整内存”选项卡中，设置最大进程数为500 在”Character Sets”选项卡选择”Choose from the list of character sets”, 选择 “ZHS16GBK”，“Default Territory”选项卡选择 China，点击“Next”按钮 将重做日志组调整为5组，每组2个大小为128m 的重做日志文件，点击“下一步” 勾选create database 和 Generate Database Create Scripts 点击”Finish”按钮 点击”OK”按钮 脚本创建完成，点击”OK”按钮 点击”Exit”按钮退出，至此，数据库创建完成。 其他配置取消密码限制12345678910111213141516sqlplus “/as sysdba”SQL&gt; ALTER PROFILE DEFAULT LIMIT COMPOSITE_LIMIT UNLIMITED;ALTER PROFILE DEFAULT LIMIT SESSIONS_PER_USER UNLIMITED;ALTER PROFILE DEFAULT LIMIT CPU_PER_SESSION UNLIMITED;ALTER PROFILE DEFAULT LIMIT CPU_PER_CALL UNLIMITED;ALTER PROFILE DEFAULT LIMIT LOGICAL_READS_PER_SESSION UNLIMITED;ALTER PROFILE DEFAULT LIMIT LOGICAL_READS_PER_CALL UNLIMITED;ALTER PROFILE DEFAULT LIMIT IDLE_TIME UNLIMITED;ALTER PROFILE DEFAULT LIMIT CONNECT_TIME UNLIMITED;ALTER PROFILE DEFAULT LIMIT PRIVATE_SGA UNLIMITED;ALTER PROFILE DEFAULT LIMIT FAILED_LOGIN_ATTEMPTS UNLIMITED;ALTER PROFILE DEFAULT LIMIT PASSWORD_LIFE_TIME UNLIMITED;ALTER PROFILE DEFAULT LIMIT PASSWORD_REUSE_TIME UNLIMITED;ALTER PROFILE DEFAULT LIMIT PASSWORD_REUSE_MAX UNLIMITED;ALTER PROFILE DEFAULT LIMIT PASSWORD_LOCK_TIME UNLIMITED;ALTER PROFILE DEFAULT LIMIT PASSWORD_GRACE_TIME UNLIMITED; 关闭数据库审计12345678910111213141516171819202122232425262728293031321、查看审计功能是否开启su – oraclesqlplus “/as sysdba”SQL&gt; show parameter audit_trailNAME TYPE VALUE-------------------- ----------- ------------------------------audit_trail string DB说明：VALUE值为DB，表面审计功能为开启的状态2、关闭oracle的审计功能SQL&gt; alter system set audit_trail=FALSE scope=spfile;System altered.3、重启数据库SQL&gt; shutdown immediate;SQL&gt; startup; 4、验证审计是否已经被关闭SQL&gt; show parameter audit_trailNAME TYPE VALUE------------- ----------- ------------------------------audit_trail string FALSE说明：VALUE值为FALSE，表面审计功能为关闭的状态lsnrctl status 监听状态查看SQL&gt; show user --显示当前连接用户 SQL&gt; show error --显示错误sqlplus /nolog SQL&gt;connect / as sysdba ;查看当前的所有数据库: select * from v$database; select name from v$database;进入test数据库：database test; 查看所有的数据库实例：select * from v$instance;更改数据库用户的密码：(将sys与system的密码改为test.)alter user sys indentified by test;alter user system indentified by test;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql主从同步]]></title>
    <url>%2F2017%2F09%2F04%2Fmysql%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[数据库,还是做个备份吧…前提：数据库版本一致，初始化数据一致（数据库一致） 主服务器新建同步用户12GRANT REPLICATION SLAVE ON *.* TO backup@&apos;%&apos; IDENTIFIED BY &apos;backup&apos;;#新建backupDB用户，%代表任何ip都可连接， 密码backup 修改配置/etc/my.cnf 12345678910111213141516171819202122232425262728293031323334353637[mysqld]log-bin=/var/lib/mysql/mysql-bin#二进制文件保存位置,这些文件是mysql的事务日志记录。server-id=1 #唯一标示#最大连接数,按需更改max_connections=10000character-set-server=utf8#每个bin-log最大大小，当此大小等于500M时会自动生成一个新的日志文件。一条记录不会写在2个日志文件中，所以有时日志文件会超过此大小。max_binlog_size = 500M#日志缓存大小binlog_cache_size = 128K#当Slave从Master数据库读取日志时更新新写入日志中，如果只启动log-bin而没有启动log-slave-updates则Slave只记录针对自己数据库操作的更新。log-slave-updates#设置bin-log日志文件保存的天数，此参数mysql5.0以下版本不支持。expire_logs_days=30#设置bin-log日志文件格式为：MIXED，可以防止主键重复。binlog_format=&quot;MIXED&quot;#要同步的数据库,可指定多个,需复制此参数#binlog-do-db=zabbix #binlog-do-db=it#要同步多个数据库，就在slave多加几个replicate-db-db=数据库名#binlog_ignore_db=mysql #忽略的数据库#binlog_ignore_db=information_schema#binlog_ignore_db=performance_schema#auto-increment-increment = 10#auto-increment-offset=1#这俩设置标示这台服务器上插入的第一个id就是 1， 第二行的id就是 11了,主主备份可以避免重复 复制的几种模式解释123456789– 基于SQL语句的复制(statement-based replication, SBR)，– 基于行的复制(row-based replication, RBR)，– 混合模式复制(mixed-based replication, MBR)。相应地，binlog的格式也有三种：STATEMENT，ROW，MIXED。 MBR 模式中，SBR 模式是默认的。在运行时可以动态改动 binlog的格式，除了以下几种情况：1.存储流程或者触发器中间2.启用了NDB3.当前会话试用 RBR 模式，并且已打开了临时表如果binlog采用了 MIXED 模式，那么在以下几种情况下会自动将binlog的模式由 SBR 模式改成 RBR 模式 mysql-bin123456789101112systemctl restart mariadb.service#锁表,禁止写操作.FLUSH TABLES WITH READ LOCK;MariaDB [(none)]&gt; show master status;+------------------+----------+--------------+---------------------------------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |+------------------+----------+--------------+---------------------------------------------+| mysql-bin.000001 | 245 | it | mysql,information_schema,performance_schema |+------------------+----------+--------------+---------------------------------------------+1 row in set (0.00 sec) 这里要注意 | mysql-bin.000001 | 245 后面的从服务会用到所以，此时，就不要对主数据库进行操作了，以免值变化。 从服务器从服务如果是克隆的主服务器,需要注意 data/mysql.auto.cnf删除,并重启服务器.否则无法完成克隆因为两台服务器mysql的server-uuid 是相同的. 修改配置/etc/my.cnf 12345678910111213141516171819202122232425262728server-id=2 #唯一标示#只读,建议开启,防止slave写了数据导致主从出现问题.read_only=on#replicate-do-db=it#下面这些主要是做主主配置#log-bin=/var/lib/mysql/mysql-bin #二进制文件保存位置#log_slave_updates = 1 #slave将复制事件写进自己的二进制日志slave-skip-errors=1007,1008,1053,1062,1213,1158,1159#error code代表的错误如下： 1007：数据库已存在，创建数据库失败 1008：数据库不存在，删除数据库失败 1050：数据表已存在，创建数据表失败 1051：数据表不存在，删除数据表失败 1053：复制过程中主服务器宕机 1054：字段不存在，或程序文件跟数据库有冲突 1060：字段重复，导致无法插入 1061：重复键名 1062：主键冲突 Duplicate entry &apos;%s&apos; for key %d 1068：定义了多个主键 1094：位置线程ID 1146：数据表缺失，请恢复数据库 1158：网络错误，出现读错误，请检查网络连接状况 1159：网络错误，读超时，请检查网络连接状况 1213: 死锁 重启并进入数据库123456789101112131415161718192021222324252627282930systemctl restart mariadb.service#这里用到了master数据库的状态值change master to master_host=&apos;10.1.*.*(master的IP)&apos;,master_user=&apos;backup&apos;,master_password=&apos;backup&apos;,master_log_file=&apos;mysql-bin.000001&apos;,master_log_pos=245;#开启slavestart slave#查看状态MariaDB [(none)]&gt; show slave status\G*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 10.1.。。。 Master_User: backup Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000001 Read_Master_Log_Pos: 468 Relay_Log_File: mariadb-relay-bin.000002 Relay_Log_Pos: 529 Relay_Master_Log_File: mysql-bin.000001 Slave_IO_Running: Yes #这里要是YES Slave_SQL_Running: Yes #这里要是YES Replicate_Do_DB: it略....#记得解锁主库UNLOCK TABLES; 然后主服务器又任何操作，从服务器就同步过来了。 其他关于主从备份优缺点机制等,推荐阅读 解除主从两个办法 彻底解除主从复制关系 stop slave; reset slave; #或直接删除master.info和relay-log.info这两个文件 修改my.cnf删除主从相关配置参数 让slave不随MySQL自动启动修改my.cnf在[mysqld]中增加 skip-slave-start 选项 mysqldump需注意mysqldump --master-data --single-transaction --user=username --password=password dbname&gt; dumpfilename 这样就可以保留 file 和 position 的信息，在新搭建一个slave的时候，还原完数据库 file 和 position 的信息也随之更新，接着再start slave 就可以很迅速的完成增量同步！ 链条式同步 如果想实现 主-从（主）-从 这样的链条式结构，需要设置：log-slave-updates #只有加上它，从前一台机器上同步过来的数据才能同步到下一台机器 二进制日志也是必须开启的：log-bin=/opt/mysql/binlogs/bin-loglog-bin-index=/opt/mysql/binlogs/bin-log.index 还可以设置一个log保存周期：expire_logs_days=14]]></content>
      <categories>
        <category>database</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx负载/反向代理]]></title>
    <url>%2F2017%2F08%2F18%2Fnginx%E7%AE%80%E5%8D%95%E7%9A%84%E8%B4%9F%E8%BD%BD-%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[用Nginx实现简单的负载和代理转发. 安装Nginxnginx默认使用80端口，请确保80未被使用12345678910111213141516171819202122Nginx# wget http://www.nginx.org/download/nginx-[version].tar.gzNginx cache purge 模块(可选)# wget http://labs.frickle.com/files/ngx_cache_purge-[version].tar.gz#编译安装./configure \--prefix=/usr/local/nginx-[version] \--with-http_stub_status_module \--with-http_ssl_module \--with-http_realip_module \ --add-module=../ngx_cache_purge-1.3# make# make install#启动，停止，重载nginx/usr/local/nginx-[version]/sbin/nginx #启动/usr/local/nginx-[version]/sbin/nginx -t #测试，检测配置/usr/local/nginx-[version]/sbin/nginx -s stop/usr/local/nginx-[version]/sbin/nginx -s reload打开浏览器，访问nginx地址，出现welcome nginx则配置成功 nginx 负载新建配置文件blance-test.conf然后在nginx.conf 中include blance-test.conf1234567891011121314151617upstream blance-test &#123; server 192.168.1.11:80; server 192.168.1.22:80;&#125;server&#123; listen 80; server_name www.example.com; location / &#123; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://blance-test; &#125; access_log logs/blance-test_access.log;&#125; proxy_set_header12345678910111213141516171819重点看下proxy_set_header X-Forwarded-For当使用了代理时，web服务器无法取得真实IP，为了避免这个情况，代理服务器通常会增加一个叫做x_forwarded_for的头信息，把连接它的客户端IP（即客户端IP）加到这个头信息里，这样就能保证网站的web服务器能获取到真实IP$host #请求中的主机头(Host)字段，如果请求中的主机头不可用或者空，则为处理请求的server名称(处理请求的server的server_name的值)。小写，不含端口。$remote_addr; #客户端的IP地址（中间无代理则是真实客户端IP，有代理则是代理IP）$proxy_add_x_forwarded_for; #就是$http_x_forwarded_for加上$remote_addr 官方解释 $proxy_add_x_forwarded_forthe “X-Forwarded-For” client request header field with the $remote_addr variable appended to it, separated by a comma. If the “X-Forwarded-For” field is not present in the client request header, the $proxy_add_x_forwarded_for variable is equal to the $remote_addr variable. nginx 反向代理可选配置，与http同级12345678910111213client_max_body_size 50m; #缓冲区代理缓冲用户端请求的最大字节数 client_body_buffer_size 256k; client_header_timeout 3m; client_body_timeout 3m; send_timeout 3m; proxy_connect_timeout 300s; #nginx跟后端服务器连接超时时间(代理连接超时) proxy_read_timeout 300s; #连接成功后，后端服务器响应时间(代理接收超时) proxy_send_timeout 300s; proxy_buffer_size 64k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 proxy_buffers 4 32k; #proxy_buffers缓冲区，网页平均在32k以下的话，这样设置 proxy_busy_buffers_size 64k; #高负荷下缓冲大小（proxy_buffers*2） proxy_temp_file_write_size 64k; #设定缓存文件夹大小，大于这个值，将从upstream服务器传递请求，而不缓冲到磁盘 proxy_ignore_client_abort on; #不允许代理端主动关闭连接 新建配置文件reverse-proxy.conf然后在nginx.conf 中include reverse-proxy.conf12345678910111213141516171819202122232425server &#123; listen 7001; server_name 192.168.1.202:7001; charset utf-8; location /console &#123; # proxy_set_header Host $host:$proxy_port; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://192.168.1.11:7001; &#125; access_log logs/192.168.1.11:7001_access.log;&#125;server &#123; listen 8001; server_name 192.168.1.202:8001; charset utf-8; location / &#123; proxy_set_header Host $host:$proxy_port; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://192.168.1.11:8001; &#125; access_log logs/192.168.1.11:8001_access.log;&#125; 这里要说明下12345678910111213server_name #主要用于配置基于名称的虚拟主机，可匹配正则，如果没有域名可填写IP，不填或随便填写一个#nginx 根据 server_name 匹配 HTTP 请求头的 host，去决定使用那个 server#如果都没有匹配则使用默认的。如果没有默认就是第一个server$http_host 和 $host的区别$host 上边描述过，主机头(Host)字段，如果不可用或空就是server_name的值。$http_host 可以理解请求地址，即浏览器中你输入的地址（IP或域名）那么这两个使用哪个好一些呢？如果Host请求头部没有出现在请求头中，则$http_host值为空，但是$host值为主域名，一般而言，会用$host代替$http_host，避免http请求中丢失Host头部的情况下Host不被重写。如果对端口又要求可加上 :$proxy_port 官方关于nginx 代理模块的文章 Nginx访问日志 IP统计awk ‘{print $1}’ access.log | sort | uniq -c|sort -n]]></content>
      <categories>
        <category>web</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ssh不能连接(yum被破坏)]]></title>
    <url>%2F2017%2F08%2F09%2Fssh%E4%B8%8D%E8%83%BD%E8%BF%9E%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[同事反应，云主机能ping但ssh不上。本地登录后，检查防火墙,ssh服务，发现服务没有了，然后就想安装openssh-server,结果yum不能用了 1234YumRepo Error: All mirror URLs are not using ftp, http[s] or file. /Eg. removing mirrorlist with no valid mirrors: /var/cache/yum/x86_64/6/base/mirrorlist.txt Error: Cannot find a valid baseurl for repo: base 查看防火墙，网络状态，以及DNS。能否ping通yum源。mirrorlist.centos.org能通则可以排除网络问题 检查仓库是否正常,检查变量等信息是否正常。123456789101112131415161718lsb_release -a能否正常显示版本号等信息LSB Version: :base-4.0-amd64:base-4.0-noarch:core-4.0-amd64:core-4.0-noarch:graphics-4.0-amd64:graphics-4.0-noarch:printing-4.0-amd64:printing-4.0-noarchDistributor ID: CentOSDescription: CentOS release 6.7 (Final)Release: 6.7Codename: Final# rpm -q --qf %&#123;version&#125; centos-release;echo6# rpm -q --qf %&#123;arch&#125; centos-release;echox86_64不正常则备份仓库配置，并手动修改*.repo文件，将$releasever变量全替换成6即可正常yum了。如果是7版本则换成7]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>ssh</tag>
        <tag>yum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git拉取权限拒绝]]></title>
    <url>%2F2017%2F08%2F03%2Fgit%E6%8B%89%E5%8F%96%E6%9D%83%E9%99%90%E6%8B%92%E7%BB%9D%2F</url>
    <content type="text"><![CDATA[自己挖的坑…由于昨晚在家新增和修改了文件,今早到公司就进行了个pull的操作1234来自 git.oschina.net:user/django * branch master -&gt; FETCH_HEAD更新 c1dc841..f21e3feerror: unable to unlink old &apos;study/app1/__pycache__/__init__.cpython-35.pyc&apos; (权限不够) 全是权限不足,第一反应是sudo的原因.没多想就直接sudo操作了,然后提示 12345Permission denied (publickey).fatal: Could not read from remote repository.Please make sure you have the correct access rightsand the repository exists. 搜索 解决办法都是说重新生成秘钥.然后复制到git.但是自己的密钥并没有变更过,以防万一,还是操作了一遍. 并没有解决问题. 想想如果不是远程的问题,那就是本地的了. 原来昨晚创建了新的文件夹用的是sudo创建的… 更改文件夹所属就好了1chown user:group /dir]]></content>
      <categories>
        <category>运维工具</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[双网卡绑定-bond]]></title>
    <url>%2F2017%2F07%2F16%2F%E5%8F%8C%E7%BD%91%E5%8D%A1%E7%BB%91%E5%AE%9A-bond%2F</url>
    <content type="text"><![CDATA[linux双网卡绑定源文 是否支持12345678910111213#cat /boot/config-2.6.32-573.el6.x86_64 |grep -i bondingCONFIG_BONDING=m# modinfo bondingfilename: /lib/modules/2.6.32-431.el6.x86_64/kernel/drivers/net/bonding/bonding.koauthor: Thomas Davis, tadavis@lbl.gov and many othersdescription: Ethernet Channel Bonding Driver, v3.6.0version: 3.6.0license: GPLsrcversion: 353B1DC123506708446C57Bdepends: 8021q,ipv6vermagic: 2.6.32-431.el6.x86_64 SMP mod_unload modversions bond模式bond的模式常用的有两种：0和1 mode=0(balance-rr） 表示负载分担round-robin，并且是轮询的方式比如第一个包走eth0，第二个包走eth1，直到数据包发送完毕。 优点：流量提高一倍 缺点：需要接入交换机做端口聚合，否则可能无法使用 mode=1（active-backup） 表示主备模式，即同时只有1块网卡在工作。 优点：冗余性高 缺点：链路利用率低，两块网卡只有1块在工作 mode=2(balance-xor)(平衡策略) 表示XOR Hash负载分担，和交换机的聚合强制不协商方式配合。（需要xmit_hash_policy，需要交换机配置port channel） 特点：基于指定的传输HASH策略传输数据包。缺省的策略是：(源MAC地址 XOR 目标MAC地址) % slave数量。其他的传输策略可以通过xmit_hash_policy选项指定，此模式提供负载平衡和容错能力 mode=3(broadcast)(广播策略) 表示所有包从所有网络接口发出，这个不均衡，只有冗余机制，但过于浪费资源。此模式适用于金融行业，因为他们需要高可靠性的网络，不允许出现任何问题。需要和交换机的聚合强制不协商方式配合。 特点：在每个slave接口上传输每个数据包，此模式提供了容错能力 mode=4(802.3ad)(IEEE 802.3ad 动态链接聚合) 表示支持802.3ad协议，和交换机的聚合LACP方式配合（需要xmit_hash_policy）.标准要求所有设备在聚合操作时，要在同样的速率和双工模式，而且，和除了balance-rr模式外的其它bonding负载均衡模式一样，任何连接都不能使用多于一个接口的带宽。 特点：创建一个聚合组，它们共享同样的速率和双工设定。根据802.3ad规范将多个slave工作在同一个激活的聚合体下。外出流量的slave选举是基于传输hash策略，该策略可以通过xmit_hash_policy选项从缺省的XOR策略改变到其他策略。需要注意的是，并不是所有的传输策略都是802.3ad适应的，尤其考虑到在802.3ad标准43.2.4章节提及的包乱序问题。不同的实现可能会有不同的适应性。 必要条件： 条件1：ethtool支持获取每个slave的速率和双工设定 条件2：switch(交换机)支持IEEE802.3ad Dynamic link aggregation 条件3：大多数switch(交换机)需要经过特定配置才能支持802.3ad模式 mode=5(balance-tlb)(适配器传输负载均衡) 是根据每个slave的负载情况选择slave进行发送，接收时使用当前轮到的slave。该模式要求slave接口的网络设备驱动有某种ethtool支持；而且ARP监控不可用。 特点：不需要任何特别的switch(交换机)支持的通道bonding。在每个slave上根据当前的负载（根据速度计算）分配外出流量。如果正在接受数据的slave出故障了，另一个slave接管失败的slave的MAC地址。 必要条件： ethtool支持获取每个slave的速率 mode=6(balance-alb)(适配器适应性负载均衡) 在5的tlb基础上增加了rlb(接收负载均衡receiveload balance).不需要任何switch(交换机)的支持。接收负载均衡是通过ARP协商实现的. 特点：该模式包含了balance-tlb模式，同时加上针对IPV4流量的接收负载均衡(receiveload balance, rlb)，而且不需要任何switch(交换机)的支持。接收负载均衡是通过ARP协商实现的。bonding驱动截获本机发送的ARP应答，并把源硬件地址改写为bond中某个slave的唯一硬件地址，从而使得不同的对端使用不同的硬件地址进行通信。来自服务器端的接收流量也会被均衡。当本机发送ARP请求时，bonding驱动把对端的IP信息从ARP包中复制并保存下来。当ARP应答从对端到达时，bonding驱动把它的硬件地址提取出来，并发起一个ARP应答给bond中的某个slave。使用ARP协商进行负载均衡的一个问题是：每次广播 ARP请求时都会使用bond的硬件地址，因此对端学习到这个硬件地址后，接收流量将会全部流向当前的slave。这个问题可以通过给所有的对端发送更新（ARP应答）来解决，应答中包含他们独一无二的硬件地址，从而导致流量重新分布。当新的slave加入到bond中时，或者某个未激活的slave重新激活时，接收流量也要重新分布。接收的负载被顺序地分布（round robin）在bond中最高速的slave上当某个链路被重新接上，或者一个新的slave加入到bond中，接收流量在所有当前激活的slave中全部重新分配，通过使用指定的MAC地址给每个 client发起ARP应答。下面介绍的updelay参数必须被设置为某个大于等于switch(交换机)转发延时的值，从而保证发往对端的ARP应答不会被switch(交换机)阻截。 bond模式小结：mode5和mode6不需要交换机端的设置，网卡能自动聚合。mode4需要支持802.3ad。mode0，mode2和mode3理论上需要静态聚合方式。 配置物理网卡配置123456789101112131415#cat ifcfg-eth0 DEVICE=eth0TYPE=EthernetONBOOT=yesBOOTPROTO=noneMASTER=bond0SLAVE=yes //可以没有此字段，就需要开机执行ifenslave bond0 eth0 eth1命令了。#cat ifcfg-eth1 DEVICE=eth1TYPE=EthernetONBOOT=yesBOOTPROTO=noneMASTER=bond0SLAVE=yes 配置bond1234567891011#cat ifcfg-bond0 //需要手工创建DEVICE=bond0TYPE=EthernetONBOOT=yesBOOTPROTO=staticIPADDR=xx.xx.xx.xxNETMASK=255.255.255.0DNS1=8.8.8.8DNS2=114.114.114.114GATEWAY=xx.xx.xx.1#USERCTL=no #表明该设备是否只能由root用戶來控制（可选） #cat/etc/modprobe.d/modprobe.conf 1234567alias bond0 bondingoptions bond0 miimon=100 mode=0 #fail_over_mac=1 此参数用于vm workstation配置bond0的链路检查时间为100ms，模式为0bond0获取mac地址有两种方式,一种是从第一个活跃网卡中获取mac地址，然后其余的SLAVE网卡的mac地址都使用该mac地址；另一种是使用fail_over_mac参数，是bond0使用当前活跃网卡的mac地址，mac地址或者活跃网卡的转换而变。 svmware workstation不支持第一种获取mac地址的方式，那么可以使用fail_over_mac=1参数 加载bond模块modprobe bonding 查看结果cat/proc/net/bonding/bond0]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>bond</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git客户端最新版安装]]></title>
    <url>%2F2017%2F07%2F12%2Fgit%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%9C%80%E6%96%B0%E7%89%88%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[升级Git为最新版centos7环境 系统默认安装为1.8版本，源码安装2.9 卸载并安装12345678910111213141516171819202122232425262728293031#卸载默认版本yum remove git -y#安装依赖库yum -y install curl-devel expat-devel gettext-devel openssl-devel zlib-develyum -y install gcc perl-ExtUtils-MakeMaker#新建文件夹，下载git源码包mkdir /usr/local/gitcd 进去wget https://github.com/git/git/archive/v2.9.2.tar.gz#解压包tar -zxvf 包名#安装gitmake prefix=/usr/local/git allmake prefix=/usr/local/git install#添加环境变量vi /etc/profile export PATH=&quot;/usr/local/git/bin:$PATH&quot; source /etc/profile#查看版本git --version #应该是git version 2.9.2#设置git默认路径 ln -s /usr/local/git/bin/git-upload-pack /usr/bin/git-upload-pack ln -s /usr/local/git/bin/git-receive-pack /usr/bin/git-receive-pack 安装完毕！ 创建git用户和组123456 groupadd git useradd git -g git passwd git #切换git用户 避免权限问题su - git Git SSH 密钥认证12345#生成密钥ssh-keygen -t rsa -C &quot;****@sina.com&quot;#会多出两个密钥文件id_rsa id_rsa.pub#复制.pub的内容到你的git账户下 测试连接1234567ssh -T git@github.com#oschina的ssh -T git@git.oschina.net输入yes 会在当前目录生成known_hosts，认证成功！至此，git实现免密连接 可以做先关git的操作了 禁止git用户shell登录1234vim /etc/passwordgit:x:502:502::/home/git:/bin/bash修改为git:x:502:502::/home/git:/usr/local/git/bin/git-shell 完]]></content>
      <categories>
        <category>运维工具</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[keepalive]]></title>
    <url>%2F2017%2F06%2F06%2Fkeepalive%2F</url>
    <content type="text"><![CDATA[Keepalived使用的vrrp协议方式，虚拟路由冗余协议 (Virtual Router Redundancy Protocol，简称VRRP).Keepalived模拟路由器的高可用，Heartbeat或Corosync的目的是实现Service的高可用。 安装如无特殊需求,直接yum安装yum install keepalived1234主配置文件：/etc/keepalived/keepalived.conf主程序文件：/usr/sbin/keepalivedUnit File：keepalived.serviceUnit File的环境配置文件：/etc/sysconfig/keepalived 单主模式10.1.27.23 主,27.24 备,vip:27.21 master123456789101112131415161718192021222324252627282930[root@master keepalived]# cat keepalived.conf! Configuration File for keepalivedglobal_defs &#123; #全局配置 router_id haproxy1 #一般为hostnmae&#125;vrrp_script checkhaproxy&#123; script "/etc/keepalived/check.sh" #haproxy 健康检测 interval 3 #3秒检查一次 weight -10&#125;vrrp_instance VI_1 &#123; #vrrp命名,多个的时候,命名要不一致. state MASTER #虚拟机路由器状态MASTER/BACKUP interface eno16777984 #通过那个网卡发送vrrp广播 virtual_router_id 51 #虚拟路由器ID,如果有多个VI要注意区分这个ID priority 100 #优先级,越大越优先(取值范围1-255) advert_int 1 #广播时间间隔,默认1s authentication &#123; #传递信息认证方式,密码仅支持8位 auth_type PASS auth_pass lizili &#125; virtual_ipaddress &#123; #虚拟路由地址 10.1.27.21/24 &#125; track_script &#123; checkhaproxy #执行健康检测脚本 &#125;&#125; slave123456789101112131415161718192021222324252627282930[root@slave keepalived]# cat keepalived.conf! Configuration File for keepalivedglobal_defs &#123; router_id haproxy2&#125;vrrp_script checkhaproxy&#123; script &quot;/etc/keepalived/check.sh&quot; interval 3 weight -10&#125;vrrp_instance VI_1 &#123; state BACKUP interface eno16777984 virtual_router_id 51 priority 90 advert_int 1 authentication &#123; auth_type PASS auth_pass lizili &#125; virtual_ipaddress &#123; 10.1.27.21/24 &#125; track_script &#123; checkhaproxy &#125;&#125; check脚本755权限vim /etc/keepalived/check.sh防止haproxy服务关闭keepalived不切,前提保证keepalive和haproxy都处于开启运行状态.12345678#!/bin/bashif [ $(ps -C haproxy --no-header | wc -l) -eq 0 ]; then /etc/init.d/haproxy startfisleep 2if [ $(ps -C haproxy --no-header | wc -l) -eq 0 ]; then systemctl stop keepalived.servicefi 测试两台都安装httpd服务yum -y install httpdvi /var/www/html/index.html内容分别写上本机IP,然后通过浏览器访问vip,应该能查看到master的IP地址.然后关闭master的keepalived服务,刷新网页,应该出现slave的地址 邮件告警建议一定加上.安装mailx12345678910111213141516#安装mailx邮件服务yum install mailx -y#配置文件追加信息（/etc/mail.rc）vim /etc/mail.rc#发件人信息set from=lizili@xxxxxx.comset smtp=smtp.xxxxxx.comset smtp-auth-user=liziliset smtp-auth-password=xxxxxxset smtp-auth=login#测试发送echo &quot;hello world&quot; | mail -s &quot;hello&quot; lizili@xxxxxx.com#echo &quot;邮件内容&quot; | mail -s &quot;标题&quot; 邮箱地址#邮件策略上,把账号加如白名单,以防被拉黑. 配置keepalived123456789#在VRRP实例中虚拟IP下配置添加以下信息vrrp_instance VI_1 &#123; #Keepalived进入MASTER状态执行脚本 notify_master &quot;/etc/keepalived/mail_notify.sh master&quot; #Keepalived进入BACKUP状态执行脚本 notify_backup &quot;/etc/keepalived/mail_notify.sh backup&quot; #Keepalived进入FAULT状态执行脚本 notify_fault &quot;/etc/keepalived/mail_notify.sh fault&quot;｝ 新建脚本 755权限123vim /etc/keepalived/mail_notify.sh#!/bin/bashecho &quot;keepalived 10.1.27.23 $1 状态被激活，请确认服务运行状态&quot;|mail -s &quot;keepalived状态切换&quot; lizili@wondersgroup.com 双主模式配置并没有太大的变化,在添加一个vrrp实例即可,配置如下master1234567891011121314vrrp_instance VI_2 &#123; #vrrp命名,多个的时候,命名要不一致. state BACKUP #修改为backup interface eno16777984 #通过那个网卡发送vrrp广播 virtual_router_id 52 #虚拟路由器ID,如果有多个VI要注意区分这个ID priority 99 #优先级,越大越优先(取值范围1-255) advert_int 1 #广播时间间隔,默认1s authentication &#123; #传递信息认证方式,密码仅支持8位 auth_type PASS auth_pass lizili &#125; virtual_ipaddress &#123; #虚拟路由地址 10.1.27.11 &#125;&#125; slave 1234567891011121314vrrp_instance VI_1 &#123; state MASTER interface eno16777984 virtual_router_id 52 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass lizili &#125; virtual_ipaddress &#123; 10.1.27.11 &#125;&#125; 其实就是增加新的配置 VI_2 使用Server B 做主，如此 Server A、B 各自拥有主虚拟 IP，同时备份对方的虚拟 IP, 这个方案可以是不同的服务，或者是同一服务的访问分流(配合 DNS 使用) 其他相关的内核参数HAProxy+Keepalived架构需要注意的内核参数有：123456/etc/systcl.confnet.ipv4.ip_forward = 1 #开启IP转发功能net.ipv4.ip_nonlocal_bind = 1 #开启允许绑定非本机的IPsystcl -p 如果使用LVS的DR或者TUN模式结合Keepalived需要在后端真实服务器上特别设置两个arp相关的参数。1234net.ipv4.conf.lo.arp_ignore = 1net.ipv4.conf.lo.arp_announce = 2net.ipv4.conf.all.arp_ignore = 1net.ipv4.conf.all.arp_announce = 2]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>keepalive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django时间问题]]></title>
    <url>%2F2017%2F05%2F19%2Fdjango%E6%97%B6%E9%97%B4%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[配置文件settings.py中，有两个配置参数是跟时间与时区有关的 TIME_ZONE 和 USE_TZ 如果USE_TZ设置为True时，使用系统默认设置的时区America/Chicago此时的TIME_ZONE不起任何作用 如果USE_TZ 设置为FalseTIME_ZONE设置为None，使用默认的America/Chicago时间。TIME_ZONE设置为其它时区的话， Windows系统，则TIME_ZONE无用，Django使用本机的时间。 如果为其他系统，以设置为准,上海的UTC时间 USE_TZ = False, TIME_ZONE = &#39;Asia/Shanghai&#39;]]></content>
      <categories>
        <category>web</category>
        <category>django</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django静态文件]]></title>
    <url>%2F2017%2F05%2F17%2Fdjango%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[Django静态文件配置 Django 1.10 目录结构12345678910111213141516171819202122Project/├── db.sqlite3├── manage.py├── Project│ ├── __init__.py│ ├── settings.py│ ├── urls.py│ ├── wsgi.py├── app01│ ├── admin.py│ ├── apps.py│ ├── __init__.py│ ├── migrations│ │ ├── __init__.py│ ├── models.py│ ├── static #静态文件位置│ │ └── css.css│ ├── templates #网页模版位置│ │ └── index.html│ ├── tests.py│ ├── views.py└── templates settings修改(项目下)123456在STATIC_URL = &apos;/static/&apos; 后添加STATIC_ROOT = os.path.join(BASE_DIR, &apos;static&apos;)#如若不行，添加如下信息STATICFILES_DIRS = ( os.path.join(BASE_DIR, &apos;/home/ubuntu/django/wechat/zbx/static&apos;), #路径 ) urls修改(项目下)12345678910111213#导入库文件from django.conf import settingsfrom django.conf.urls.static import static末尾追加+ static(settings.STATIC_URL, document_root = settings.STATIC_ROOT)#最后类似from django.conf import settingsfrom django.conf.urls.static import staticurlpatterns = [ url(r&apos;^admin/&apos;, admin.site.urls),] + static(settings.STATIC_URL, document_root = settings.STATIC_ROOT) 网页模版下引用1&lt;link rel=&quot;stylesheet&quot; href=&quot;/static/css.css&quot;&gt; 重新运行项目即可使用了。]]></content>
      <categories>
        <category>web</category>
        <category>django</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iSCSI存储]]></title>
    <url>%2F2017%2F05%2F15%2FiSCSI%E5%AD%98%E5%82%A8%2F</url>
    <content type="text"><![CDATA[临时需要个挂个iSCSI,发现基本想不起来,果然好记性不如烂笔头,还是写一下比较好-。- 摘:iSCSI是一种基于TCP/IP 的协议，用来建立和管理IP存储设备、主机和客户机等之间的相互连接，并创建存储区域网络（SAN）。SAN 使得SCSI 协议应用于高速数据传输网络成为可能，这种传输以数据块级别（block-level）在多个数据存储网络间进行。SCSI 结构基于C/S模式，其通常应用环境是：设备互相靠近，并且这些设备由SCSI 总线连接。·简单说iSCSI就是把SCSI指令通过TCP/IP协议封装起来，在以太网中传输。iSCSI 可以实现在IP网络上传递和运行SCSI协议，使其能够在诸如高速千兆以太网上进行数据存取，实现了数据的网际传递和管理。基于iSCSI建立的存储区域网（SAN）与基于光纤的FC-SAN相比，具有很好的性价比。 关闭了selinux 和防火墙，centos7target （服务器）： 192.168.247.149Initiator（客户端）：192.168.247.154 服务端新加硬盘做存储1234Disk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytes 创建磁盘并格式化 一个硬盘主 分区至少有1个，最多4个，扩展分区可以没有，最多1个。且主分区+扩展分区总共不能超过4个。为了突破这最多四个主分区的限制，管理员可以把其中一个主分区设置为扩展分区(注意只能够使用一个扩展分区)来进行扩充。而在扩充分区下，又可以建立多个逻辑分区。也就是说，扩展分区是无法直接使用的，必须在细分成逻辑分区才可以用来存储数据。通常情况下，逻辑分区的起始位置及结束位置记录在每个逻辑分区的第一个扇区，这也叫做扩展分区表。在扩展分区下，系统管理员可以根据实际情况建立多个逻辑分区，将一个扩展分区划割成多个区域来使用。 格式化为LVM（LVM是 Logical Volume Manager逻辑卷管理）LVM的好处就是可以按需分配，动态管理1234567891011121314151617181920212223242526272829303132Command (m for help): nPartition type: p primary (0 primary, 0 extended, 4 free) e extendedSelect (default p): p #必须要一个主分区Partition number (1-4, default 1): First sector (2048-41943039, default 2048): Using default value 2048Last sector, +sectors or +size&#123;K,M,G&#125; (2048-41943039, default 41943039): Using default value 41943039Partition 1 of type Linux and of size 20 GiB is setCommand (m for help): t #类型Selected partition 1 #编号 可按 L 查看要创建的格式Hex code (type L to list all codes): 8eChanged type of partition 'Linux' to 'Linux LVM'Command (m for help): p #查看Disk /dev/sdb: 21.5 GB, 21474836480 bytes, 41943040 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0xea844b86 Device Boot Start End Blocks Id System/dev/sdb1 2048 41943039 20970496 8e Linux LVM保存即可partprobe #是配置生效 创建逻辑卷12345678910111213141516171819[root~] ]$pvcreate /dev/sdb1 Physical volume &quot;/dev/sdb1&quot; successfully created[root~] ]$pvs PV VG Fmt Attr PSize PFree /dev/sda2 centos lvm2 a-- 59.78g 0 /dev/sdb1 lvm2 --- 20.00g 20.00g[root~] ]$vgcreate vg_iscsi /dev/sdb1 Volume group &quot;vg_iscsi&quot; successfully created[root~] ]$vgs VG #PV #LV #SN Attr VSize VFree centos 1 2 0 wz--n- 59.78g 0 vg_iscsi 1 0 0 wz--n- 20.00g 20.00g[root~] ]$lvcreate -l 100%FREE -n /dev/vg_iscsi/lv_iscsi Logical volume &quot;lv_iscsi&quot; created.[root~] ]$lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert root centos -wi-ao---- 57.78g swap centos -wi-ao---- 2.00g lv_iscsi vg_iscsi -wi-a----- 20.00g 安装配置target12345678910111213141516171819202122232425262728293031323334353637383940414243444546[root~] ]$yum -y install targetcli[root~] ]$targetcli #最初状态/&gt; lso- / ......................................................................................................................... [...] o- backstores .............................................................................................................. [...] | o- block .................................................................................................. [Storage Objects: 0] | o- fileio ................................................................................................. [Storage Objects: 0] | o- pscsi .................................................................................................. [Storage Objects: 0] | o- ramdisk ................................................................................................ [Storage Objects: 0] o- iscsi ............................................................................................................ [Targets: 0] o- loopback ......................................................................................................... [Targets: 0]/&gt; cd backstores/block /backstores/block&gt; create sdb1_iscsi /dev/vg_iscsi/lv_iscsiCreated block storage object sdb1_iscsi using /dev/vg_iscsi/lv_iscsi.切换到iscsi下/iscsi&gt; create iqn.2017-05.com.master:ip149 #注意全局唯一，格式iqn.日期（日期只能有年月并且月份必须加0.颠倒的domain：自定义标识/iscsi/iqn.20...149/tpg1/acls&gt; create iqn.2017-05.com.master:ip149Created Node ACL for iqn.2017-05.com.master:ip149/iscsi/iqn.20...149/tpg1/acls&gt; cd ../luns /iscsi/iqn.20...149/tpg1/luns&gt; create /backstores/block/sdb1_iscsi/iscsi/iqn.20...149/tpg1/luns&gt; cd ../portals//iscsi/iqn.20.../tpg1/portals&gt; create 192.168.247.149Using default IP port 3260/iscsi/iqn.20.../tpg1/portals&gt; cd /#完成状态/&gt; lso- / ......................................................................................................................... [...] o- backstores .............................................................................................................. [...] | o- block .................................................................................................. [Storage Objects: 1] | | o- sdb1_iscsi ........................................................ [/dev/vg_iscsi/lv_iscsi (20.0GiB) write-thru activated] | o- fileio ................................................................................................. [Storage Objects: 0] | o- pscsi .................................................................................................. [Storage Objects: 0] | o- ramdisk ................................................................................................ [Storage Objects: 0] o- iscsi ............................................................................................................ [Targets: 1] | o- iqn.2017-05.com.master:ip149 ...................................................................................... [TPGs: 1] | o- tpg1 ............................................................................................... [no-gen-acls, no-auth] | o- acls .......................................................................................................... [ACLs: 1] | | o- iqn.2017-05.com.master:ip149 ......................................................................... [Mapped LUNs: 1] | | o- mapped_lun0 ............................................................................ [lun0 block/sdb1_iscsi (rw)] | o- luns .......................................................................................................... [LUNs: 1] | | o- lun0 ...................................................................... [block/sdb1_iscsi (/dev/vg_iscsi/lv_iscsi)] | o- portals .................................................................................................... [Portals: 1] | o- 0.0.0.0:3260 ..................................................................................................... [OK] o- loopback ......................................................................................................... [Targets: 0]/&gt; exit 启动服务1234[root~] ]$systemctl start target.service [root~] ]$systemctl enable target.service Created symlink from /etc/systemd/system/multi-user.target.wants/target.service to /usr/lib/systemd/system/target.service.[root~] ]$ 客户端12345678910111213141516171819202122 [root~] ]$yum -y install iscsi-initiator* [root~] ]$vim /etc/iscsi/initiatorname.iscsi InitiatorName=iqn.2017-05.com.master:ip149 #服务器的iqn[root@minion-02 /]# systemctl restart iscsi[root@minion-02 /]# iscsiadm -m discovery -t st -p 192.168.247.149192.168.247.149:3260,1 iqn.2017-05.com.master:ip149[root@minion-02 /]# iscsiadm -m node -T iqn.2017-05.com.master:ip149 -p 192.168.247.149 -lLogging in to [iface: default, target: iqn.2017-05.com.master:ip149, portal: 192.168.247.149,3260] (multiple)Login to [iface: default, target: iqn.2017-05.com.master:ip149, portal: 192.168.247.149,3260] successful.[root@minion-02 /]# fdisk -l#可以看到iscsi已经挂上 为sdbDisk /dev/sdb: 21.5 GB, 21470642176 bytes, 41934848 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 4194304 bytes[root@minion-02 /]# #sdb就像是新加的硬盘，我们可以fdisk 它 n p 1 enter enter w我们可以对这个盘进行单独的挂载。切记不可扩展到某个分区 挂载123456789101112131415161718192021[root@minion-02 /]# mkfs.xfs /dev/sdb1[root@minion-02 /]# mkdir /mnt/iscsi[root@minion-02 /]# mount /dev/sdb1 /mnt/iscsi/[root@minion-02 /]# blkid/dev/sda1 : UUID=&quot;64f589c2-2ac4-47f7-8d35-170913a2563f&quot; TYPE=”xfs”[root@minion-02 /]# vim /etc/fstabUUID=&quot;64f589c2-2ac4-47f7-8d35-170913a2563f&quot; /mnt/iscsi xfs defaults,_netdev 0 0fstab一定呀写对，不然系统重启会启动不起来，特别注意。万一 启动不起来怎么办？重启虚拟机 按 e 进行编辑修改ro rd........等 为 rd.breakswitch_root:/# mount –o remount,rw /sysroot/switch_root:/# chroot /sysroot/sh-4.2#vi /etc/fstab #重新编辑##这里还可以修改root密码。passwd root如果开了seLinux.记得 touch /.autorelabel 这句是为了selinux生效,否则系统无法正常启动如果忘记密码也可用这个办法修改]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>iSCSI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django连接MySql]]></title>
    <url>%2F2017%2F05%2F13%2Fdjango%E8%BF%9E%E6%8E%A5MySql%2F</url>
    <content type="text"><![CDATA[前言Django默认连接的是sqlite,简单的开发测试还不错,随着需求的增加,难免需要更换 setting.py1234567891011121314151617DATABASES = &#123; &apos;default&apos;: &#123;# &apos;ENGINE&apos;: &apos;django.db.backends.sqlite3&apos;,# &apos;NAME&apos;: os.path.join(BASE_DIR, &apos;db.sqlite3&apos;), &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;, #数据库名字 &apos;NAME&apos;: &apos;study&apos;, &apos;USER&apos;: &apos;root&apos;, &apos;PASSWORD&apos;: &apos;centos&apos;, &apos;HOST&apos;: &apos;127.0.0.1&apos;, &apos;PORT&apos;: &apos;3306&apos;, &apos;OPTIONS&apos;: &#123; &apos;autocommit&apos;: True, &apos;init_command&apos;: &quot;SET sql_mode=&apos;STRICT_TRANS_TABLES&apos;&quot;, &#125;, &#125;&#125; 安装相关模块 python3 不在支持MySQLdb安装pymsql pip3 install pymysql 123#去项目下修改__init__.py,使其默认数据库模块为pymysqlimport pymysqlpymysql.install_as_MySQLdb() 项目下执行12python manage.py makemigrationspython manage.py migrate 如果有类似如下报错1234/usr/lib64/python2.7/site-packages/pymysql/cursors.py:165: Warning: (3135, u&quot;&apos;NO_ZERO_DATE&apos;, &apos;NO_ZERO_IN_DATE&apos; and &apos;ERROR_FOR_DIVISION_BY_ZERO&apos; sql modes should be used with strict mode. They will be merged with strict mode in a future release.&quot;) result = self._query(query)/usr/lib64/python2.7/site-packages/pymysql/cursors.py:165: Warning: (3090, u&quot;Changing sql mode &apos;NO_AUTO_CREATE_USER&apos; is deprecated. It will be removed in a future release.&quot;) result = self._query(query) 更改 setting.py DATABASES 中 &#39;init_command&#39;: &quot;SET sql_mode=&#39;traditional&#39;&quot;, 操纵models.py数据库相关一般都写在这个模块下 前提，应用要加到setting中12345678910111213141516171819202122232425from django.db import models# Create your models here.#新建了一个Student类，继承自models.Modelclass Student(models.Model): name = models.CharField(max_length=128) age = models.IntegerField(max_length=3#上面代码其实就相当于原生sqlCREATE TABLE myapp_person ( &quot;id&quot; serial NOT NULL PRIMARY KEY, &quot;name&quot; varchar(30) NOT NULL, &quot;age&quot; int() NOT NULL);#然后进行同步python manage.py makemigrationspython manage.py migrate#生成一个项目名称+下划线+小写类名的表比如项目叫study_1，那表名就叫study_1_student 123456789#插入数据class Student(models.Model): Student.objects.create(name=&apos;lizili&apos;,age=18) Student.objects.create(name=&apos;vic&apos;,age=22) Student.objects.create(name=&apos;zhang&apos;,age=12)#返回数据 def __str__(self): #固定格式 return u&apos;name: %s , age:%s&apos; % (self.name,self.age) 12345678#需要数据的页面#导入from study_1.models import Student#查询，展示def test(request): student_list = Student.objects.all() student_str = map(str,student_list) return HttpResponse(student_str)]]></content>
      <categories>
        <category>web</category>
        <category>django</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix监控MySQL性能]]></title>
    <url>%2F2017%2F05%2F01%2Fzabbix%E7%9B%91%E6%8E%A7MySQL%E6%80%A7%E8%83%BD%2F</url>
    <content type="text"><![CDATA[套用自带模板监控mysql性能 安装agent查看此链接 DB权限 在客户端的mysql里添加权限,使用zabbix账号连接本地的mysql12mysql&gt; grant all on *.* to zabbix@&apos;localhost&apos; identified by &quot;zabbix”;mysql&gt; flush privileges; 编辑 my.cnf/etc/zabbix/etc/my.cnf (需新建)1234567891011#zabbix Agent[mysql]host=localhostuser=zabbixpassword=zabbixsocket=/var/lib/mysql/mysql.sock #具体根据个人情况[mysqladmin]host=localhostuser=zabbixpassword=zabbixsocket=/var/lib/mysql/mysql.sock 修改agentd/etc/zabbix/zabbix_agentd.d/userparameter_mysql.confHOME=/var/lib/zabbix 修改为 HOME=/etc/zabbix/etc/ 其他zabbix_agentd.conf配置文件中Include选择要包含 zabbix_agentd.d service zabbix-agent restart 然后去web端口,添加主机 套用内置mysql模板就可以了. 关于userparameter_mysql.conf 还有一种配置 新建脚本vim /etc/zabbix/chk_mysql.sh12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#!/bin/bash# 用户名MYSQL_USER=&apos;zabbix&apos;# 密码MYSQL_PWD=&apos;zabbix&apos;# 主机地址/IPMYSQL_HOST=&apos;127.0.0.1&apos;# 端口MYSQL_PORT=&apos;3306&apos;# 数据连接MYSQL_CONN=&quot;/usr/bin/mysqladmin -u$&#123;MYSQL_USER&#125; -p$&#123;MYSQL_PWD&#125; -h$&#123;MYSQL_HOST&#125; -P$&#123;MYSQL_PORT&#125;&quot;# 参数是否正确if [ $# -ne &quot;1&quot; ];then echo &quot;arg error!&quot; fi # 获取数据case $1 in Uptime) result=`$&#123;MYSQL_CONN&#125; status|cut -f2 -d&quot;:&quot;|cut -f1 -d&quot;T&quot;` echo $result ;; Com_update) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w &quot;Com_update&quot;|cut -d&quot;|&quot; -f3` echo $result ;; Slow_queries) result=`$&#123;MYSQL_CONN&#125; status |cut -f5 -d&quot;:&quot;|cut -f1 -d&quot;O&quot;` echo $result ;; Com_select) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w &quot;Com_select&quot;|cut -d&quot;|&quot; -f3` echo $result ;; Com_rollback) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w &quot;Com_rollback&quot;|cut -d&quot;|&quot; -f3` echo $result ;; Questions) result=`$&#123;MYSQL_CONN&#125; status|cut -f4 -d&quot;:&quot;|cut -f1 -d&quot;S&quot;` echo $result ;; Com_insert) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w &quot;Com_insert&quot;|cut -d&quot;|&quot; -f3` echo $result ;; Com_delete) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w &quot;Com_delete&quot;|cut -d&quot;|&quot; -f3` echo $result ;; Com_commit) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w &quot;Com_commit&quot;|cut -d&quot;|&quot; -f3` echo $result ;; Bytes_sent) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w &quot;Bytes_sent&quot; |cut -d&quot;|&quot; -f3` echo $result ;; Bytes_received) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w &quot;Bytes_received&quot; |cut -d&quot;|&quot; -f3` echo $result ;; Com_begin) result=`$&#123;MYSQL_CONN&#125; extended-status |grep -w &quot;Com_begin&quot;|cut -d&quot;|&quot; -f3` echo $result ;; *) echo &quot;Usage:$0(Uptime|Com_update|Slow_queries|Com_select|Com_rollback|Questions|Com_insert|Com_delete|Com_commit|Bytes_sent|Bytes_received|Com_begin)&quot; ;; esac 修改配置12345678910vim /etc/zabbix/zabbix_agentd.d/userparameter_mysql.conf#UserParameter=mysql.status[*],echo &quot;show global status where Variable_name=&apos;$1&apos;;&quot; | HOME=/var/lib/zabbix mysql -N | awk &apos;&#123;print $$2&#125;&apos;UserParameter=mysql.status[*],/etc/zabbix/chk_mysql.sh $1#UserParameter=mysql.size[*],bash -c &apos;echo &quot;select sum($(case &quot;$3&quot; in both|&quot;&quot;) echo &quot;data_length+index_length&quot;;; data|index) echo &quot;$3_length&quot;;; free) echo &quot;data_free&quot;;; esac)) from information_schema.tables$([[ &quot;$1&quot; = &quot;all&quot; || ! &quot;$1&quot; ]] || echo &quot; where table_schema=\&quot;$1\&quot;&quot;)$([[ &quot;$2&quot; = &quot;all&quot; || ! &quot;$2&quot; ]] || echo &quot;and table_name=\&quot;$2\&quot;&quot;);&quot; | HOME=/var/lib/zabbix mysql -N&apos;#UserParameter=mysql.ping,HOME=/var/lib/zabbix mysqladmin ping | grep -c aliveUserParameter=mysql.ping,mysqladmin -uzabbix -pzabbix -P3306 -h127.0.0.1 ping | grep -c aliveUserParameter=mysql.version,mysql -V]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu安装Django-mysql]]></title>
    <url>%2F2017%2F04%2F29%2Fubuntu%E5%AE%89%E8%A3%85Django-mysql%2F</url>
    <content type="text"><![CDATA[安装mysql1sudo apt install mysql-server mysql-client libmysqlclient-dev 启动mysql并重置密码 修改配置1234567891011/etc/init.d/mysql start#重置密码,注意符合复杂度mysql_secure_installation#注释 vi /etc/mysql/mysql.conf.d/mysqld.cnf bind-address = 127.0.0.1#连接数据库开启root远程mysql -u -p xxxxxgrant all privileges on *.* to &apos;root&apos;@&apos;%&apos; identified by &apos;******&apos;;flush privileges或退出重启/etc/init.d/mysql restart 安装pip31sudo apt-get install python3-pip 安装django1sudo apt-get install django==1.10 使用django12345678910sudo mkdir djangocd djangosudo django-admin startproject studycd studysudo python3 manage.py startapp app1sudo python3 manage.py runserver 0.0.0.0:8000#本机打开127.0.0.1:8000即可看到 It worked!Congratulations on your first Django-powered page.]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos密码破解]]></title>
    <url>%2F2017%2F04%2F24%2Fcentos%E5%AF%86%E7%A0%81%E7%A0%B4%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[破解centos密码 centos712345678910111213141516171819rd.break方法：- 启动的时候，在启动界面，相应启动项，内核名称上按“e”；- 进入后，找到linux16开头的地方，按“end”键到最后，输入rd.break，按ctrl+x进入；- 进去后输入命令mount，发现根为/sysroot/，并且不能写，只有ro=readonly权限；- mount -o remount,rw /sysroot/，重新挂载，之后mount，发现有了r,w权限；- chroot /sysroot/ 改变根；- passwd root 修改root密码- 如果开了seLinux.记得 touch /.autorelabel 这句是为了selinux生效,否则系统无法正常启动- exit 退出重启init方法：- 启动系统，并在GRUB2启动屏显时，按下e键进入编辑模式。- 在linux16/linux/linuxefi所在参数行尾添加以下内容：init=/bin/sh- 按Ctrl+x启动到shell。- 挂载文件系统为可写模式：mount –o remount,rw /- 运行passwd,并按提示修改root密码。- 如何之前系统启用了selinux，必须运行以下命令，否则将无法正常启动系统：touch /.autorelabel- 运行命令exec /sbin/init来正常启动，或者用命令exec /sbin/reboot重启 centos61234567- 重启系统，在开机启动的时候能看到引导目录，用上下方向键选择你忘记密码的那个系统，然后按e。- 选择第二项—kernel，然后继续按”E”- 在rhgb quiet后回车输入single或者1，然后回车- 然后回车后，回到该界面，然后按b进行重新引导系统- 启动后，我们发现直接进入系统，无需要输入账户及密码- 进入后，我们可以根据passwd root来修改密码了]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu16安装后]]></title>
    <url>%2F2017%2F04%2F22%2Fubuntu16%E5%AE%89%E8%A3%85%E5%90%8E%2F</url>
    <content type="text"><![CDATA[更新root密码12sudo supasswd root 触摸板控制12345678重启后失效关闭触摸板： sudo modprobe -r psmouse 打开触摸板： sudo modprobe psmouse方案二,安装应用进行管理sudo add-apt-repository ppa:atareao/atareaosudo apt-get updatesudo apt-get install touchpad-indicator 更新补丁12sudo apt-get update sudo apt-get upgrade 卸载libreOffice1sudo apt-get remove libreoffice-common 删Amazon的链接1sudo apt-get remove unity-webapps-common 删除不常用软件12345注意按需删除，如无强迫症不建议删除。比如雷鸟邮件客户端，其实也挺好用的。另：删除后如果需要以后可在安装sudo apt-get remove thunderbird totem rhythmbox empathy brasero simple-scan gnome-mahjongg aisleriot sudo apt-get remove gnome-mines cheese transmission-common gnome-orca webbrowser-app gnome-sudoku landscape-client-ui-install sudo apt-get remove onboard deja-dup 安装Unity Tweak Tool可用来启动点击图标最小化，调整主题等功能1sudo apt install unity-tweak-tool 安装wps12345678910sudo apt install wps-office#消除wps打开提示字体缺失链接: https://pan.baidu.com/s/1jIR4R8U 密码: 1ka9#下载解压，切换到目录内sudo cp -rp * /usr/share/fonts/wps-office/#生成字体的索引信息：sudo mkfontscalesudo mkfontdir#更新字体缓存sudo fc-cache 安装chrome123456官网下载chrome的Linux版本，或者链接: http://pan.baidu.com/s/1i59oUpB 密码: 5rntsudo apt-get install libappindicator1 libindicator7 sudo dpkg -i google-chrome-stable_current_amd64.deb sudo apt-get -f install 安装flash12系统设置--软件和更新--其他软件----（勾选第一个）sudo apt-get install flashplugin-installer 安装下载应用12345sudo apt-get install uget #下载工具sudo apt-get install aria2 #插件#打开软件编辑---设置---插件，启用aria2，启用aria2插件分类---属性---默认设置，设置默认的下载路径。最大连接数等 ####安装第三方wechat（electronic-wechat-linux）123自行搜索安装包，或者链接: http://pan.baidu.com/s/1dFalmVn 密码: q4es开箱即用 安装网易云音乐1234去网易官网下载包或者链接: https://pan.baidu.com/s/1pLM9QR5 密码: 5jrdsudo dpkg -i 包名sudo apt-get -f install 包名（-f修复依赖关系） 安装便签1sudo apt-get install xpad 安装搜狗输入法12345添加源 sudo vim /etc/apt/sources.list.d/ubuntukylin.listdeb http://archive.ubuntukylin.com:10006/ubuntukylin trusty mainsudo apt-get updatesudo apt-get install sogoupinyin 安装大小写提示123sudo add-apt-repository ppa:tsbarnes/indicator-keylocksudo apt-get updatesudo apt-get install indicator-keylock 安装vim git filezilla1sudo apt-get install vim git filezilla 安装sublime 3123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105sudo add-apt-repository ppa:webupd8team/sublime-text-3 sudo apt-get update sudo apt-get install sublime-text#注册—– BEGIN LICENSE —– Country Rebel Single User License EA7E-993095 19176BCE 3FF86EA0 3CE86508 6BE4DCA7 9F74D761 4D0CAD8B E4033008 43FC73F3 1C01F6DD C4829BE9 E7830578 A4823ADC 61B224F1 DC93C458 ABAAAE0F 925C32D4 04A83C36 813FF6C8 9877942C 4418F99C 2F15E5B8 544EDB80 D9A86985 4CBBA6A8 998DE3E4 7FB33E15 6CD30357 6DC96CEA ECB1BC4E D8010D5A 77BA86C8 BA7F76CC —— END LICENSE ——win系统----- BEGIN LICENSE -----TwitterInc200 User LicenseEA7E-8900071D77F72E 390CDD93 4DCBA022 FAF6079061AA12C0 A37081C5 D0316412 4584D13694D7F7D4 95BC8C1C 527DA828 560BB037D1EDDD8C AE7B379F 50C9D69D B35179EF2FE898C4 8E4277A8 555CE714 E1FB0E43D5D52613 C3D12E98 BC49967F 7652EED29D2D2E61 67610860 6D338B72 5CF95C69E36B85CC 84991F19 7575D828 470A92AB------ END LICENSE ------ctrl + 飘（ESC下面）然后输入以下代码import urllib.request,os; pf = &apos;Package Control.sublime-package&apos;; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); open(os.path.join(ipp, pf), &apos;wb&apos;).write(urllib.request.urlopen( &apos;http://sublime.wbond.net/&apos; + pf.replace(&apos; &apos;,&apos;%20&apos;)).read())win系统import urllib.request,os,hashlib; h = &apos;eb2297e1a458f27d836c04bb0cbaf282&apos; + &apos;d0e7a3098092775ccb37ca9d6b2e4b7d&apos;; pf = &apos;Package Control.sublime-package&apos;; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); by = urllib.request.urlopen( &apos;http://packagecontrol.io/&apos; + pf.replace(&apos; &apos;, &apos;%20&apos;)).read(); dh = hashlib.sha256(by).hexdigest(); print(&apos;Error validating download (got %s instead of %s), please try manual install&apos; % (dh, h)) if dh != h else open(os.path.join( ipp, pf), &apos;wb&apos; ).write(by)如果不成功，下载包 手动安装https://packagecontrol.io/installation然后按下Ctrl+Shift+P调出命令面板输入install 调出 Install Package 选项并回车，然后在列表中选中要安装的插件。ChineseLocalizations #中文汉化Boxy Theme #主题SFTP #如其名Sublime CodeIntel #代码提示和补全插件Bracket Highlighter #匹配括号Emmet #前端神器（前身Zen Coding）Alignment #代码对齐SidebarEnhancements #侧边栏功能增加Markdown Editing // Markdown编辑和语法高亮支持 Markdown Preview// Markdown导出html预览支持 shift+ctrl+p 输入mp可浏览器浏览align argumentsChineseLocalIzationsConvertToUTF8 #解决中文乱码Ctagsfilediffpretty jsonwordHighlightzzzzzzzz-localizationPerference----&gt;Package Settings-------&gt;SFTP-------&gt;setting user&#123; &quot;email&quot;: &quot;xiaosong@xiaosong.me&quot;, &quot;product_key&quot;: &quot;d419f6-de89e9-0aae59-2acea1-07f92a&quot;&#125;##个人配置 &quot;font_size&quot;: 12, &quot;ignored_packages&quot;: [ &quot;Vintage&quot; ], // 设置tab的大小为4 &quot;tab_size&quot;:4, // 使用空格代替tab &quot;translate_tabs_to_spaces&quot;: true, // 添加行宽标尺 &quot;rulers&quot;: [80, 100], // 显示空白字符 &quot;draw_white_space&quot;: &quot;all&quot;, // 保存时自动去除行末空白 &quot;trim_trailing_white_space_on_save&quot;: true, // 保存时自动增加文件末尾换行 &quot;ensure_newline_at_eof_on_save&quot;: true, // 默认编码格式 &quot;default_encoding&quot;: &quot;UTF-8&quot;#解决无法输入中文的问题git clone https://github.com/lyfeyaj/sublime-text-imfix.git或链接: https://pan.baidu.com/s/1gf1l1jP 密码: piug移动subl到/usr/bin/，移动sublime-imfix.so到/opt/sublime_text/（sublime的安装目录）命令行 输入 subl 如果启动成功，即可输入中文 经典下拉菜单指示器123sudo add-apt-repository ppa:diesch/testingsudo apt-get update sudo apt-get install classicmenu-indicator 安装截图12自带的也很好用，但是shutter更丰富。sudo apt-get install shutter 安装unrar12用来解压rarsudo apt-get install unrar vpn安装(本人根据公司情况安装,并不适合每个人)123http://support.arraynetworks.com.cn/troubleshooting下载相关软件以及说明书或 链接: https://pan.baidu.com/s/1hr9GD7Y 密码: d2kk 安装kvm虚拟机12345678910111213141516171819202122232425262728293031321. 检查CPU是否支持虚拟化技术egrep &quot;(svm|vmx)&quot; /proc/cpuinfo有结果输出,类似如下信息,则可以安装flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt dtherm ida arat pln pts2. 安装kvm依赖sudo apt-get install qemu-kvmsudo apt-get install qemusudo apt-get install virt-managersudo apt-get install virt-viewer sudo apt-get install libvirt-bin sudo apt-get install bridge-utils3. 配置网络sudo cp /etc/network/interfaces /etc/network/interfaces-bak #备份配置sudo vim /etc/network/interfaces#修改配置如下auto br0iface br0 inet staticaddress 192.168.1.130network 192.168.1.0netmask 255.255.255.0broadcast 192.168.1.255#gateway 192.168.1.1dns-nameservers 223.5.5.5bridge_ports eth0bridge_stp off4. 重启sudo reboot5. 打开程序virt-manager 美化12345678910111213141516#Flatabulous主题sudo add-apt-repository ppa:noobslab/themessudo apt-get updatesudo apt-get install flatabulous-theme#图包sudo add-apt-repository ppa:noobslab/iconssudo apt-get updatesudo apt-get install ultra-flat-icons#Numix主题 （图包好看 可配Flatabulous主题）sudo add-apt-repository ppa:numix/ppasudo apt-get updatesudo apt-get install numix-gtk-theme numix-icon-theme-circle#壁纸更换sudo apt-get install variety]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix-agent安装]]></title>
    <url>%2F2017%2F04%2F18%2Fzabbix-agent%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[监控路由交换等,由于本身不能安装软件,所以通常使用SNMP协议进行数据的采集.但是,对于系统的监控最好还是采用agent进行采集,方便. Zabbix3.2 CentOS7 x64 Yum源配置12345#centos7rpm -ivh http://repo.zabbix.com/zabbix/3.2/rhel/7/x86_64/zabbix-release-3.2-1.el7.noarch.rpm#centos6 rpm -ivh http://repo.zabbix.com/zabbix/3.2/rhel/6/x86_64/zabbix-release-3.2-1.el6.noarch.rpm zabbix_agent安装配置centos1234567891011yum install zabbix-agent -yvim /etc/zabbix/zabbix_agentd.conf Server= 服务端IP #用于被动模式ServerActive= 服务端IP#用于主动模式Hostname=本机Ip #不要用127.0.0.1 #或者 弄个唯一名字，这里的名字在服务端添加主机的时候要用！建议使用IP主动模式失败， `Received empty response from Zabbix Agent at [10.1.93.252]. Assuming that ...` 不知为何，systemctl start zabbix-agent#启动zabbix agent 主动和被动的区别。以agent端为出发，agent主动发送就是主动，被动接受就是被动。 Ubuntu amd641234567#下载软件包wget http://repo.zabbix.com/zabbix/3.2/ubuntu/pool/main/z/zabbix/zabbix-agent_3.2.4-1+trusty_amd64.deb#然后安装dpkg -i zabbix....deb##再修改配置，同centos windows agent安装下载agent包 http://www.zabbix.com/download 拷贝zabbix_agents_3.2.0.win\bin\win64下所有文件（非文件夹）到C:\Program Files\zabbix下32位到 C:\Program Files x86\zabbix下 新建文件C:\Program Files\zabbix\zabbix_agent.conf复制代码，主要修改地方同linux。不要写错，否则服务启动不起来s123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363第一种：Server= 服务端IP #用于被动模式ServerActive= 服务端IP#用于主动模式Hostname=本机Ip #不要用127.0.0.1 如果有特殊需求第二种：# This is a configuration file for Zabbix agent service (Windows)# To get more information about Zabbix, visit http://www.zabbix.com############ GENERAL PARAMETERS #################### Option: LogType# Specifies where log messages are written to:# system - Windows event log# file - file specified with LogFile parameter# console - standard output## Mandatory: no# Default:# LogType=file### Option: LogFile# Log file name for LogType &apos;file&apos; parameter.## Mandatory: no# Default:# LogFile=LogFile=c:\zabbix_agentd.log### Option: LogFileSize# Maximum size of log file in MB.# 0 - disable automatic log rotation.## Mandatory: no# Range: 0-1024# Default:# LogFileSize=1### Option: DebugLevel# Specifies debug level:# 0 - basic information about starting and stopping of Zabbix processes# 1 - critical information# 2 - error information# 3 - warnings# 4 - for debugging (produces lots of information)# 5 - extended debugging (produces even more information)## Mandatory: no# Range: 0-5# Default:# DebugLevel=3### Option: SourceIP# Source IP address for outgoing connections.## Mandatory: no# Default:# SourceIP=### Option: EnableRemoteCommands# Whether remote commands from Zabbix server are allowed.# 0 - not allowed# 1 - allowed## Mandatory: no# Default:# EnableRemoteCommands=0### Option: LogRemoteCommands# Enable logging of executed shell commands as warnings.# 0 - disabled# 1 - enabled## Mandatory: no# Default:# LogRemoteCommands=0##### Passive checks related### Option: Server# List of comma delimited IP addresses (or hostnames) of Zabbix servers.# Incoming connections will be accepted only from the hosts listed here.# If IPv6 support is enabled then &apos;127.0.0.1&apos;, &apos;::127.0.0.1&apos;, &apos;::ffff:127.0.0.1&apos; are treated equally.## Mandatory: no# Default:# Server=Server=127.0.0.1### Option: ListenPort# Agent will listen on this port for connections from the server.## Mandatory: no# Range: 1024-32767# Default:# ListenPort=10050### Option: ListenIP# List of comma delimited IP addresses that the agent should listen on.# First IP address is sent to Zabbix server if connecting to it to retrieve list of active checks.## Mandatory: no# Default:# ListenIP=0.0.0.0### Option: StartAgents# Number of pre-forked instances of zabbix_agentd that process passive checks.# If set to 0, disables passive checks and the agent will not listen on any TCP port.## Mandatory: no# Range: 0-100# Default:# StartAgents=3##### Active checks related### Option: ServerActive# List of comma delimited IP:port (or hostname:port) pairs of Zabbix servers for active checks.# If port is not specified, default port is used.# IPv6 addresses must be enclosed in square brackets if port for that host is specified.# If port is not specified, square brackets for IPv6 addresses are optional.# If this parameter is not specified, active checks are disabled.# Example: ServerActive=127.0.0.1:20051,zabbix.domain,[::1]:30051,::1,[12fc::1]## Mandatory: no# Default:# ServerActive=ServerActive=127.0.0.1### Option: Hostname# Unique, case sensitive hostname.# Required for active checks and must match hostname as configured on the server.# Value is acquired from HostnameItem if undefined.## Mandatory: no# Default:# Hostname=Hostname=Windows host### Option: HostnameItem# Item used for generating Hostname if it is undefined. Ignored if Hostname is defined.# Does not support UserParameters or aliases.## Mandatory: no# Default:# HostnameItem=system.hostname### Option: HostMetadata# Optional parameter that defines host metadata.# Host metadata is used at host auto-registration process.# An agent will issue an error and not start if the value is over limit of 255 characters.# If not defined, value will be acquired from HostMetadataItem.## Mandatory: no# Range: 0-255 characters# Default:# HostMetadata=HostMetadata=wonders_windows_1### Option: HostMetadataItem# Optional parameter that defines an item used for getting host metadata.# Host metadata is used at host auto-registration process.# During an auto-registration request an agent will log a warning message if# the value returned by specified item is over limit of 255 characters.# This option is only used when HostMetadata is not defined.## Mandatory: no# Default:# HostMetadataItem=### Option: RefreshActiveChecks# How often list of active checks is refreshed, in seconds.## Mandatory: no# Range: 60-3600# Default:# RefreshActiveChecks=120### Option: BufferSend# Do not keep data longer than N seconds in buffer.## Mandatory: no# Range: 1-3600# Default:# BufferSend=5### Option: BufferSize# Maximum number of values in a memory buffer. The agent will send# all collected data to Zabbix server or Proxy if the buffer is full.## Mandatory: no# Range: 2-65535# Default:# BufferSize=100### Option: MaxLinesPerSecond# Maximum number of new lines the agent will send per second to Zabbix Server# or Proxy processing &apos;log&apos;, &apos;logrt&apos; and &apos;eventlog&apos; active checks.# The provided value will be overridden by the parameter &apos;maxlines&apos;,# provided in &apos;log&apos;, &apos;logrt&apos; or &apos;eventlog&apos; item keys.## Mandatory: no# Range: 1-1000# Default:# MaxLinesPerSecond=20############ ADVANCED PARAMETERS #################### Option: Alias# Sets an alias for an item key. It can be used to substitute long and complex item key with a smaller and simpler one.# Multiple Alias parameters may be present. Multiple parameters with the same Alias key are not allowed.# Different Alias keys may reference the same item key.# For example, to retrieve paging file usage in percents from the server:# Alias=pg_usage:perf_counter[\Paging File(_Total)\% Usage]# Now shorthand key pg_usage may be used to retrieve data.# Aliases can be used in HostMetadataItem but not in HostnameItem or PerfCounter parameters.## Mandatory: no# Range:# Default:### Option: Timeout# Spend no more than Timeout seconds on processing.## Mandatory: no# Range: 1-30# Default:# Timeout=3### Option: PerfCounter# Syntax: &lt;parameter_name&gt;,&quot;&lt;perf_counter_path&gt;&quot;,&lt;period&gt;# Defines new parameter &lt;parameter_name&gt; which is an average value for system performance counter &lt;perf_counter_path&gt; for the specified time period &lt;period&gt; (in seconds).# For example, if you wish to receive average number of processor interrupts per second for last minute, you can define new parameter &quot;interrupts&quot; as following:# PerfCounter = interrupts,&quot;\Processor(0)\Interrupts/sec&quot;,60# Please note double quotes around performance counter path.# Samples for calculating average value will be taken every second.# You may run &quot;typeperf -qx&quot; to get list of all performance counters available in Windows.## Mandatory: no# Range:# Default:### Option: Include# You may include individual files in the configuration file.## Mandatory: no# Default:# Include=# Include=c:\zabbix\zabbix_agentd.userparams.conf# Include=c:\zabbix\zabbix_agentd.conf.d\# Include=c:\zabbix\zabbix_agentd.conf.d\*.conf####### USER-DEFINED MONITORED PARAMETERS ########## Option: UnsafeUserParameters# Allow all characters to be passed in arguments to user-defined parameters.# The following characters are not allowed:# \ &apos; &quot; ` * ? [ ] &#123; &#125; ~ $ ! &amp; ; ( ) &lt; &gt; | # @# Additionally, newline characters are not allowed.# 0 - do not allow# 1 - allow## Mandatory: no# Range: 0-1# Default:# UnsafeUserParameters=0### Option: UserParameter# User-defined parameter to monitor. There can be several user-defined parameters.# Format: UserParameter=&lt;key&gt;,&lt;shell command&gt;## Mandatory: no# Default:# UserParameter=####### TLS-RELATED PARAMETERS ########## Option: TLSConnect# How the agent should connect to server or proxy. Used for active checks.# Only one value can be specified:# unencrypted - connect without encryption# psk - connect using TLS and a pre-shared key# cert - connect using TLS and a certificate## Mandatory: yes, if TLS certificate or PSK parameters are defined (even for &apos;unencrypted&apos; connection)# Default:# TLSConnect=unencrypted### Option: TLSAccept# What incoming connections to accept.# Multiple values can be specified, separated by comma:# unencrypted - accept connections without encryption# psk - accept connections secured with TLS and a pre-shared key# cert - accept connections secured with TLS and a certificate## Mandatory: yes, if TLS certificate or PSK parameters are defined (even for &apos;unencrypted&apos; connection)# Default:# TLSAccept=unencrypted### Option: TLSCAFile# Full pathname of a file containing the top-level CA(s) certificates for# peer certificate verification.## Mandatory: no# Default:# TLSCAFile=### Option: TLSCRLFile# Full pathname of a file containing revoked certificates.## Mandatory: no# Default:# TLSCRLFile=### Option: TLSServerCertIssuer# Allowed server certificate issuer.## Mandatory: no# Default:# TLSServerCertIssuer=### Option: TLSServerCertSubject# Allowed server certificate subject.## Mandatory: no# Default:# TLSServerCertSubject=### Option: TLSCertFile# Full pathname of a file containing the agent certificate or certificate chain.## Mandatory: no# Default:# TLSCertFile=### Option: TLSKeyFile# Full pathname of a file containing the agent private key.## Mandatory: no# Default:# TLSKeyFile=### Option: TLSPSKIdentity# Unique, case sensitive string used to identify the pre-shared key.## Mandatory: no# Default:# TLSPSKIdentity=### Option: TLSPSKFile# Full pathname of a file containing the pre-shared key.## Mandatory: no# Default:# TLSPSKFile= 注册zabbix服务管理员身份运行cmd 切换到zabbix目录下123456zabbix_agentd.exe -c .C:\Program Files\zabbix\zabbix_agentd.win.conf -i -c 表示配置文件路径 -i 表示安装 删除的话： -d 表示卸载zabbix_agentd.exe -s #启动或者去服务里面手动启动 完]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>zabbix agent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix-grafana]]></title>
    <url>%2F2017%2F04%2F11%2Fzabbix-grafana%2F</url>
    <content type="text"><![CDATA[前言(封面图片来自网上)Grafana是一个可视化面板（Dashboard），有非常漂亮的图表和布局展示，通过插件与zabbix结合,可以很好的弥补zabbix图形化扎眼的缺点 centos7 官网demografana-zabbix 官方文档官方安装教程 简单说明12345678910#安装grafana sudo yum install https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-4.2.0-1.x86_64.rpm#安装zabbix 插件 grafana-cli plugins install alexanderzobnin-zabbix-app#安装饼图插件 grafana-cli plugins install grafana-piechart-panel#启动grafanasystemctl start grafana-serversystemctl enable grafana-server 访问IPADDRESS:3000 即可打开grafana的登录界面默认的账户密码都是admin进去之后开启zabbix插件，Plugins里开启。然后点击数据源(Data sources),添加数据源(add data sources)然后添加zabbix数据源 这里的URL要是zabbix网站地址 比如：http://1.1.1.1/zabbix/api_jsonrpc.php grafana-zabbix 官方文档有如何添加机器,以及如何通过template添加机器的教程 创建模板 这里简单记录如何通过模板添加主机 grafana 提供了四个变量,用来确认 群组,主机,应用集,监控项,一般情况下我们只要定义下group,host,item就能进行分组/分类监控了. 添加模板变量 这里通过添加两个变量 帮助理解模板的变量 这样两个变量定义下来,就能对组和主机进行一个筛选,当然还可以定义变量对应用,监控项等进行筛选.不再述123456query的匹配原则 * returns all groups *.* returns all hosts (from all groups) Servers.* returns all hosts in group Servers Servers.*.* returns all applications in group Servers Servers.*.*.* returns all items from hosts in group Servers 保存模版后,可以给模板添加图形 完]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>grafana</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php-ajax]]></title>
    <url>%2F2017%2F04%2F08%2Fphp-ajax%2F</url>
    <content type="text"><![CDATA[前言日常我们最常见的就是百度搜索，输入的时候，还没输入完，搜索结果已经出现了，并且会随着你的输入而改变.其实这就是ajax 第一次需要Ajax的时候还不知道它叫ajax，那时候只想实现系统的一个功能，选中主选项后，剩余的子选项会随之而变，从而对选择结果有个过滤，然后就查到了AJAX。 什么是AJAX 简单来说就是异步传输专业点：Asynchronous JavaScript and XML（异步的 JavaScript 和 XML）。这里又引出了个新概念，同步和异步 同步和异步 专业的知识也就不说了，毕竟也没深究大概解释下同步和异步的概念，我们打电话是同步，而发消息是异步。同步交互：发出一个请求后，要等待服务器响应结束，才能发第二个。异步交互：发出一个请求后，无需等待服务器响应结束，就可发出第二个。 Ajax原理 Ajax的原理简单来说通过XmlHttpRequest对象来向服务器发异步请求，从服务器获得数据，然后用javascript来操作DOM而更新页面。这其中最关键的一步就是从服务器获得请求数据。要清楚这个过程和原理，我们必须对 XMLHttpRequest有所了解。XMLHttpRequest是ajax的核心机制，它是在IE5中首先引入的，是一种支持异步请求的技术。简单的说，也就是javascript可以及时向服务器提出请求和处理响应，而不阻塞用户。达到无刷新的效果。所以我们先了解下XMLHttpRequest XMLHttpRequest 属性 解释 onreadystatechange 每次状态改变所触发事件的事件处理程序 responseText 服务器进程返回数据的字符串形式 responseXML 服务器进程返回的DOM兼容的文档数据对象 status 服务器返回的数字代码，比如常见的404（未找到）200（已就绪） status Text 伴随状态码的字符串信息 readyState 对象状态值 readyState 数值 含义 0 (未初始化) 对象已建立，但是尚未初始化（尚未调用open方法） 1 (初始化) 对象已建立，尚未调用send方法 2 (发送数据) send方法已调用，但是当前的状态及http头未知 3 (数据传送中) 已接收部分数据，因为响应及http头不全，这时通过responseBody和responseText获取部分数据会出现错误 4 (完成) 数据接收完毕,此时可以通过通过responseXml和responseText获取完整的回应数据 很明显，当readyState返回值为4的时候，证明是程序是正常走完的。 Ajax的实现由于各浏览器之间存在差异，所以创建一个XMLHttpRequest对象可能需要不同的方法。下面是一个当初学习的笔记，算是个比较标准的创建XMLHttpRequest对象的方法。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354ajax.js 后面还有两个页面程序 function getXmlHttpObject()&#123; var xmlhttp; if(window.XMLHttpRequest)&#123; //code for IE7+, Firefox, Chrome, Opera, Safari xmlhttp=new XMLHttpRequest(); &#125;else&#123; //code for IE6, IE5 xmlhttp=new ActiveXObject(&quot;Microsoft.XMLHTTP&quot;); &#125; return xmlhttp; &#125; //验证 var myXmlHttpRequest=&quot;&quot;; function checkName()&#123; myXmlHttpRequest=getXmlHttpObject(); //通过ajax对象发送请求 if (myXmlHttpRequest)&#123; //get 方式 var url=&quot;tb.php?username=&quot;+document.getElementById(&apos;username&apos;).value; myXmlHttpRequest.open(&quot;get&quot;,url,true); //第一个参数：表示提交数据方式, 即post还是get //第二个参数：请求的url地址和传递的参数 //第三个参数：传输方式，false为同步，true为异步。默认为true。 //指定回调函数也就是chuli 由于会实验两次使用，所以封装了函数调用 myXmlHttpRequest.onreadystatechange=chuli; 真的发送请求,如果是get请求则填入空，如果是post填写实际数据 myXmlHttpRequest.send(null); //psot方式 var url=&quot;tb.php&quot;; var data=&quot;username=&quot;+document.getElementById(&apos;username&apos;).value; myXmlHttpRequest.open(&quot;POST&quot;,url,true); //必须要的一句话,定义传输的文件HTTP头信息 myXmlHttpRequest.setRequestHeader(&quot;Content-Type&quot;,&quot;application/x-www-form-urlencoded&quot;); //回调函数 myXmlHttpRequest.onreadystatechange=chuli; // 发送 myXmlHttpRequest.send(data); &#125; &#125; function chuli()&#123; //window.alert(&quot;chuli 被调用&quot;+myXmlHttpRequest.readyState) if(myXmlHttpRequest.readyState==4)&#123; //window.alert(&apos;服务器返回的是：&apos;+myXmlHttpRequest.responseText); document.getElementById(&apos;tishi&apos;).value=myXmlHttpRequest.responseText; &#125; &#125; 123456789101112131415161718192021222324ta.php（注册界面）&lt;html&gt;&lt;head&gt;&lt;title&gt;regist&lt;/title&gt;&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=utf-8&quot; /&gt;&lt;script src=&apos;ajax.js&apos; charset=&apos;gbk&apos; &gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;h4&gt;账户注册&lt;/h4&gt; &lt;form action=&quot;#&quot; method=&quot;post&quot;&gt; 账户：&lt;input type=&quot;text&quot; name=&quot;username&quot; onkeyup=&quot;checkName()&quot; id=&quot;username&quot;/&gt; &lt;input type=&quot;button&quot; value=&quot;验证&quot; onclick=&quot;checkName()&quot; /&gt; &lt;input type=&quot;text&quot; style=&quot;border:0&quot; id=&quot;tishi&quot; /&gt; &lt;br/&gt; &lt;br/&gt; 密码：&lt;input type=&quot;password&quot; name=&quot;password&quot;/&gt; &lt;br/&gt; &lt;br/&gt; 邮箱：&lt;input type=&quot;email&quot; name=&quot;email&quot;/&gt; &lt;br/&gt; &lt;br/&gt; &lt;input type=&quot;Submit&quot; name=&quot;regist&quot; value=&quot;注册&quot;/&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt; 12345678910tb.php（输出页面）&lt;?php //$username=$_GET[&apos;username&apos;];$username=$_POST[&apos;username&apos;];if($username==someone)&#123; echo $username.&quot;用户已存在&quot;;&#125;else&#123; echo $username.&quot;用户可用&quot;;&#125; 一个简单的案例就完成了，帮助自己理解Ajax]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>ajax</tag>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix-python-wechat告警推送]]></title>
    <url>%2F2017%2F03%2F31%2Fzabbix-python-wechat%E5%91%8A%E8%AD%A6%E6%8E%A8%E9%80%81%2F</url>
    <content type="text"><![CDATA[前言zabbx告警结合微信,可以更及时对故障响应,处理. 告警的模式分为两种,第一种就是本文消息的直接推送,第二种是图文推送,可做到交互,本文主要介绍第一种 前提条件 zabbix 企业号 脚本 企业号申请不赘述. 获取信息取得企业号的部门ID,应用ID, CorpID,Secret 脚本脚本可以推送两种格式,文本和新闻. 推送文本来自网上, 视情况修改4处 self.__corpid 和self.__secret toparty agentid1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980#!/usr/bin/env python# coding: utf-8import urllib,urllib2,jsonimport sysreload(sys)sys.setdefaultencoding( &quot;utf-8&quot; )class WeChat(object): __token_id = &apos;&apos; # init attribute def __init__(self,url): self.__url = url.rstrip(&apos;/&apos;) #CorpID self.__corpid = &apos;wx643f**********&apos; #Secret self.__secret = &apos;YQOu7Qzad********hGJ9xHlby****_v1oF2WpBOlsy****TivMKAL***voA3MwKH&apos; # Get TokenID def authID(self): params = &#123;&apos;corpid&apos;:self.__corpid, &apos;corpsecret&apos;:self.__secret&#125; data = urllib.urlencode(params) content = self.getToken(data) try: self.__token_id = content[&apos;access_token&apos;] # print content[&apos;access_token&apos;] except KeyError: raise KeyError # Establish a connection def getToken(self,data,url_prefix=&apos;/&apos;): url = self.__url + url_prefix + &apos;gettoken?&apos; try: response = urllib2.Request(url + data) except KeyError: raise KeyError result = urllib2.urlopen(response) content = json.loads(result.read()) return content # Get sendmessage url def postData(self,data,url_prefix=&apos;/&apos;): url = self.__url + url_prefix + &apos;message/send?access_token=%s&apos; % self.__token_id request = urllib2.Request(url,data) try: result = urllib2.urlopen(request) except urllib2.HTTPError as e: if hasattr(e,&apos;reason&apos;): print &apos;reason&apos;,e.reason elif hasattr(e,&apos;code&apos;): print &apos;code&apos;,e.code return 0 else: content = json.loads(result.read()) result.close() return content # send message def sendMessage(self,touser,message): self.authID()# 具体可查看wechat接口文档http://qydev.weixin.qq.com/ data = json.dumps(&#123; #&apos;touser&apos;:touser, #企业号中的用户帐号,如果没,则按部门推送. &apos;toparty&apos;:&quot;3&quot;, #部门ID &apos;msgtype&apos;:&quot;text&quot;, &apos;agentid&apos;:&quot;1&quot;, #应用ID &apos;text&apos;:&#123; &apos;content&apos;:message &#125;, &apos;safe&apos;:&quot;0&quot; &#125;,ensure_ascii=False) response = self.postData(data) print responseif __name__ == &apos;__main__&apos;: a = WeChat(&apos;https://qyapi.weixin.qq.com/cgi-bin&apos;) a.sendMessage(sys.argv[1], sys.argv[3]) 推送news同样的脚本,需要修改如下1234567891011121314151617181920212223242526272829303132333435##图文格式(推荐),修改脚本的data如下 data = json.dumps(&#123; &apos;touser&apos;:touser, #企业号中的用户帐号 &apos;toparty&apos;:&quot;3&quot;, #部门ID &apos;msgtype&apos;:&quot;news&quot;, &apos;agentid&apos;:&quot;1&quot;, #应用ID &apos;news&apos;:&#123; &quot;articles&quot;:[&#123; &quot;title&quot;:title, &quot;description&quot;:message &#125;] &#125;, &quot;safe&quot;:0 &#125;,ensure_ascii=False)##end##修改1：import re2：def sendMessage(self,touser,message): 修改为def sendMessage(self,touser,title,message):3：if __name__ == &apos;__main__&apos;: a = WeChat(&apos;https://qyapi.weixin.qq.com/cgi-bin&apos;) a.sendMessage(sys.argv[1], sys.argv[3])修改为if __name__ == &apos;__main__&apos;: a = WeChat(&apos;https://qyapi.weixin.qq.com/cgi-bin&apos;) info = sys.argv[3] info2 = re.split(&apos;[&amp;&amp;]&apos;,info) a.sendMessage(sys.argv[1],info2[0],info2[2])4：zabbix页面的动作-默认信息中添加&amp;&amp; 用来进行信息分割 脚本放至zbx脚本目录下即可 zabbix媒介配置 管理 —&gt; 媒介—&gt; 新建名称随便,这里命名wechat脚本名称要和上面的一致wechat.py脚本参数要依次填写以下三个这三个参数就是传给脚本的sys.argv[] 123&#123;ALERT.SENDTO&#125;&#123;ALERT.SUBJECT&#125;&#123;ALERT.MESSAGE&#125; 用户 创建一个wechat用户,给予相关用户媒介权限(刚刚创建的媒介)注意收件人,这个是脚本的第一个参数.也就是说这里要填写的是应该是微信用户，或者部门ID，这里填写部门ID 这样wechat.py脚本才能取得正确的值 动作 动作的 操作选项–&gt;选发送消息,添加相应的用户 或者群组就行了.我是发送给wechat用户的,因为他关联了wechat.py媒介.所以所有的消息将传递给他,他的媒介连接脚本,脚本连接企业微信,整个流程就打通了. 参考配置告警:123456789&#123;TRIGGER.SEVERITY&#125; : &#123;TRIGGER.NAME&#125;&amp;&amp;-------------------------------------------ID：&#123;EVENT.ID&#125;主机名称:&#123;HOST.NAME&#125;主机地址:&#123;HOST.IP&#125;告警时间:&#123;EVENT.DATE&#125; - &#123;EVENT.TIME&#125;告警描述:&#123;TRIGGER.DESCRIPTION&#125;--------------------------------- 恢复:1234567891011恢复 : &#123;TRIGGER.NAME&#125;&amp;&amp;-------------------------------------------ID：&#123;EVENT.ID&#125;主机名称:&#123;HOST.NAME&#125;主机地址:&#123;HOST.IP&#125;告警时间:&#123;EVENT.DATE&#125; - &#123;EVENT.TIME&#125;恢复时间:&#123;EVENT.RECOVERY.DATE&#125; - &#123;EVENT.RECOVERY.TIME&#125;持续时间:&#123;EVENT.AGE&#125;告警等级: &#123;TRIGGER.SEVERITY&#125;告警描述:&#123;TRIGGER.DESCRIPTION&#125; 图文(参考)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168#!/usr/bin/env python3# coding: utf-8import sysimport requestsfrom time import sleepimport jsonimport timeWX_CORPID = r&quot;wx643f8***********&quot;WX_CORPSECRET = r&quot;qwojyG*******************&quot;WX_TOKEN_FILE = &quot;/tmp/accesstoken&quot;AGENT_ID = &apos;100000*&apos;TOPARTY=&apos;*&apos;LOG_FILE=&quot;/tmp/zabbix_send_log&quot;def c_log(msg): try: perameter_file=open(LOG_FILE,&apos;a&apos;) perameter_file.write(msg+&quot;\n&quot;) except: exit(1) finally: perameter_file.close()def refresh_token(corpid=WX_CORPID, corpsecrt=WX_CORPSECRET): get_url = r&quot;https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid=&quot; + WX_CORPID + &quot;&amp;corpsecret=&quot; + WX_CORPSECRET for i in range(3): try: req_ret = requests.get(get_url, timeout=6) jso_ret = req_ret.json() file_tok = open(WX_TOKEN_FILE, &quot;w&quot;) file_tok.write(jso_ret[&quot;access_token&quot;]) file_tok.close() return jso_ret[&quot;access_token&quot;] except requests.exceptions.ConnectTimeout: sleep(10) except Exception as exc: print(exc.args) return None return Nonedef get_token(corpid=WX_CORPID, corpsecrt=WX_CORPSECRET): try: file_tok = open(WX_TOKEN_FILE, &quot;r&quot;) token = file_tok.read() file_tok.close() if len(token) !=64: raise FileNotFoundError(r&quot;token length !=64&quot;) return token except FileNotFoundError: get_url = r&quot;https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid=&quot; + WX_CORPID + &quot;&amp;corpsecret=&quot; + WX_CORPSECRET for i in range(3): try: req_ret = requests.get(get_url, timeout=6) jso_ret = req_ret.json() file_tok = open(WX_TOKEN_FILE, &quot;w&quot;) file_tok.write(jso_ret[&quot;access_token&quot;]) file_tok.close() return jso_ret[&quot;access_token&quot;] except requests.exceptions.ConnectTimeout: sleep(10) except Exception as exc: print(exc.args) return None except Exception as exc: print(exc.args) return Nonedef create_articles(): msg_argv=sys.argv[3].split(&quot;&amp;&amp;&quot;) if(msg_argv[0]==&quot;PROBLEM&quot;): if(msg_argv[1]==&quot;灾难&quot;): pic_url=&quot;图片地址&quot; elif(msg_argv[1]==&quot;一般严重&quot;): pic_url=&quot;图片地址&quot; elif(msg_argv[1]==&quot;严重&quot;): pic_url=&quot;图片地址&quot; elif(msg_argv[1]==&quot;警告&quot;): pic_url=&quot;图片地址&quot; elif(msg_argv[1]==&quot;通知&quot;): pic_url=&quot;图片地址&quot; else: pic_url=&quot;图片地址&quot; ret = [ &#123; &quot;title&quot;: &quot;%s&quot;%(msg_argv[2]), &quot;description&quot;:&quot;ID:%s\n告警时间: %s&quot;%(msg_argv[3],msg_argv[7]), &#125;, &#123; &quot;title&quot;:&quot;主机分类: %s \n主机名称: %s \n主机地址: %s&quot;%(msg_argv[4],msg_argv[5],msg_argv[6]), &quot;picurl&quot;: &quot;%s&quot;%pic_url &#125;, &#123; &quot;title&quot;:&quot;告警描述:\n%s&quot;%(msg_argv[8]), &#125; ] return ret elif(msg_argv[0]==&quot;OK&quot;): if(msg_argv[1]==&quot;通知&quot;): return None else: pic_url=&quot;图片地址&quot; return [ &#123; &quot;title&quot;: &quot;恢复-%s&quot;%(msg_argv[2]), &quot;description&quot;:&quot;ID: %s\n持续时长：%s\n恢复时间: %s\n告警时间: %s&quot;%(msg_argv[3],msg_argv[10],msg_argv[7],msg_argv[9]), &#125;, &#123; &quot;title&quot;:&quot;主机分类: %s\n主机名称: %s\n主机地址: %s&quot;%(msg_argv[4],msg_argv[5],msg_argv[6]), &quot;picurl&quot;: &quot;%s&quot;%pic_url &#125;, &#123; &quot;title&quot;:&quot;告警等级: %s\n告警描述: %s&quot;%(msg_argv[1],msg_argv[8]) &#125; ] return None#def send_news(type,target,arti):def send_news(arti): access_token = get_token() if access_token == None: return 1 send_msg_url = r&quot;https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token=&quot;+access_token msg_josn =&#123;&#125; msg_josn[&quot;toparty&quot;] = TOPARTY msg_josn[&quot;msgtype&quot;] = &quot;news&quot; msg_josn[&quot;agentid&quot;] = AGENT_ID msg_josn[&quot;news&quot;] = &#123;&quot;articles&quot;: arti&#125; #print (msg_josn) send_data = json.dumps(msg_josn, ensure_ascii=False).encode(encoding=&apos;UTF8&apos;,) #print(send_data) for i in range(4): try: if i &gt;= 4: return 1 req_ret = requests.post(send_msg_url, data=send_data, timeout=5) c_log(req_ret.text) jos_ret = req_ret.json() if jos_ret[&quot;errcode&quot;] == 0: return 0 elif jos_ret[&quot;errcode&quot;] == 40014: token = refresh_token(WX_CORPID, WX_CORPSECRET) if token == None: return 1 access_token = token send_msg_url = r&quot;https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token=&quot; + access_token else: return 1 except requests.exceptions.ConnectTimeout: sleep(2) except Exception as exc: return 1 return 1if __name__==&quot;__main__&quot;: articles=create_articles() #if(articles==None): # exit(1) #send_news(0,sys.argv[1],articles)# send_news(articles) if(send_news(articles)!=0): exit(1)#告警&#123;TRIGGER.STATUS&#125;&amp;&amp;&#123;TRIGGER.SEVERITY&#125;&amp;&amp;&#123;HOST.NAME&#125;-&#123;TRIGGER.NAME&#125;&amp;&amp;&#123;EVENT.ID&#125;&amp;&amp;&#123;TRIGGER.HOSTGROUP.NAME&#125;&amp;&amp;&#123;HOST.NAME&#125;&amp;&amp;&#123;HOST.IP&#125;&amp;&amp;&#123;EVENT.DATE&#125;-&#123;EVENT.TIME&#125;&amp;&amp;&#123;TRIGGER.DESCRIPTION&#125;#恢复&#123;TRIGGER.STATUS&#125;&amp;&amp;&#123;TRIGGER.SEVERITY&#125;&amp;&amp;&#123;HOST.NAME&#125;-&#123;TRIGGER.NAME&#125;&amp;&amp;&#123;EVENT.ID&#125;&amp;&amp;&#123;TRIGGER.HOSTGROUP.NAME&#125;&amp;&amp;&#123;HOST.NAME&#125;&amp;&amp;&#123;HOST.IP&#125;&amp;&amp;&#123;EVENT.DATE&#125; - &#123;EVENT.TIME&#125;&amp;&amp;&#123;TRIGGER.DESCRIPTION&#125;&amp;&amp;&#123;EVENT.RECOVERY.DATE&#125; - &#123;EVENT.RECOVERY.TIME&#125;&amp;&amp;&#123;EVENT.AGE&#125; 可推送出类似如下格式的告警 图文(参考)进阶 对web开发有一定了解,熟悉python,zabbix API,微信API,用Django做后台处理交互.可推出如下告警.有想法的可研究,过程复杂,三言两语讲不清. 完]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix-server-is-not-running]]></title>
    <url>%2F2017%2F03%2F30%2Fzabbix-server-is-not-running%2F</url>
    <content type="text"><![CDATA[前言(图片来自网上)zabbix server is not running: the infomation displayed may not be current 看log( /tmp/zabbix_server.log) Connection to database &#39;xxx&#39; failed: [1045] Access denied for user &#39;xxx&#39;@&#39;localhost&#39; (using password: NO) 看端口123[root@localhost conf]# netstat -ntlp |grep zabbixtcp 0 0 0.0.0.0:10050 0.0.0.0:* LISTEN 3672/zabbix_agentdtcp 0 0 :::10050 :::* LISTEN 3672/zabbix_agentd 我本机装了agent ,自己监控自己.可以看到zabbix_server的端口10051根本就没起来,所以可能根本就不是帐号或者权限的问题.确定方向在拍错. 解决方法 检查 zabbix_server.conf 里面 密码是否启动 检查 mysql用户zabbix 是否能够正常登录 检查数据库是否授权show grants for zabbix@&#39;localhost&#39;; 1234567mysql&gt; select user,host from mysql.user;+--------+-----------+| user | host |+--------+-----------+| root | 127.0.0.1 || root | localhost |+--------+-----------+ 创建,授权grant all privileges on zabbix.* to &#39;zabbix&#39;@&#39;%&#39; identified by &#39;zabbix&#39;; 要去检查下配置文件 zabbix_server.conf1DBPassword=zabbix #注意这个配置文件 不需要加引号的! 如果出现 ERROR 1045ERROR 1045 (28000): Access denied for user ‘xxx’@’localhost’ (using password: YES) 首先照上 查看各权限,如果还不行 则1234删除匿名用户.mysql&gt; use mysql mysql&gt; delete from user where user=&apos;&apos;; mysql&gt; flush privileges; 5.10 更新今天监控突然启动不起来了.报错如出一辙,以为谁动了配置.赶紧上去看log1234567891011[root@localhost ~]# tailf /tmp/zabbix_server.log 10151:20170510:083714.639 SSH2 support: YES 10151:20170510:083714.639 IPv6 support: YES 10151:20170510:083714.639 TLS support: NO 10151:20170510:083714.639 ****************************** 10151:20170510:083714.639 using configuration file: /usr/local/zabbix/etc/zabbix_server.conf 10151:20170510:083714.646 current database version (mandatory/optional): 03020000/03020000 10151:20170510:083714.646 required mandatory version: 03020000 10151:20170510:083715.302 __mem_malloc: skipped 1 asked 244072 skip_min 35304 skip_max 35304 10151:20170510:083715.302 [file:strpool.c,line:53] zbx_mem_realloc(): out of memory (requested 244072 bytes) 10151:20170510:083715.302 [file:strpool.c,line:53] zbx_mem_realloc(): please increase CacheSize configuration parameter 显示CacheSize不足了.所以去配置文件调整下就好了.]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix-proxy搭建]]></title>
    <url>%2F2017%2F03%2F29%2Fzabbix-proxy%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[流程 安装proxy—&gt;监控proxy—&gt;配置代理的mariadb—&gt;添加proxy—&gt;使用 安装proxy12345#添加zabbix 源rpm -ivh http://repo.zabbix.com/zabbix/3.2/rhel/7/x86_64/zabbix-release-3.2-1.el7.noarch.rpm#安装相关软件yum -y install fping zabbix-proxy-mysql 监控proxy(配置agent)123456789101112131415#安装并配置zabbix-agentyum install zabbix-agent#vim /etc/zabbix/zabbix_agent.conf 进行修改Server=zabbix server IPServer active=zabbix server IPHost name=zabbixproxy #(hsotname在server上添加监控的时候是要用到的)#开启并开机启动服务#然后去server上添加主机配置---&gt; 主机---&gt; 创建主机---&gt; 主机名:上述的hostnameagent 接口 就是代理的IP地址#其余按需配置,不多赘述 配置proxy的mariadb1234567891011121314151617181920#安装mariadbyum groupinstall mariadb mariadb-client systemctl start mariadbsystemctl enable mariadb#设置密码等mysql_secure_installation#登录并创建库create database zabbix_proxy character set utf8;#创建用户并授权grant all privileges on zabbix_proxy.* to zabbix@localhost identified by 'centos';#刷新生效flush privileges#导入zabbix数据库到mariadbrpm -ql zabbix-proxy-mysql #查找schema.sql.gz文件位置cd /usr/share/doc/zabbix-proxy-mysql-3.2.4/gunzip schema.sql.gz#导入mysql -uroot -p zabbix_proxy &lt; schema.sql 添加proxy1234567891011121314151617181920212223242526#修改配置文件#vim /etc/zabbix/zabbix_proxy.confServer=zabbix server IPHostname=zabbixproxy#DB 设定档DBName=zabbixDBUser=zabbixDBPassword=111111ProxyLocalBuffer=0 #设定为0小时，除非有其他第三方应用和插件需要调用ProxyOfflineBuffer=1 #proxy或者server无法连接时，保留离线的监控数据的时间，单位小时ConfigFrequency=60 #server和proxy配置修改同步时间间隔，设定5-10分钟即可。DataSenderFrequency=10 #数据发送时间间隔，10-30s；#网络传输质量越好，可以设定间隔时间越短，监控效果也越迅速；StartPollers=10 #开启多线程数，一般不要超过30个；StartPollersUnreachable=1 #该线程用来单独监控无法连接的主机，1个即可；StartTrappers=10 #trapper线程数StartPingers=1 #fping线程数CacheSize=64M #用来保存监控数据的缓存数，根据监控主机数量适当调整；Timeout=10 #超时时间，设定不要超过30s，不然会拖慢其他监控数据抓取时间；TrapperTimeout=30 #同上FpingLocation=/usr/sbin/fping #配合simple check icmp检测使用，如不需要可关闭；其他配置默认即可；#开启并开机启动服务 回到web端 Administration--&gt;Proxies--&gt;Create proxy hostname 与上述的要一致 当我们再次创建主机的时候就可以通过 修改 由agent代理程序监测(Monitored by proxy) 选项进行选择了]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>zabbix-proxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix图形化中文乱码]]></title>
    <url>%2F2017%2F03%2F29%2Fzabbix%E5%9B%BE%E5%BD%A2%E5%8C%96%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81%2F</url>
    <content type="text"><![CDATA[主要是应为zabbix web端 默认没有中文字体库 从 windows下控制面板-&gt;字体-&gt;选择一种中文字库,宋体 楷体等上传至/var/www/html/zabbix/fonts下修改后缀为ttf 修改 include/defines.inc.php 下1define(&apos;ZBX_GRAPH_FONT_NAME&apos;, &apos;SIMKAI&apos;); // font file name #SIMKAI 是字体文件名]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix-rpm安装]]></title>
    <url>%2F2017%2F03%2F28%2Fzabbix-rpm%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[官网提供不同版本的仓库文件 此次安装以centos7为基础,zabbix3.4 安装源文件1rpm -ivh http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-2.el7.noarch.rpm 安装123yum install zabbix-server-mysql -yyum install zabbix-web-mysql -yyum -y install mariadb mariadb-server mariadb-libs mariadb-devel 启动httpd,mysql1234systemctl enable mariadbsystemctl start mariadbsystemctl enable httpdsystemctl enable httpd 设置mysql密码1mysqladmin -uroot password &apos;password&apos;; 这里建议,运行一次mysql配置向导,删除匿名用户123456运行mysql_secure_installation会执行几个设置： a)为root用户设置密码 b)删除匿名账号 c)取消root用户远程登录 d)删除test库和对test库的访问权限 e)刷新授权表使修改生效 配置php123456vi /etc/php.inidate.timezone = Asia/Shanghaimax_execution_time = 300post_max_size = 32Mmax_input_time=300memory_limit = 128M 创建zabbix库1create database zabbix charset utf8; 创建/授权创建zabbix用户并授权1234grant all privileges on zabbix.* to &apos;zabbix&apos;@&apos;%&apos; identified by &apos;zabbix&apos;;#刷新flush privileges; 导入库文件123cd /usr/share/doc/zabbix-server-mysql-3.4.3gzip -d create.sql.gzmysql -uzabbix -p zabbix &lt; create.sql 配置zabbix_server12345vi /etc/zabbix/zabbix_server.confLogFile=/var/log/zabbix/zabbix_server.logDBName=zabbixDBUser=zabbixDBPassword=zabbix 启动zabbix12systemctl start zabbix-server.service systemctl enable zabbix-server.service web访问1http://ipaddr/zabbix 最后会提示创建成功,并且提示配置文件路径 Congratulations! You have successfully installed Zabbix frontend.Configuration file “/etc/zabbix/web/zabbix.conf.php” created.]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix编译安装]]></title>
    <url>%2F2017%2F03%2F28%2Fzabbix%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[前言踩了不少坑,总结个文档. 安装基础环境(依赖)平台在 centos 7+ （PHP 5.5）12345678910yum -y install php php-mysql php-common php-gd php-ldap php-odbc php-pear php-xml php-mcrypt php-xmlrpc php-devel php-mbstring php-snmp php-soap curl curl-devel php-bcmathyum -y install mariadb mariadb-server mariadb-libs mariadb-develyum install -y httpd-manual httpd mod_ssl mod_perl mod_auth_mysqlyum install -y fping mysql-connector-odbc mysql-devel libdbi-dbd-mysql libssh2 libxml2 libxml2-devel libssh2-devel unixODBC unixODBC-develyum install -y iksemel*yum install -y net-snmp-devel net-snmp-utils curl-devel OpenIPMI OpenIPMI-devel rpm-build openldap openldap-devel java java-develyum install -y pam-devel (目的是为了安装monit来监控heartbeat等服务)yum install -y gcc*#如果php不支持mysql查看php-mysql是否安装成功 平台在 centos 6+123456789安装epel源rpm -ivh http://mirrors.sohu.com/fedora-epel/6/x86_64/epel-release-6-8.noarch.rpm然后安装支持PHP5.4 以上的源 并安装PHP 相关的服务rpm -Uvh http://mirror.webtatic.com/yum/el6/latest.rpmyum install -y httpd mysql mysql-server mysql-develyum install php55w php55w-bcmath php55w-cli php55w-common php55w-devel php55w-fpm php55w-gd php55w-imap php55w-ldap php55w-mbstring php55w-mcrypt php55w-mysql php55w-odbc php55w-pdo php55w-pear php55w-pecl-igbinary php55w-xml php55w-xmlrpc php55w-opcache php55w-intl php55w-pecl-memcache 其他的安装包同7 开启HTTPD MYSQL 安装zabbix下载zabbix 并解压12https://www.zabbix.com/download然后解压 编译并开启相关服务1./configure --prefix=/usr/local/zabbix --enable-server --enable-proxy --enable-agent --enable-ipv6 --with-mysql --with-net-snmp --with-libcurl --with-openipmi --with-ldap --with-ssh2 --with-jabber --enable-java --with-libxml2 --with-libxml2 --with-libcurl 为了开启vm的监控 创建用户和组12groupadd zabbixuseradd -g zabbix zabbix 复制文件到web目录下！ 创建目录1mkdir /var/www/html/zabbix /root/Downloads/zabbix-3.0.1/frontends/php1cp -rp * /var/www/html/zabbix/ 创建库1create database zabbix default charset utf8; 创建zabbix用户并设置密码12grant all privileges on zabbix.* to &apos;zabbix&apos;@&apos;%&apos; identified by &apos;zabbix&apos;;flush privileges; 进入解压后的zabbix目录 database/mysql 导入相应数据到zabbix数据库 导入库文件1234mysql -uroot -p zabbix &lt; schema.sql初始化server（顺序不能变）mysql -uroot -p zabbix &lt; images.sql mysql -uroot -p zabbix &lt; data.sql 启动脚本复制启动脚本到init.d/root/Downloads/zabbix-3.0.1/misc/init.d/fedora/core5123[root@localhost core5]# lszabbix_agentd zabbix_server[root@localhost core5]# cp -rp * /etc/init.d/ 注意：/usr/local/zabbix-2.2.2/etc/zabbix_*此安装路径下也两个启动程序。但是不是启动脚本。曾经使用这两个命令，但是zabbix启动不起来。所以使用了启动脚本 然后修改这两个脚本文件中zabbix的路径ZABBIX_BIN=”/usr/local/zabbix/sbin/zabbix_server” 修改/etc/php.ini，使配置达到要求 123456max_execution_time = 300 memory_limit = 128M post_max_size = 16M upload_max_filesize = 2M max_input_time = 300 date.timezone=Asia/Shanghai 启动相关服务123456/etc/init.d/zabbix_agentd start/etc/init.d/zabbix_server startsystemctl start httpd.service systemctl enable httpdsystemctl start mariadbsystemctl enable mariadb 访问本机地址下的zabbix网站进行设置]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ansible-salt-puppet对比]]></title>
    <url>%2F2017%2F03%2F25%2Fansible-salt-puppet%E5%AF%B9%E6%AF%94%2F</url>
    <content type="text"><![CDATA[对三种运维工具做了图,进行了简单的对比]]></content>
      <categories>
        <category>运维工具</category>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>ansible</tag>
        <tag>saltstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[saltstack基础]]></title>
    <url>%2F2017%2F03%2F25%2Fsaltstack%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[salt简介 SaltStack是一个服务器基础架构集中化管理平台，具备配置管理、远程执行、监控等功能，基于Python语言实现，结合轻量级消息队列（ZeroMQ）与Python第三方模块（Pyzmq、PyCrypto、Pyjinjia2、python-msgpack和PyYAML等）构建。 通过部署SaltStack，我们可以在成千万台服务器上做到批量执行命令，根据不同业务进行配置集中化管理、分发文件、采集服务器数据、操作系统基础及软件包管理等，SaltStack是运维人员提高工作效率、规范业务配置与操作的利器。 salt基本原理 SaltStack 采用 C/S模式，server端就是salt的master，client端就是minion，minion与master之间通过ZeroMQ消息队列通信 minion上线后先与master端联系，把自己的pub key发过去，这时master端通过salt-key -L命令就会看到minion的key，接受该minion-key后，也就是master与minion已经互信 master可以发送任何指令让minion执行了，salt有很多可执行模块，比如说cmd模块，在安装minion的时候已经自带了，它们通常位于你的python库中，locate salt | grep /usr/ 可以看到salt自带的所有东西。 这些模块是python写成的文件，里面会有好多函数，如cmd.run，当我们执行salt &#39;*&#39; cmd.run &#39;uptime&#39;的时候，master下发任务匹配到的minion上去，minion执行模块函数，并返回结果。master监听4505和4506端口，4505对应的是ZMQ的PUB system，用来发送消息，4506对应的是REP system是来接受消息的。 具体步骤如下 Salt stack的Master与Minion之间通过ZeroMq进行消息传递，使用了ZeroMq的发布-订阅模式，连接方式包括tcp，ipc salt命令，将cmd.run ls命令从salt.client.LocalClient.cmd_cli发布到master，获取一个Jodid，根据jobid获取命令执行结果。 master接收到命令后，将要执行的命令发送给客户端minion。 minion从消息总线上接收到要处理的命令，交给minion._handle_aes处理 minion._handle_aes发起一个本地线程调用cmdmod执行ls命令。线程执行完ls后，调用minion._return_pub方法，将执行结果通过消息总线返回给master master接收到客户端返回的结果，调用master._handle_aes方法，将结果写的文件中 salt.client.LocalClient.cmd_cli通过轮询获取Job执行结果，将结果输出到终端。 安装salt 导入salt 密钥 12345678910111213141516177版本rpm --import https://repo.saltstack.com/yum/redhat/7/x86_64/latest/SALTSTACK-GPG-KEY.pub6版本rpm --import https://repo.saltstack.com/yum/redhat/6/x86_64/latest/SALTSTACK-GPG-KEY.pub#新增 /etc/yum.repos.d/saltstack.repo7 &amp; 6版本[saltstack-repo] name = RHEL / CentOS $ releasever的SaltStack repo baseurl = https://repo.saltstack.com/yum/redhat/$releasever/$basearch/latest enabled = 1 gpgcheck = 1 gpgkey = https：// repo.saltstack.com/yum/redhat/$releasever/$basearch/latest/SALTSTACK-GPG-KEY.pub 安装 salt-minion, salt-master,或Salt components: 12345yum install salt-masteryum install salt-minionyum install salt-sshyum install salt-syndicyum install salt-cloud 配置saltmaster 一般使用默认就好 (/etc/salt/master) 1234567891011121314151617181920212223242526272829303132#指定master，冒号后有一个空格master: 192.168.2.22user: root#-------以下为可选--------------# salt运行的用户，影响到salt的执行权限user: root#s alt的运行线程，开的线程越多一般处理的速度越快，但一般不要超过CPU的个数worker_threads: 10# master的管理端口publish_port : 4505# master跟minion的通讯端口，用于文件服务，认证，接受返回结果等ret_port : 4506# 如果这个master运行的salt-syndic连接到了一个更高层级的master,那么这个参数需要配置成连接到的这个高层级master的监听端口syndic_master_port : 4506# 指定pid文件位置pidfile: /var/run/salt-master.pid# saltstack 可以控制的文件系统的开始位置root_dir: /# 日志文件地址log_file: /var/log/salt_master.log# 分组设置nodegroups: group_all: '*'# salt state执行时候的根目录file_roots: base: - /srv/salt/# 设置pillar 的根目录pillar_roots: base: - /srv/pillar 启动master 12systemctl start salt-mastersystemctl enable salt-master minion(/etc/salt/minion) 12345678910111213141516171819202122232425262728293031323334#指定master，冒号后有一个空格master: 192.168.2.22id: minion-01user: root#-------以下为可选--------------# minion的识别ID，可以是IP，域名，或是可以通过DNS解析的字符串id: 192.168.0.100# salt运行的用户权限user: root# master的识别ID，可以是IP，域名，或是可以通过DNS解析的字符串master : 192.168.0.100# master通讯端口master_port: 4506# 备份模式，minion是本地备份，当进行文件管理时的文件备份模式backup_mode: minion# 执行salt-call时候的输出方式output: nested # minion等待master接受认证的时间acceptance_wait_time: 10# 失败重连次数，0表示无限次，非零会不断尝试到设置值后停止尝试acceptance_wait_time_max: 0# 重新认证延迟时间，可以避免因为master的key改变导致minion需要重新认证的syn风暴random_reauth_delay: 60# 日志文件位置log_file: /var/logs/salt_minion.log# 文件路径基本位置file_roots: base: - /etc/salt/minion/file# pillar基本位置pillar_roots: base: - /data/salt/minion/pillar 启动minion 12systemctl start salt-mastersystemctl enable salt-master 添加key master 端查看key 1234567891011121314151617181920[root@master salt]# salt-key Accepted Keys:Denied Keys:Unaccepted Keys: #可看到 minion已经检测到，没有认证keyminion-01Rejected Keys:[root@master salt]# salt-key -a minion-01The following keys are going to be accepted:Unaccepted Keys:minion-01Proceed? [n/Y] y #Y确认添加Key for minion minion-01 accepted. #添加成功[root@master salt]# salt-key Accepted Keys:minion-01Denied Keys:Unaccepted Keys:Rejected Keys:[root@master salt]# salt-key常用参数 -a 添加指定ID 的key -A 添加全部 -R 拒绝全部 -d 删除指定ID的 -D 删除全部 测试连通性1234[root@master salt]# salt 'minion-01' test.pingminion-01: True #返回结果表示成功[root@master salt]# 简单服务的安装12345678910111213141516171819[root/] ]$salt 'minion-01' pkg.install ftp #解释minion-01: ---------- ftp: ---------- new: 0.17-67.el7 old:[root/] ]$#去minion查看[root@minion-01 tmp]# rpm -qa ftpftp-0.17-67.el7.x86_64#salt 'minion-01' pkg.install ftp#1.'*' 代表的是target是指在那些minion上操作#2. 'pkg' 是一个执行模块,就像'test' #3.'install' 是执行模块下面的函数，像test下的ping#4.'ftp' 是函数的参数(arg)，有的函数需要参数，有的不需要比如test.ping就不需要参数 123456##查看所有执行模块的docsalt 'minion' sys.doc##查看test模块的帮助salt 'minion' sys.doc test ##查看test.ping函数的帮助salt 'minion' sys.doc test.ping salt常用命令salt 该命令执行salt的执行模块,通常在master端运行.常用命令 1234salt [option] '&lt;target&gt;' &lt;function&gt; [arguments]#例如salt 'minion-01' cmd.run 'ip addr' salt-run 该命令执行runner(salt自带或者自定义的，)，通常在master端执行，比如经常用到的manage 123456salt-run [options] [runner.func]#例如salt-run manage.status ##查看所有minion状态salt-run manage.down ##查看所有没在线minionsalt-run manged.up ##查看所有在线minion salt-key 密钥管理，通常在master端执行 123456salt-key [options]salt-key -L ##查看所有minion-keysalt-key -a &lt;key-name&gt; ##接受某个minion-keysalt-key -d &lt;key-name&gt; ##删除某个minion-keysalt-key -A ##接受所有的minion-keysalt-key -D ##删除所有的minion-key salt-call 该命令通常在minion上执行，minion自己执行可执行模块，不通过master下发job 123salt-call [options] &lt;function&gt; [arguments]salt-call test.ping ##自己执行test.ping命令salt-call cmd.run 'ifconfig' ##自己执行cmd.run函数 salt-cp 分发文件到minion上,不支持目录分发.运行在master 123456salt-cp [options] '&lt;target&gt;' SOURCE DEST#例如salt-cp '*' testfile.html /tmpsalt-cp 'test*' index.html /tmp/a.html#如果minion 是windows端 默认/ 指的是 C:\ /test = C:\test salt-master1234salt-master [options]salt-master ##前台运行mastersalt-master -d ##后台运行mastersalt-master -l debug ##前台debug输出 salt-minion1234salt-minion [options]salt-minion ##前台运行salt-minion -d ##后台运行salt-minion -l debug ##前台debug输出 普通用户执行salt两种方法 1: ACL(修改master) 1234567891011121314 client_acl: monitor: #uonghu - test*: #权限 - test.* dev: - service.* sa: - .*#重启master #给予目录和文件权限chmod +r /etc/salt/masterchmod +x /var/run/saltchmod +x /var/cache/salt 2 external_auth(修改master) 123456789 pam: fred: - test.*#重启master #给予目录和文件权限chmod +r /etc/salt/masterchmod +x /var/run/saltchmod +x /var/cache/salt 使用Token不必每次都输入账号密码，使用external_auth每次都是需要密码的，这样多麻烦，这里引入了Token，它会保存一串字符到在当前用户家目录下.salt_token中，在有效时间内使用external_auth是不需要输入密码的，默认时间12hour，可以通过master配置文件修改 1salt -T -a pam &apos;*&apos; test.ping target target也就是目标,目的.指定master命令应该对谁执行 正则匹配 12345[root@master /]# salt -E 'mini*' test.pingminion-02: Trueminion-01: True 列表匹配 12345[root@master ~]# salt -L minion-01,minion-02 test.pingminion-02: Trueminion-01: True grains匹配 12345[root@master ~]# salt -G 'os:CentOs' test.pingminion-02: Trueminion-01: True 组匹配 1234567891011121314#开启master 的default_includevim /etc/salt/master.d/nodegroup.conf #写到master中也是这个格式nodegroups: test1: 'L@test1,test2 or test3*' test2: 'G@os:CenOS or test2'salt -N test1 test.ping #-N指定groupname在top file中使用nodegroups'test1': - match: nodegroup ##没s,匹配的是文件 - webserver 123456[root@master ~]# salt -N nodegroups test.pingminion-02: Trueminion-01: True#组需要在master中预先定义 复合匹配 salt -C &#39;G@os:MacOS or L@Minion1&#39; Pillar匹配 salt -I &#39;key:value&#39; test.ping CIDR匹配 salt -S &#39;192.168.1.0/24&#39; test.ping 在top文件中匹配 grains 123'node_type:web': - match: grain #没有s - webserver top文件中使用jinja 123&#123;% set self = grains['node_type'] %&#125; - match: grain- &#123;&#123; self &#125;&#125; 一次在n个minion上执行 12345-b n--batch-size n#例：salt '*' -b 5 test.ping#5个5个的ping 多master 2个master并不会共享Minion keys，一个master删除了一个key不会影响另一个 不会自动同步File_roots,所以需要手动去维护，如果用git就没问题了 不会自动同步Pillar_Roots，所以需要手工去维护，也可以用git Master的配置文件也是独立的 123456789101112131415#安装 salt-master#原master的密钥cp一份到新的masterscp /etc/salt/pki/master/master* newmaster:/etc/salt/pki/master/#启动新的Master#修改配置minion的配置master: - master1 - master2#重启minion#新master接受所有的keysalt-key -Lsalt-key -A YAML 语法风格 空格和TAB yaml两个空格为缩进, TAB不要使用! 冒号: 和减号- : 和- 后面要跟上一个空格在写 数字解析 mode: 0644 会解析成为mode: 644 最好使用mode: (0644) 简写 12345678910vim: pkg.installed #第一个简写 user.present #第二个简写.不被支持,因为不支持双简写#建议规范书写vim: pkg: - installed user: - present Jinja Jinja 基于Python模板引擎开发,saltstack默认使用yaml_jinja渲染器,渲染流程时先jinja在yaml解析.所以在开始解析yaml的时候可以使用jinja”偷个腥” 区分模板文件 在salt中,files和templates都使用file这个state模块.那么如何区分模板是什么文件呢. 12345678 - templates: jinja file.managed: - name: /tmp/test - source: salt://tmp/test - template: jinja - defaults: Server: &#123;&#123; pillar['.....'] &#125;&#125; jinja中使用grains 1&#123;&#123; grains[&apos;os&apos;] &#125;&#125; jinja中使用执行模块 1&#123;&#123; salt[&apos;network.hw_addr&apos;](&apos;eth0&apos;) &#125;&#125; jinja中使用Pillar 1&#123;&#123; pillar[&apos;apache&apos;][&apos;PORT&apos;] &#125;&#125; Jinja的逻辑关系 12345&#123;% if grains[&apos;os&apos;] == &apos;RedHat&apos; %&#125;apache: httpd&#123;% elif grains[&apos;os&apos;] == &apos;Debian&apos; %&#125;apache: apache2&#123;% endif %&#125; 更多使用自行研究 salt常用模块和API查看支持的所有modules1234[root/] ]$salt 'minion-01' sys.list_modulesminion-01: - acl... salt.client调用API举例[root/] ]$cd /usr/lib/python2.7/site-packages/salt/modules/ 模块path API调用示例 123456789101112[root/] ]$cat test.py #!/usr/bin/pythonimport salt.clientclient = salt.client.LocalClient()res = client.cmd('*','test.ping')print res[root/] ]$./test.py &#123;'minion-02': True, 'minion-01': True&#125;##解释一下#当我们调用salt.client.LocalClient的时候,其实就等于我们执行了 salt '*' test.ping API调用： 1client.cmd(&apos;*&apos;,&apos;file.remove&apos;,[&apos;/tmp/foo&apos;]) salt sys.doc module 可以查看模块支持那些命令 Archive 实现对系统曾经的压缩包调用支持gzip,gunzip.rar,tar,unrar,unzip等 12345#采用gunzip解压sourcefile.txt.gz包salt '*' archive.gunzip sourcefile.txt.gz#采用gzip压缩sourcefile.txt文件salt '*' archive.gzip sourcefile.txt API调用： 1client.cmd(&apos;*&apos;,&apos;archive.gunzip&apos;,[&apos;sourcefile.txt.gz&apos;]) cmd 实现对远程命令的调用执行,(默认具备root权限!谨慎使用) 123456#获取所欲被控主机的内存使用情况salt '*' cmd.run 'free -m'#在wx主机上运行test.py脚本，其中script/test.py存放在file_roots指定的目录（默认是在/srv/salt,自定义在/etc/salt/master文件中定义），#该命令会做2个动作：首先同步test.py到minion的cache目录；起床运行该脚本salt 'minion-01' cmd.script salt://script/test.py API调用： 1client.cmd(&apos;*&apos;,&apos;cmd.run&apos;,[&apos;free -m&apos;]) cp 实现远程文件目录的复制,以及下载URL文件等操作 1234567891011#将被控主机的/etc/hosts文件复制到被控主机本地的salt cache目录（/var/cache/salt/minion/localfiles/）salt '*' cp.cache_local_file /etc/hosts#将主控端file_roots指定位置下的目录复制到被控主机/minion/目录下salt '*' cp.get_dir salt://script/ /minion/#将主控端file_roots指定位置下的文件复制到被控主机/minion/test.py文件(file为文件名)salt '*' cp.get_dir salt://script/test.py /minion/test.py#下载URL内容到被控主机指定位置(/tmp/index.html)salt '*' cp.get_url http://www.slashdot.ort /tmp/index.html API调用： 1client.cmd(&apos;*&apos;,&apos;cp.get_file&apos;,[&apos;salt://script/test.py&apos;,&apos;/minion/test.py&apos;]) cron 实现对minion的crontab控制 12345678#查看指定被控主机、root用户的crontab操作salt 'minion-01' cron.raw_cron root#为指定被控主机、root用户添加/usr/local/weekly任务zuoyesalt 'minion-01' cron.set_job root '*' '*' '*' '*' 1 /usr/local/weekly #删除指定被控主机、root用户crontab的/usr/local/weekly任务zuoyesalt 'minion-01' cron.rm_job root /usr/local/weekly API调用： 1client.cmd('wx','cron.set_job',['root','*','*','*','*',1,'/usr/local/weekly']) file 对minion的文件操作,包括文件读写,权限,查找校验 1234567891011121314151617181920212223242526272829303132333435#校验所有被控主机/etc/fstab文件的md5值是否为xxxxxxxxxxxxx,一致则返回True值salt '*' file.check_hash /etc/fstab md5=xxxxxxxxxxxxxxxxxxxxx#校验所有被控主机文件的加密信息，支持md5、sha1、sha224、shs256、sha384、sha512加密算法salt '*' file.get_sum /etc/passwd md5#修改所有被控主机/etc/passwd文件的属组、用户权限、等价于chown root:root /etc/passwdsalt '*' file.chown /etc/passwd root root#复制所有被控主机/path/to/src文件到本地的/path/to/dst文件salt '*' file.copy /path/to/src /path/to/dst#检查所有被控主机/etc目录是否存在，存在则返回True,检查文件是否存在使用file.file_exists方法salt '*' file.directory_exists /etc#获取所有被控主机/etc/passwd的stats信息salt '*' file.stats /etc/passwd#获取所有被控主机/etc/passwd的权限mode，如755，644salt '*' file.get_mode /etc/passwd#修改所有被控主机/etc/passwd的权限mode为0644salt '*' file.set_mode /etc/passwd 0644#在所有被控主机创建/opt/test目录salt '*' file.mkdir /opt/test#将所有被控主机/etc/httpd/httpd.conf文件的LogLevel参数的warn值修改为infosalt '*' file.sed /etc/httpd/httpd.conf 'LogLevel warn' 'LogLevel info'#给所有被控主机的/tmp/test/test.conf文件追加内容‘maxclient 100’salt '*' file.append /tmp/test/test.conf 'maxclient 100'#删除所有被控主机的/tmp/foo文件salt '*' file.remove /tmp/foo network 返回minion的主机信息 12345678910111213141516171819#在指定被控主机获取dig、ping、traceroute目录域名信息salt 'minion-01' network.dig www.qq.comsalt 'minion-01' network.ping www.qq.comsalt 'minion-01' network.traceroute www.qq.com#获取指定被控主机的mac地址salt 'minion-01' network.hwaddr eth0#检测指定被控主机是否属于10.0.0.0/16子网范围，属于则返回Truesalt 'minion-01' network.in_subnet 10.0.0.0/16#获取指定被控主机的网卡配置信息salt 'minion-01' network.interfaces#获取指定被控主机的IP地址配置信息salt 'minion-01' network.ip_addrs#获取指定被控主机的子网信息salt 'minion-01' network.subnets API调用： 1client.cmd('minion-01','network.ip_addrs') pkg minion的程序包管理,如yum, apt-get等 12345678#为所有被控主机安装PHP环境，根据不同系统发行版调用不同安装工具进行部署，如redhat平台的yum，等价于yum -y install phpsalt '*' pkg.install php#卸载所有被控主机的PHP环境salt '*' pkg.remove php#升级所有被控主机的软件包salt '*' pkg.upgrade API调用： 1client.cmd(&apos;*&apos;,&apos;pkg.remove&apos;,[&apos;php&apos;]) status1salt &apos;*&apos; status.version API 123import salt.clientclient = salt.client.LocalClient()client.cmd('*','status.uptime') system 用来日常操作计算机 12345system.halt #停止正在运行的系统system.init 3 #切换到字符界面，5是图形界面system.poweroffsystem.rebootsystem.shutdown systemd(service)1234567891011121314service.available sshd #查看服务是否可用service.disable &lt;service name&gt; #设置开机启动的服务service.enable &lt;service name&gt;service.disabled &lt;service name&gt; #查看服务是不是开机启动service.enabled &lt;service name&gt;service.get_disabled #返回所有关闭的服务service.get_enabled #返回所有开启的服务service.get_all #返回所有服务service.reload &lt;service name&gt; #重新载入指定的服务service.restart &lt;service name&gt; #重启服务service.start &lt;service name&gt;service.stop &lt;service name&gt;service.status &lt;service name&gt;service.force_reload &lt;service name&gt; #强制载入指定的服务 使用 1234[root@mail python]# salt '*' service.available sshdmonitor: Trueapi调用:&gt;&gt;&gt; client.cmd('*','service.available',['sshd'])&#123;'monitor': True&#125; grains 服务器的一些静态信息，强调的是静态，就是不会变的东西，比如说os是centos，不会变化，除非重新安装系统 grains的使用1234567891011121314151617181920212223242526272829303132333435363738394041#查询所有grains信息[root@master salt]# salt 'minion-01' grains.items minion-01: ---------- SSDs: biosreleasedate: 09/21/2015 biosversion: 6.00 cpu_flags: - fpu - vme - de.....#查询grains指定项[root@master salt]# salt '*' grains.item osminion-02: ---------- os: CentOSminion-01: ---------- os: CentOS[root@master salt]# [root@master salt]# salt -G 'os:CentOS' test.pingminion-01: True#对系统是CentOS的服务器进行ping测试操作#os:CentOS ; 就是对应上面grains.items显示出来的os值是CentOs的对象进行匹配 #对cpu架构是x86_64的服务器显示CPU的个数salt -G 'cpuarch:x86_64' grains.item num_cpus #对字典值的对象进行匹配salt -G 'ip_interfaces:eno16777728:192.168.2.*' test.ping 在SLS中用grains 1234# 在xxx.sls中使用grains'os:CentOS': - match: grain - webserver 自定义grains(两种方法)1 . minion端修改 重启生效 修改配置文件 /etc/salt/minion 或者写在/etc/salt/grains中 打开 default_include: minion.d/*.conf 或者直接添加此命令 在minion端的/etc/salt/minion.d/ 目录下新建并编辑.conf后缀文件 123456789101112131415grains: #如果是/etc/salt/grains中,不需此行 roles: - webserver sex: boy #名字：值 age: #名字：多个值 - 33 - 44 # 重启生效[root@master ~]# salt 'minion-01' grains.item ageminion-01: ---------- age: - 33 - 44[root@master ~]# 2 . minion端修改 同步之后生效 base目录（在/etc/salt/master中配置的file_roots项，默认在/srv/salt）下生成_grains 目录,新建文件,用python来写 编写文件,需要返回一个字典 123456789101112131415161718192021 vim test1.pydef hello(): ##函数名字无所谓，应该是所有函数都会运行 agrain = &#123;&#125; agrain['hello'] = 'lzl' return agrain ##返回这个字典========================#!/usr/bin/python# -*- coding:utf-8 -*-import osdef file(): grains=&#123;&#125;#初始化一个字典， file = os.popen('ulimit -n').read() grains['my_file']=file return grains#注意文件赋予权限chmod a+x .py 123456789#同步到各个minion中去salt '*' saltutil.sync_all#查看[root/srv/salt/_grains] ]$salt 'minion-01' grains.item hellominion-01: ---------- hello: lzl pillar Pillar在salt中是非常重要的组成部分，利用它可以完成很强大的功能，它可以指定一些信息到指定的minion上，不像grains一样是分发到所有Minion上的，它保存的数据可以是动态的,Pillar以sls来写的，格式是键值 适用 1.比较敏感的数据，比如密码，key等 2.特殊数据到特定Minion上 3.动态的内容 4.其他数据类型 pillar基本使用查看所有 1salt &apos;*&apos; pillar.items 查看某个 123salt '*' pillar.item KEY#可以取到更小粒度的salt '*' pillar.get &lt;key&gt;:&lt;key&gt; 编写pillar 指定pillar_roots 默认是/srv/pillar/(可通过修改master配置文件修改),建立目录 top.sls 123456789101112131415base: #指定环境 '*': #target - test1 #引用test1.sls 或者test1/init.sls #通过分组名匹配，base: group1: - match: nodegroup #必须要有 - match: nodegroup - webserver #通过grain模块匹配的示例base: 'os:CentOS': - match: grain #必须要有- match: grain - webserver test1.sls 12name: test1user: lzl 刷新 pillar数据 1salt &apos;*&apos; saltutil.refresh_pillar 查看结果 12345678[root/srv/pillar] ]$salt 'minion-01' pillar.itemsminion-01: ---------- name: test1 user: lzl[root/srv/pillar] ]$ 在state中通过jinja使用pillar默认state文件位置/src/salt/ 12345678user.sls&#123;% for user, uid in pillar.get('users', &#123;&#125;).items() %&#125; ##pillar.get('users',&#123;&#125;)可用pillar['users']代替，前者在没有得到值的情况下，赋默认值&#123;&#123;user&#125;&#125;: user.present: - uid: &#123;&#123;uid&#125;&#125;&#123;% endfor %&#125; jinja配合grains 指定pillar数据123456789&#123;% if grains['os_family'] == 'RedHat' %&#125;apache: httpd&#123;% elif grains['os'] == 'CentOS' %&#125;apache: httpdvim: vim&#123;% elif grains['os'] == 'Arch' %&#125;apache: apachevim: vim&#123;% endif %&#125; 使用salt state 它的核心是写sls(SaLt State file)文件,sls文件默认格式是YAML格式，并默认使用jinja模板，jinja是根据django的模板语言发展而来的语言，简单并强大，支持for if 等循环判断。salt state主要用来描述系统，软性，服务，配置文件的状态，常常被称为配置管理！ 通常state，pillar,top file会用sls文件来编写。state文件默认是放在/srv/salt中，它与你的master配置文件中的file_roots设置有关 简单的state文件配置&amp;介绍12345678910111213141516171819202122232425262728293031323334#/srv/salt/apahce.slsapache: ##state ID，全文件唯一,如果模块没跟-name默认用的ID作为-name pkg: ##模块 #- name: apache ##函数参数，可以省略 - installed ##函数 service: ##模块 - running ##函数 #- name: apache ##函数参数，这个是省略的，也可以写上 - require: ##依赖系统 - pkg: apache ##表示依赖id为apache的pkg状态 #声明一个叫apache的状态id,该id可以随意，最好能表示一定意思#pkg代表的是pkg模块#installed是pkg模块下的一个函数，描述的是状态，该函数表示apache是否部署，返回值为True或者False，为真时，表示状态OK，否则会去满足该状态(下载安装apache)，如果满足不了会提示error,在该模块上面省略了参数-name: apache,因为ID为apache,这些参数是模块函数需要的（可以去查看源码）#service是指的service模块#这个模块下主要是描述service状态的函数，running状态函数表示apache在运行，省略-name不在表述，-require表示依赖系统，依赖系统是state system的重要组成部分，在该处描述了apache服务的运行需要依赖apache软件的部署，这里就要牵涉到sls文件的执行，sls文件在salt中执行时无序(如果没有指定顺序，后面会讲到order)，假如先执行了service这个状态，它发现依赖pkg包的安装，会去先验证pkg的状态有没有满足，如果没有依赖关系的话，我们可以想象，如果没有安装apache，apache 的service肯定运行会失败的，我们来看看怎么执行这个sls文件: salt '*' state.sls apache #在命令行里这样执行，.sls不写，如果在目录下，将目录与文件用’.’隔开，#如： httpd/apache.sls –&gt; httpd.apache#或者salt '*' state.highstate #前提是存在top.sls 去指定minion运行的是哪个文件#top.slsbase: '*': - webserver state.sls默认的运行环境是base环境，但是它并不读取top.sls（top.sls定义了运行环境以及需要运行的sls） state.sls也可以指定读取哪个环境：state.sls salt_env=’prod’ xxxx.sls，这个xxxx.sls可以不在top.sls中记录。 state.highstate: 这个是全局的所有环境，以及所有状态都生效。它会读取每一个环境的top.sls，并且对所有sls都生效。不在top.sls文件里面记录的sls则不会被执行； 阅读后写的版本 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657webserver: pkg: - name: httpd - installed service: - name: httpd - running - reqire: -pkg: httpd[root/srv/salt] ]$salt 'minion-02' state.sls webserverminion-02:---------- ID: webserver Function: pkg.installed Name: httpd Result: True Comment: The following packages were installed/updated: httpd Started: 18:24:07.033564 Duration: 65091.443 ms Changes: ---------- httpd: ---------- new: 2.4.6-45.el7.centos old: httpd-tools: ---------- new: 2.4.6-45.el7.centos old: mailcap: ---------- new: 2.1.41-2.el7 old:---------- ID: webserver Function: service.running Name: httpd Result: True Comment: Started Service httpd Started: 18:25:12.142495 Duration: 5599.171 ms Changes: ---------- httpd: TrueSummary------------Succeeded: 2 (changed=2)Failed: 0------------Total states run: 2[root/srv/salt] ]$ 较复杂的state/srv/salt/ssh/init.sls 1234567891011121314151617openssh-client: pkg.installed/etc/ssh/ssh_config: file.managed: - user: root - group: root - mode: 644 - source: salt://ssh/ssh_config - require: - pkg: openssh-client#ssh/init.sls 意思是当执行 salt '*' state.sls ssh的时候其实就是执行init.sls#第一行:文件名,全文件唯一,如果pkg等模块没跟- name 包名, 默认用的ID作为-name#第二行: 简写,意思pkg下的installed函数#第三行: ID 告诉minion下载的文件应该放哪里!#第四行:简写#第八行:source是告诉minion从哪里下载源文件!#salt://ssh/ssh_config其实就是/srv/salt/ssh/ssh_config 前面/srv/salt这个路径和file_roots的配置有关 /srv/salt/ssh/server.sls 1234567891011121314151617181920212223242526272829303132include: - ssh#include表示包含意思，就是把ssh/init.sls直接包含进来openssh-server: pkg.installedsshd: service.running: - require: - pkg: openssh-client - pkg: openssh-server - file: /etc/ssh/banner - file: /etc/ssh/sshd_config/etc/ssh/sshd_config: file.managed: - user: root - group: root - mode: 644 - source: salt://ssh/sshd_config - require: - pkg: openssh-server/etc/ssh/banner: file: - managed - user: root - group: root - mode: 644 - source: salt://ssh/banner - require: - pkg: openssh-server 此时的目录结构应该是 123456├── ssh│ ├── banner│ ├── init.sls│ ├── server.sls│ ├── ssh_config│ └── sshd_config 关于include古官网的demo 1234567891011121314151617include: - ssh.serverextend: /etc/ssh/banner: file: - source: salt://ssh/custom-banner #包含ssh/server.sls,扩展/etc/ssh/banner，重新其source而其它的如user,group等不变，与include一致。include: - apacheextend: apache: service: - watch: - pkg: mod_python#把apache.sls包含进来，想apache-service是追加了依赖关系(watch也是依赖系统的函数). 关于渲染器 render system salt默认是用的yaml_jinja渲染器处理ss文件,会优先使用jinjia处理,然后传给yaml处理然后生成salt需要的python数据类型. apache/init.sls 12345678910111213apache: pkg:installed: &#123;% if grains['os'] == 'CentoOS' %&#125; - name: httpd &#123;% endif %&#125; service.running: &#123;% if grains['os'] == 'CentoOS' %&#125; - name: httpd &#123;% endif %&#125; - watch: - pkg: apache #简单的例子,使用jinja结合grains进行判断 user/init.sls 12345678910111213141516171819202122232425&#123;% set users = ['jerry','tom','gaga'] %&#125;&#123;% for user in users %&#125;&#123;&#123; user &#125;&#125;: user.present: - shell: /bin/bash - home: /home/&#123;&#123; user &#125;&#125;&#123;% endfor %&#125;---------------------------&#123;% if salt['cmd.run']('uname -i') == 'x86_64' %&#125;hadoop: user.present: - shell: /bin/bash - home: /home/hadoop&#123;% elif salt['cmd.run']('uname -i') == 'i386' %&#125;openstack: user.present: - shell: /bin/bash- home: /home/openstack&#123;% else %&#125;django: user.present: - shell: /sbin/nologin&#123;% endif %&#125; py渲染器 纯python写的sls文件.如果使用其他的渲染器,需要在文件开头声明,!py就是声明用的py渲染器, py中可用的变量有salt,grains,pillar,opts,env,sls,前三个分别对应jinja里的salt,grains,pillar,opts是minion的配置文件的字典，env对应的是环境如base,sls对应的是sls的文件名 12345678910111213#!pyimport osdef run(): '''add user hadoop'''platform = os.popen('uname -a').read().strip()if platform == 'x86_64': return &#123;'hadoop': &#123;'user': ['present',&#123;'shell': '/bin/bash'&#125;, &#123;'home': '/home/hadoop'&#125;]&#125;&#125;elif platform == 'i386': return &#123;'openstack': &#123;'user': ['present', &#123;'shell': '/bin/bash'&#125;, &#123;'home': '/home/openstack'&#125;]&#125;&#125;else: return &#123;'django': &#123;'user': ['present', &#123;'shell': '/sbin/nologin'&#125;]&#125;&#125;#注意的是return的数据结构&#123;ID: &#123;module: [func, arg1,arg2,...,]&#125;&#125; 或 &#123;ID: &#123;module.func: [arg1,arg2,..,]&#125;&#125; 。表示的内容与“示例；salt字典”表达的相同 state的执行顺序 stata执行,也就是.sls文件的执行是无序的.为了保证每次的顺序是一致的,就加入了state order , 先了解下高级数据(High Data)和低级数据(Low Data). 高级数据就是指编写的sls文件的数据 低级数据就是经过render和parser编译过的数据 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374[root~] ]$salt 'minion-01' state.show_highstateminion-01: ---------- webserver: ---------- __env__: base __sls__: webserver pkg: |_ ---------- name: httpd - installed |_ ---------- order: 10000 service: |_ ---------- name: httpd - running |_ ---------- -pkg: httpd reqire: None |_ ---------- order: 10001[root~] ]$salt 'minion-01' state.show_lowstateminion-01: |_ ---------- __env__: base __id__: webserver __sls__: webserver fun: installed name: httpd order: 10000 state: pkg |_ ---------- -pkg: httpd __env__: base __id__: webserver __sls__: webserver fun: running name: httpd order: 10001 reqire: None state: service[root~] ]$ 查看可知,里面有个order,这个是默认salt 会自动设置,从10000开始.可通过修改master state_auto_order: False来关闭 order的设定 include 被include的文件Order靠前,先执行 手动定义order 12345httpd: pkg: - installed - order: 1#order的值越小,优先级越高.但是-1 是最后! 依赖关系系统 就是前面使用过的 - require 依赖关系系统 requisite system 我们已经使用过依赖关系系统了,就是定义状态和状态之间的依赖关系,常用的函数有 require和watch 以及他们的变种require_in和watch-in 四者有何区别? require,watch是指依赖，require_in,watch_in是指被依赖 watch 常用于service,而且当依赖条件发生变化的时候会执行一些动作 123456789101112131415161718192021222324252627/etc/httpd/httpd.conf: file: - managed - source: salt://httpd/httpd.conf pkg.installed service: - running - require: - pkg: httpd - watch: - file://etc/httpd/httpd.conf #当httpd.conf改变时，重启httpd服务 ============================ /etc/httpd/httpd.conf: file: - managed - source: salt://httpd/httpd.conf - watch_in: - service: httpd httpd: pkg: - installed - require_in: - service: httpd service: - running salt state多环境 针对不同的环境,应用不同state的file,比如开发,测试,生产等. 通过修改master对不同的环境应用不通过的目录 123456789101112131415161718192021#官方demoExample: file_roots: base: - /srv/salt/ dev: - /srv/salt/dev/services - /srv/salt/dev/states prod: - /srv/salt/prod/services - /srv/salt/prod/states#file_roots 配置salt配置的存放目录, 其中base环境是必要的, 指定top.sls存放的位置.#默认没指定环境时则从base目录获取文件#其它则是一些自定义的, 可以通过环境变量指定.#这样可以逻辑上隔离一些环境配置.#每一个环境都可以定义多个目录, 优先级关系由定义目录的顺序决定.file_roots: base: - /srv/salt/foo - /srv/salt/bar#如果寻找 salt://file.sls, 如果都存在/srv/salt/foo/file.sls和/srv/salt/bar/file.sls, 则使用第一个找到的. 另一个例子 1234567891011file_roots: base: - /srv/salt/prod qa: - /srv/salt/qa - /srv/salt/prod dev: - /srv/salt/dev - /srv/salt/qa - /srv/salt/prod#/srv/salt/prod 里的配置是在三种环境下都可以, /srv/salt/qa 只在qa和dev环境下可用, /srv/salt/dev则只在dev环境下可用. 简答你的实施案例 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#master配置file_roots: base: - /home/base/ dev: - /home/dev/ - /home/base/ #base环境 #/home/base├── envtest.sls└── top.sls#cat /home/base/envtest.slsenvtest: cmd.run: - name: "echo '[base] env'" #dev环境#/home/dev/├── mytest.sls└── top.sls#cat /home/dev/mytest.slsenvtest: cmd.run: - name: "echo '[dev] env'"##执行效果如下,如果不添加环境变量,则提示找不到文件[root/srv/salt/dev] ]$salt 'minion-01' state.sls mytest test=Trueminion-01: Data failed to compile:---------- No matching sls found for 'mytest' in env 'base'ERROR: Minions returned with non-zero exit code#加上环境变量执行[root/srv/salt/dev] ]$salt 'minion-01' state.sls mytest saltenv='dev' test=Trueminion-01:---------- ID: mytest Function: cmd.run Name: echo dev-env Result: None Comment: Command "echo dev-env" would have been executed Started: 23:54:46.298421 Duration: 0.422 ms Changes: Summary------------Succeeded: 1 (unchanged=1)Failed: 0------------Total states run: 1[root/srv/salt/dev] ]$ salt schedule(salt中的crontab) 周期性的执行一些函数,需要注意的是: 在minion上执行salt可执行模块里的函数,在master执行的是runner模块的函数. 共有三种方式:master minion pillar master端 minion端 pillar 一般而言,尤其是在minion端配置,基本不会用到的,主要还是一pillar为主 修改top.sls 12#添加 - schedule /srv/pillar/schedule.sls 12345678schedule: test-job: function: cmd.run seconds: 10 args: - 'date &gt;&gt; /date.log' #没隔10S 在/目录的date.log文件中记录一条时间 1234567891011salt "*" saltutil.refresh_pillar#刷新pillar到minion#回到minion 可以查看到[root@minion-01 /]# lsbin boot date.log dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var[root@minion-01 /]# cat date.log Fri Mar 24 02:27:40 CST 2017Fri Mar 24 02:27:50 CST 2017Fri Mar 24 02:28:00 CST 2017.... salt ssh salt-ssh 是 0.17.0 新出现的一个功能.对于有些不能安装minion的机器,ssh不失为一种好的选择但是SSH并不能取代minion,salt的有些功能不支持ssh.而且走的是SSH 并不是ZeroMQ,所以速度会有所影响 12#首先安装salt-ssh.yum -y install salt-ssh 12345678910111213[root~] ]$cat /etc/salt/roster #roster文件名和路径!minion-01: host: 192.168.247.153 user: root passwd: centosminion-02: host: 192.168.247.154 user: root passwd: centos sudo: True#如果不给passwd的话,执行salt-ssh会提示输入密码#普通用户给sudo权限 123456789101112131415161718192021#第一次使用记得加参数 -i 否则报错如下[root~] ]$salt-ssh 'minion-01' test.pingminion-01: ---------- retcode: 254 stderr: stdout: The host key needs to be accepted, to auto accept run salt-ssh with the -i flag: The authenticity of host '192.168.247.153 (192.168.247.153)' can't be established. ECDSA key fingerprint is 16:f6:f5:49:24:9c:91:da:d7:02:58:a2:14:08:e4:15. Are you sure you want to continue connecting (yes/no)? #第一次运行 添加-i参数[root~] ]$salt-ssh 'minion-01' test.ping -iminion-01: True[root~] ]$salt-ssh 'minion-01' test.pingminion-01: True[root~] ]$ Returners略 扩展salt略]]></content>
      <categories>
        <category>运维工具</category>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>saltstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux文件共享]]></title>
    <url>%2F2017%2F03%2F25%2Flinux%E6%96%87%E4%BB%B6%E5%85%B1%E4%BA%AB%2F</url>
    <content type="text"><![CDATA[文章包括NFS和samba NFS安装相关服务1yum install nfs-utils rpcbind 创建共享文件夹12mkdir -p /nfs_share/share-onemkdir -p /nfs_share/share-two 编辑配置文件vi /etc/exports12345# 所有的IP都可访问/nfs_share/share-one *(rw,async,no_root_squash)# 某网段/IP可访问/nfs_share/share-two 192.168.1.0/24(rw,async,no_root_squash) 然后输入exportfs -r重新共享所有目录 配置文件还是要解释下:rw:read-write，可读写ro:read-only，只读sync:文件同时写入硬盘和内存async:文件暂存于内存，而不是直接写入内存no_root_squash:NFS客户端连接服务端时如果使用的是root的话，那么对服务端分享的目录来说，也拥有root权限。显然开启这项是不安全的root_squash:NFS客户端连接服务端时如果使用的是root的话，那么对服务端分享的目录来说，权限降低至拥有匿名用户权限，通常他将使用nobody或nfsnobody身份all_squash:不论NFS客户端连接服务端时使用什么用户，对服务端分享的目录来说都是匿名用户权限； 启动服务1234service rpcbind start #这个先启动service nfs startchkconfig rpcbind onchkconfig nfs on 客户端挂载同服务器,安装服务创建挂载目录并开启服务,然后1234567#查看共享目录showmount -e server_ip#挂载mount -t nfs 192.168.1.123:/nfs_share/share-two /mnt#如果网络不稳,换成tcp协议挂载,默认使用udpmount -t nfs 192.168.1.123:/nfs_share/share-two /mnt -o proto=tcp -o nolock 开机自动挂载123vi /etc/fstabserver_ip:/nfs_share/share-two /mnt nfs default 0 0 samba安装服务yum -y install samba samba-client samba-common 配置文件vim /etc/samba/smb.conf12345678[smbshare] #命名comment = samba share #注释path = /smbshare #路径read list = harry #可读用户#这里也可以用组来表示 read list = @samba_group#writeable=yes#write list = harry #可写用户,可写默认有可读权限.hosts allow = 172.24.1. #ip限制,注意点. 添加用户添加组: groupadd samba_group先添加系统用户useradd harry -s /sbin/nologin -g samba_group添加samba用户smbpasswd -a harry 然后输入密码即可 文件夹&amp;权限1234mkdir /smbsharesetfacl -m u:harry:rwx /smbshare #setfacl -m g:samba_group:rwx /smbshare #根据组修改文件acl#getfacl filename #查看文件夹的权限 开启服务1234systemctl restart smbsystemctl restart nmbsystemctl enable smbsystemctl enable nmb 客户端挂载安装服务yum -y install cifs-utilsvim /etc/fstab1//192.168.1.(smb服务地址)/multishare /mnt/multishare cifs sec=ntlmssp,user=harry,password=harry,multiuser 0 0 mount –adf -h]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>nfs</tag>
        <tag>samba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git显示分支]]></title>
    <url>%2F2017%2F03%2F22%2Fgit%E6%98%BE%E7%A4%BA%E5%88%86%E6%94%AF%2F</url>
    <content type="text"><![CDATA[前言git仓库显示当前分支结构,以及路径. vi ~/.bashrc 记得soure(来源于网络) 12345678910111213141516171819202122232425function git_branch &#123; ref=$(git symbolic-ref HEAD 2&gt; /dev/null) || return; echo &quot;(&quot;$&#123;ref#refs/heads/&#125;&quot;) &quot;;&#125;function parse_git_dirty &#123; local git_status=$(git status 2&gt; /dev/null | tail -n1) || $(git status 2&gt; /dev/null | head -n 2 | tail -n1); if [[ &quot;$git_status&quot; != &quot;&quot; ]]; then local git_now; # 标示 if [[ &quot;$git_status&quot; =~ nothing\ to\ commit || &quot;$git_status&quot; =~ Your\ branch\ is\ up\-to\-date\ with ]]; then git_now=&quot;=&quot;; elif [[ &quot;$git_status&quot; =~ Changes\ not\ staged || &quot;$git_status&quot; =~ no\ changes\ added ]]; then git_now=&apos;~&apos;; elif [[ &quot;$git_status&quot; =~ Changes\ to\ be\ committed ]]; then #Changes to be committed git_now=&apos;*&apos;; elif [[ &quot;$git_status&quot; =~ Untracked\ files ]]; then git_now=&quot;+&quot;; elif [[ &quot;$git_status&quot; =~ Your\ branch\ is\ ahead ]]; then git_now=&quot;#&quot;; fi echo &quot;$&#123;git_now&#125;&quot;; fi&#125;PS1=&quot;[\[\e[1;35m\]\u\[\e[1;32m\]@hostname:\w\[\e[0m\]] \[\e[0m\]\[\e[1;36m\]\$(git_branch)\[\033[0;31m\]\$(parse_git_dirty)\[\033[0m\]]\$&quot;]]></content>
      <categories>
        <category>运维工具</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django基础]]></title>
    <url>%2F2017%2F03%2F19%2Fdjango%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[前言感谢自强学堂 Django简介 urls.py 网址入口，关联到对应的view.py中的一个函数（或者generic类），访问网址就对应一个函数 view.py 处理用户发出的请求，从urls.py中对应过来，通过选人templates中的网页，可将内容显示，比如，登陆后的用户名，用户请求的数据，输出到网页 models.py 与数据库关联，存入或读取数据的时候会用到这个 forms.py 表单，用户在浏览器上输入数据提交，对数据的验证工作以及输入框的生成等工作 templates文件夹 views.py 中的函数渲染templates中的Html模板，得到动态内容的网页，当然可以用缓存来提高速度。 admin.py 后台，可以用很少的代码量，拥有一个强大的后台 settings.py Django 的设置，配置文件，比如Debug开关，静态文件位置等 Django环境搭建 Django 1.5.x 支持 Python 2.6.5 Python 2.7, Python 3.2 和 3.3. Django 1.6.x 支持 Python 2.6.X, 2.7.X, 3.2.X 和 3.3.X Django 1.7.x 支持 Python 2.7, 3.2, 3.3, 和 3.4 （注意：Python 2.6 不支持了） Django 1.8.x 支持 Python 2.7, 3.2, 3.3, 3.4 和 3.5. （长期支持版本 LTS) Django 1.9.x 支持 Python 2.7, 3.4 和 3.5. 不支持 3.3 了 Django 1.10.x 支持 Python 2.7, 3.4 和 3.5. Django 1.11.x 下一个长期支持版本，将于2017年4月发布 更详细的可以参考这里一般来说，选择长期支持版本比较好。 使用最新版本的问题就是，可能要用到的一些第三方插件没有及时更新，无法正常使用这些三方包。 如果是学习，可以选择目前的 Django 1.8.x 来进行，遇到问题也容易找到答案。 当然如果需要新版本的功能也可以使用新版本，毕竟 Django 1.9 以后admin界面还是更漂亮些 安装Django安装pip ubuntu sudo apt-get install python-pip centos yum -y install python-pip 升级pip pip install --upgrade pip 利用pip安装Django 12（sudo) pip install Django或者 (sudo) pip install Django==1.8.16 或者 pip install Django==1.10.3 搭建多个互不干扰的开发环境12# 安装:(sudo) pip install virtualenv 12345678910111213mkdir myprojectcd myprojectvirtualenv --no-site-packages test#命令virtualenv就可以创建一个独立的Python运行环境，我们还加上了参数--no-site-packages，这样，已经安装到系统Python环境中的所有第三方包都不会复制过来，这样，我们就得到了一个不带任何第三方包的“干净”的Python运行环境。source test/bin/activate#命令行提示符的最前方，会提示当前所在的python环境#然后就可以在此环境下 进行开发/测试等deactivate #退出环境 ####Django的基本命令（请牢牢记住，不能tab） 新建一个django project1django-admin.py startproject zixue 新建app1234python manage.py startapp app-name或 django-admin.py startapp app-name#一般一个项目有多个app, 当然通用的app也可以在多个项目中使用。 同步数据库123456789python manage.py syncdb #注意：Django 1.7.1及以上的版本需要用以下命令python manage.py makemigrationspython manage.py migrate#这种方法可以创建表，当你在models.py中新增了类时，运行它就可以自动在数据库中创建表了，不用手动创建。#备注：对已有的 models 进行修改，Django 1.7之前的版本的Django都是无法自动更改表结构的，不过有第三方工具 south, 使用开发服务器开发服务器，即开发时使用，一般修改代码后会自动重启，方便调试和开发，但是由于性能问题，建议只用来测试，不要用在生产环境。 1234567891011python manage.py runserver # 当提示端口被占用的时候，可以用其它端口：python manage.py runserver 8001python manage.py runserver 9999（当然也可以kill掉占用端口的进程） # 监听所有可用 ip （电脑可能有一个或多个内网ip，一个或多个外网ip，即有多个ip地址）python manage.py runserver 0.0.0.0:8000# 如果是外网或者局域网电脑上可以用其它电脑查看开发服务器# 访问对应的 ip加端口，比如 http://172.16.20.2:8000 清空数据库1python manage.py flush 创建超级管理员123456python manage.py createsuperuser # 按照提示输入用户名和对应的密码就好了邮箱可以留空，用户名和密码必填 # 修改 用户密码可以用：python manage.py changepassword username 导入导出数据 12python manage.py dumpdata appname &gt; appname.jsonpython manage.py loaddata appname.json Django羡慕的环境终端1python manage.py shell 数据库命令行1234python manage.py dbshellDjango 会自动进入在settings.py中设置的数据库，如果是 MySQL 或 postgreSQL,会要求输入数据库用户密码。在这个终端可以执行数据库的SQL语句。如果您对SQL比较熟悉，可能喜欢这种方式。 更多命令1终端上输入 python manage.py 可以看到详细的列表，在忘记子名称的时候特别有用。 Django的视图与网址创建项目1django-admin.py startproject mysite 创建成功后，目录如下 123456789101112mysite├── manage.py└── mysite ├── __init__.py ├── settings.py ├── urls.py └── wsgi.py #新建了一个 mysite 目录，其中还有一个 mysite 目录#这个子目录 mysite 中是一些项目的设置settings.py 文件#总的urls配置文件 urls.py 以及部署服务器时用到的 wsgi.py 文件# __init__.py 是python包的目录结构必须的，与调用有关。 新建应用（app） 名字叫learn1python manage.py startapp learn #learn只是一个app的名称 把我们新定义的app加到settings.py中的INSTALL_APPS 12345678910111213141516mysite/mysite/settings.pyINSTALLED_APPS = ( 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'learn',)#备注,这一步是干什么呢? 新建的 app 如果不加到 INSTALL_APPS 中的话,#django 就不能自动找到app中的模板文件(app-name/templates/下的文件)#和静态文件(app-name/static/中的文件) , 后面你会学习到它们分别用来干什么. 定义视图函数 （访问页面的内容）修改 应用 learn 中的view.py 1234567891011121314#coding:utf-8from django.http import HttpResponsedef index(request): return HttpResponse(u'欢迎') #第一行是声明编码为utf-8, 因为我们在代码中用到了中文,如果不声明就报错.#第二行引入HttpResponse，它是用来向网页返回内容的，#就像Python中的 print 一样，只不过 HttpResponse 是把内容显示到网页上。#我们定义了一个index()函数，第一个参数必须是 request，与网页发来的请求有关，request#变量里面包含get或post的内容，用户浏览器，系统等信息#在里面（后面会讲，先了解一下就可以）。#函数返回了一个 HttpResponse 对象，可以经过一些处理，最终显示几个字到网页上。#那问题来了，我们访问什么网址才能看到刚才写的这个函数呢？怎么让网址和函数关联起来呢？ 定义视图函数相关的URL打开mysite下的urls.py 123456789101112#Django 1.7from django.conf.urls import patterns, include, urlfrom django.contrib import adminadmin.autodiscover() urlpatterns = patterns('', url(r'^$', 'learn.views.index'), # new # url(r'^blog/', include('blog.urls')), url(r'^admin/', include(admin.site.urls)),) 1234567891011#Django1.8 以上from django.conf.urls import urlfrom django.contrib import adminfrom learn import views as learn_views # new urlpatterns = [ url(r'^$', learn_views.index), # new url(r'^admin/', admin.site.urls),] 1234#开启python测试python manage.py runserver#允许远程访问python manager.py runserver 0.0.0.0:8000 （指定IP和端口) 视图与网址进阶新建项目新建应用同上 修改应用下的views.py12345678910from django.shortcuts import renderfrom django.http import HttpResponse def add(request): a = request.GET['a'] b = request.GET['b'] c = int(a)+int(b) return HttpResponse(str(c)) #注：request.GET 类似于一个字典，更好的办法是用 request.GET.get('a', 0) 当没有传递 a 的时候默认 a 为 0 修改项目下的urls.py1234567891011from django.conf.urls import urlfrom django.contrib import adminfrom learn import views as learn_viewsfrom calc import views as calc_viewsurlpatterns = [ url(r'^add/$',calc_views.add,name='add'), url(r'^$',learn_views.index), url(r'^admin/', admin.site.urls),] 打开网址IP:8000/add/?a=1&amp;b=2 采用add/2/4的方式进入cala/views.py 定义函数 123def add2(request,a,b): c = int(a) + int(b) return HttpResponse(str(c)) 修改项目下的urls.py Django 1.7.X 1url(r'^add/(\d+)/(\d+)/$', 'calc.views.add2', name='add2'), Django 1.8+ 1234 url(r&apos;^add/(\d+)/(\d+)/$&apos;, calc_views.add2, name=&apos;add2&apos;), #我们可以看到网址中多了 (\d+), 正则表达式中 \d 代表一个数字，+ 代表一个或多个前面的字符，写在一起 \d+ 就是一个或多个数字，用括号括起来的意思是保存为一个子组（更多知识请参见 Python 正则表达式），每一个子组将作为一个参数，被 views.py 中的对应视图函数接收。访问 http://127.0.0.1:8000/add/4/5/ 就可以看到和刚才同样的效果 URL name详解url(r&#39;^add/$&#39;, calc_views.add,name=&#39;add&#39;), 这里的name=&#39;add&#39; 是用来干什么的呢？ 简单的来说，name可以在template,models，views中得到对应的网址，相当于给网址去了名字，只要名字不变，网址变不变都是可以获取到的 修改calc/views.py (应用calc已经在setting.py中INSTALLED_APPS导入,不然模板是找不到的) 12345678from django.http import HttpResponsefrom django.shortcuts import render def index(request): return render(request, 'home.html')...#render 是渲染模板 然后新建templates文件夹,在新建home.html 123456789&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;自强学堂&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;a href="/add/4/5/"&gt;计算 4+5&lt;/a&gt;&lt;/body&gt;&lt;/html&gt; 修改项目中的urls.py 12345678910...from learn import views as learn_viewsfrom calc import views as calc_viewsurlpatterns = [ url(r'^$',calc_views.index,name='home'), url(r'^add/$',calc_views.add,name='add'), url(r'^add/(\d+)/(\d+)/$',calc_views.add2,name='add2'), url(r'^admin/', admin.site.urls),] 然后运行服务,访问页面就会出现 计算4+5 的链接 12345&lt;a href=&quot;/add/4/5/&quot;&gt;计算 4+5&lt;/a&gt;如果这样写“死网址”，会使得在改了网址（正则）后，模板（template)，视图(views.py，用以用于跳转)，模型(models.py，可以用用于获取对象对应的地址）用了此网址的，都得进行相应的更改，修改的代价很大，一不小心，有的地方没改过来，就不能用了。那么有没有更优雅的方式来解决这个问题呢？ 1234567不带参数的：&#123;% url &apos;name&apos; %&#125;带参数的：参数可以是变量名&#123;% url &apos;name&apos; 参数 %&#125; 例如：&lt;a href=&quot;&#123;% url &apos;add2&apos; 4 5 %&#125;&quot;&gt;link&lt;/a&gt; 当 urls.py 进行更改，前提是不改 name（这个参数设定好后不要轻易改），获取的网址也会动态地跟着变，比如改成： 123url(r'^new_add/(\d+)/(\d+)/$', calc_views.add2, name='add2')#add 变成了 new_add，但是后面的 name='add2' 没改，这时 &#123;% url 'add2' 4 5 %&#125; 就会渲染对应的网址成 /new_add/4/5/ 另外，比如用户收藏夹中收藏的URL是旧的，如何让以前的 /add/3/4/自动跳转到现在新的网址呢？ 要知道Django不会帮你做这个，这个需要自己来写一个跳转方法： 具体思路是，在 views.py 写一个跳转的函数： 12345678from django.http import HttpResponseRedirectfrom django.core.urlresolvers import reverse # django 1.4.x - django 1.10.x# from django.urls import reverse # new in django 1.10.x def old_add2_redirect(request, a, b): return HttpResponseRedirect( reverse('add2', args=(a, b)) ) urls.py中 12url(r'^add/(\d+)/(\d+)/$', calc_views.old_add2_redirect),url(r'^new_add/(\d+)/(\d+)/$', calc_views.add2, name='add2'), 这样，假如用户收藏夹中有 /add/4/5/ ，访问时就会自动跳转到新的 /new_add/4/5/ 了 templates创建一个项目和app 123django-admin.py startproject zqxt_tmplcd zqxt_tmplpython manage.py startapp learn 把 learn 加入到 settings.INSTALLED_APPS中 12345678910INSTALLED_APPS = ( 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'learn',) 打开 learn/views.py 写一个首页的视图 1234from django.shortcuts import render def home(request): return render(request, 'home.html') 创建templates/home.html 然后将输入和网址对应 123456789101112from django.conf.urls import include, urlfrom django.contrib import adminfrom learn import views as learn_views urlpatterns = [ url(r'^$', learn_views.home, name='home'), url(r'^admin/', include(admin.site.urls)),]#Django1.10+#url(r'^admin/', admin.site.urls), #include 项目中有多个应用,所以就会有多个templates以及多个index.html默认情况下Django是不会去区分的,最先找到那个就显示那个,所以如果为了区分的话 就在各个应用的templates下进行在划分 12345678910111213project├── app1|....│ ├── templates│ │ └── app1│ │ ├── index.html│ │ └── search.html├── app2|.....│ ├── templates│ │ └── app2│ │ ├── index.html│ │ └── poll.html 模版补充知识点网站模板的设计，一般的，我们做网站有一些通用的部分，比如导航，底部，访问统计代码等等 可以写一个 base.html 来包含这些通用文件（include) 1234567891011121314151617181920212223242526&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;&#123;% block title %&#125;默认标题&#123;% endblock %&#125; - test&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &#123;% include 'nav.html' %&#125; &#123;% block content %&#125;&lt;div&gt;这里是默认内容，所有继承自这个模板的，如果不覆盖就显示这里的默认内容。&lt;/div&gt;&#123;% endblock %&#125; &#123;% include 'bottom.html' %&#125; &#123;% include 'tongji.html' %&#125; &lt;/body&gt;&lt;/html&gt;#如果需要，写足够多的 block 以便继承的模板可以重写该部分#include 是包含其它文件的内容，就是把一些网页共用的部分拿出来，重复利用#改动的时候也方便一些，还可以把广告代码放在一个单独的html中，改动也方便一些，#在用到的地方include进去。其它的页面继承自 base.html 就好了，#继承后的模板也可以在 block 块中 include 其它的模板文件。 templatesde 进阶 主要讲解模板中的循环，条件判断，常用的标签，过滤器的使用 基本字节的显示views.py 12345678# -*- coding: utf-8 -*-from django.shortcuts import render def home(request): string = u"学习Django，用它来建网站" return render(request, 'home.html', &#123;'string': string&#125;)#在视图中我们传递了一个字符串名称是 string(引号内的表示可悲html调用的) 到模板 home.html home.html 1&#123;&#123; string &#125;&#125; for循环views.py 123def home(request): TutorialList = ["HTML", "CSS", "jQuery", "Python", "Django"] return render(request, 'home.html', &#123;'TutorialList': TutorialList&#125;) home.html 123&#123;% for i in TutorialList %&#125;&#123;&#123; i &#125;&#125;&#123;% endfor %&#125; 1234567891011121314151617&gt; for循环要有个结束标记&gt;&gt; 一般的变量声明使用&#123;&#123;&#125;&#125;&gt;&gt; 功能性的 比如循环，条件判断等使用&#123;% %&#125;##### 显示字典的内容views.py```pythondef home(request): info_dict = &#123;&apos;site&apos;: u&apos;学堂&apos;, &apos;content&apos;: u&apos;IT技术教程&apos;&#125; return render(request, &apos;home.html&apos;, &#123;&apos;info_dict&apos;: info_dict&#125;) home.html 1站点：&#123;&#123; info_dict.site &#125;&#125; 内容：&#123;&#123; info_dict.content &#125;&#125; 遍历字典 123&#123;% for key, value in info_dict.items %&#125; &#123;&#123; key &#125;&#125;: &#123;&#123; value &#125;&#125;&#123;% endfor %&#125; 条件判断和 for 循环views.py 123def home(request): List = map(str, range(100))# 一个长度为100的 List return render(request, 'home.html', &#123;'List': List&#125;) home.html 123&#123;% for item in List %&#125; &#123;&#123; item &#125;&#125;, #每次结束都会在值得后面添加最后，最后一个依然会添加 99,&#123;% endfor %&#125; 所以，如何判读是不是最后一次遍历呢 forloop.last变量 判断是否为最后一项，如果是则为真，反之。 123&#123;% for item in List %&#125; &#123;&#123; item &#125;&#125;&#123;% if not forloop.last %&#125;, &#123;% endif %&#125; ##判断不是最后一个则加逗号&#123;% endfor %&#125; for循环的其他变量 变量 描述 forloop.counter 索引从1开始计算 forloop.counter0 索引从0开始计算 forloop.revcounter 索引最大长度到1 forloop.revcounter0 索引最大长度到0 forloop.first 遍历元素为第一项时，返回真 forloop.last 遍历元素为最后一项，返回真 forloop.parentloop 用在嵌套for循环中，获取上一层for循环的forloop 当列表可能为空的时候用 for empty 1234567&lt;ul&gt;&#123;% for athlete in athlete_list %&#125; &lt;li&gt;&#123;&#123; athlete.name &#125;&#125;&lt;/li&gt;&#123;% empty %&#125; &lt;li&gt;抱歉，列表为空&lt;/li&gt;&#123;% endfor %&#125;&lt;/ul&gt; 模板上得到视图对应的网址12345678910111213141516# views.pydef add(request, a, b): c = int(a) + int(b) return HttpResponse(str(c))# urls.pyurlpatterns = patterns(&apos;&apos;, url(r&apos;^add/(\d+)/(\d+)/$&apos;, &apos;app.views.add&apos;, name=&apos;add&apos;),) # template html&#123;% url &apos;add&apos; 4 5 %&#125;#name 的方便之处。#当urls文件发生改变的生后，并不需要去修改html#因为html中我们使用的是name 也就是add 还可以使用 as 语句将内容取别名（相当于定义一个变量） 123&#123;% url &apos;some-url-name&apos; arg arg2 as the_url %&#125; &lt;a href=&quot;&#123;&#123; the_url &#125;&#125;&quot;&gt;链接到：&#123;&#123; the_url &#125;&#125;&lt;/a&gt; 模板中使用逻辑操作==, !=, &gt;=, &lt;=, &gt;, &lt; 这些比较都可以在模板中使用 1234567891011&#123;% if var &gt;= 90 %&#125;成绩优秀，自强学堂你没少去吧！学得不错&#123;% elif var &gt;= 80 %&#125;成绩良好&#123;% elif var &gt;= 70 %&#125;成绩一般&#123;% elif var &gt;= 60 %&#125;需要努力&#123;% else %&#125;不及格啊，大哥！多去自强学堂学习啊！&#123;% endif %&#125; and, or, not, in, not in 也可以在模板中使用 12345&#123;% if num &lt;= 100 and num &gt;= 0 %&#125;num在0到100之间&#123;% else %&#125;数值不在范围之内！&#123;% endif %&#125; 判断是否在某个列表中 123&#123;% if &apos;ZILI&apos; in List %&#125;自强学堂在名单中&#123;% endif %&#125; 模板中获取当前网址，当前用户名等修改setting 1234567891011121314TEMPLATES = [ &#123; 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': [], 'APP_DIRS': True, 'OPTIONS': &#123; 'context_processors': [ ... 'django.template.context_processors.request', ... ], &#125;, &#125;,] 然后在模板中就可以调用了 获取用户 1&#123;&#123; request.user &#125;&#125; 判断登录 12345&#123;% if request.user.is_authenticated %&#125; &#123;&#123; request.user.username &#125;&#125;，您好！&#123;% else %&#125; 请登陆，这里放登陆链接&#123;% endif %&#125; 获取网址 1&#123;&#123; request.path&#125;&#125; 获取当前get 参数 1&#123;&#123; request.GET.urlencode&#125;&#125; 合并到一起举例 1&lt;a href=&quot;&#123;&#123; request.path &#125;&#125;?&#123;&#123; request.GET.urlencode &#125;&#125;&amp;delete=1&quot;&gt;当前网址加参数 delete&lt;/a&gt; 模型（数据库） Django模型适合数据库相关的，与数据库相关的代码一般写在models.py中，Django支持 sqlite3，Mysql，PostgreSQL等数据库，只要在setting.py中进行配置即可 123django-admin.py startproject learn_models # 新建一个项目cd learn_models # 进入到该项目的文件夹django-admin.py startapp people # 新建一个 people 应用（app) 一个项目包含多个应用，一个应用也可以在多个项目中 添加新的项目到settings.py – INSTALLED_APPS下 修改models.py与数据库相关的代码一般写在models.py中 12345678910111213141516from django.db import models class Person(models.Model): name = models.CharField(max_length=30) age = models.IntegerField() #新建了一个Person类，继承自models.Model, 一个人有姓名和年龄。这里用到了Field，#上面代码其实就相当于原生sqlCREATE TABLE myapp_person ( "id" serial NOT NULL PRIMARY KEY, "name" varchar(30) NOT NULL, "age" int() NOT NULL); 表名person_person由Django自动生成：项目名称+下划线+小写类名 同步数据库（默认使用SQLite3.0 无需配置） 123456Django 1.9 默认使用python manage.py makemigrationspython manage.py migrate#同步数据库 migrate代替老版本的syscdb#这两行命令会对models.py 进行检测，自动发现需要更改的，应用到数据库中去。127.0.0.1:8000/admin就可以看到简易的CMS系统了 同步数据库命令返回值 12345678910111213141516171819202122232425262728293031323334[root/myProject/learn_models] ]$python manage.py makemigrationsMigrations for 'people': 0001_initial.py: - Create model Person[root/myProject/learn_models] ]$python manage.py migrateOperations to perform: Apply all migrations: people, sessions, auth, contenttypes, adminRunning migrations: Rendering model states... DONE Applying contenttypes.0001_initial... OK Applying auth.0001_initial... OK Applying admin.0001_initial... OK Applying admin.0002_logentry_remove_auto_add... OK Applying contenttypes.0002_remove_content_type_name... OK Applying auth.0002_alter_permission_name_max_length... OK Applying auth.0003_alter_user_email_max_length... OK Applying auth.0004_alter_user_username_opts... OK Applying auth.0005_alter_user_last_login_null... OK Applying auth.0006_require_contenttypes_0002... OK Applying auth.0007_alter_validators_add_error_messages... OK Applying people.0001_initial... OK Applying sessions.0001_initial... OK[root/myProject/learn_models] ]$#创建superuserpython manage.py createsuperuserUsername (leave blank to use 'root'): Email address: ****@qq.comPassword: Password (again): Superuser created successfully.#此时我们登录 ipaddress:8000/admin 就能看到简单的CMS Django shell操作数据表 Django中的交互式shell来进行数据库的增删改查等操作 增加 查询1234567891011121314151617181920212223242526272829python manage.py shell#数据增加In [1]: from people.models import PersonIn [2]: Person.objects.create(name='lizili',age=18)#新加数据Out[2]: &lt;Person: Person object&gt;#数据库查询#查询所有，返回一个列表，无对象返回空In [6]: Person.objects.all()Out[6]: [&lt;Person: Person object&gt;]#查询指定对象In [4]: a=Person.objects.get(id=1)In [17]: a.nameOut[17]: 'lizili'#每次都要赋值才能查找，很麻烦，所以可以去modules.py中对语句进行修改from django.db import models# Create your models here.class Person(models.Model): name =models.CharField(max_length=30) age = models.IntegerField() def __str__(self): return u'name:%s , age:%s' % (self.name,self.age)#这样每次就可以直接查询了In [1]: from people.models import PersonIn [2]: Person.objects.get(id=1)Out[2]: &lt;Person: name:lizili , age:26&gt; 新建数据12345678910111213#1Person.objects.create(name=name,age=age)#2p = Person(name="WZ", age=23)p.save()#3p = Person(name="TWZ")p.age = 23p.save()#4这种方法是防止重复很好的方法，但速度要相对慢些#返回一个元组，第一个为Person对象，第二个为True或False, 新建时返回的是True, 已经存在时返回False.Person.objects.get_or_create(name="WZT", age=23) 查询数据1234567891011121314151617Person.objects.all()#查询所有Person.objects.all()[:10] #切片操作，获取10个人，不支持负索引，切片可以节约内存Person.objects.get(name='lizili') #关键字#get方法#get是用来获取一个对象的，如果需要获取满足条件的一些人，就要用到filter#filter方法Person.objects.filter(name="abc") # 等于Person.objects.filter(name__exact="abc") 名称严格等于 "abc" 的人Person.objects.filter(name__iexact="abc") # 名称为 abc 但是不区分大小写，可以找到 ABC, Abc, aBC，这些都符合条件Person.objects.filter(name__contains="abc") # 名称中包含 "abc"的人Person.objects.filter(name__icontains="abc") #名称中包含 "abc"，且abc不区分大小写Person.objects.filter(name__regex="^abc") # 正则表达式查询Person.objects.filter(name__iregex="^abc")# 正则表达式不区分大小写#filter是找出满足条件的，当然也有排除符合某条件的Person.objects.exclude(name__contains="WZ") # 排除包含 WZ 的Person对象Person.objects.filter(name__contains="abc").exclude(age=23) # 找出名称含有abc, 但是排除年龄是23岁的 自定义Field更多Field 以后补 数据表的更改 当数据库设计完后，发现不满意，需要更改，添加/删除字段。 Django 1.7+ 12345678910#直接修改models.py 然后执行以下语句即可python manage.py makemigrationspython manage.py migrate#会出现一下提示，选 1# 1) Provide a one-off default now (will be set on all existing rows)# 2) Quit, and let me add a default in models.py#新增了字段，但是原来已经的数据没有这个字段，#当你这个字段没有默认值，又不能为空的时候它就不知道怎么做#需要选择 1 来指定一个 “一次性的值” 给已有字段。 QuerySet API 数据库接口相关的接口（QuerySet API) 从数据库中查询出来的结果一般是一个集合，这个集合叫做 QuerySet]]></content>
      <categories>
        <category>web</category>
        <category>django</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell基础]]></title>
    <url>%2F2017%2F03%2F12%2Fshell%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[前言Shell 是一个用 C 语言编写的程序，它是用户使用 Linux 的桥梁。Shell 既是一种命令语言，又是一种程序设计语言。Shell 是指一种应用程序，这个应用程序提供了一个界面，用户通过这个界面访问操作系统内核的服务。 Shell基本介绍shell学习必备基础 Linux的基本使用 如何在bash上执行程序 简单的管道传输 使用 &amp;将程序放在后台执行 入门为什么要使用shell脚本? 使用脚本编程语言的好处是,脚本语言多半运行在比编译语言还高得层级,能够轻易处理文件与目录之类的对象.缺点:一般情况下,效率比较低.不过权衡之下,脚本的执行速度已经很快,快到足以让人感觉不到性能不高了.常用的脚本编程语言有:shelll,Ruby,JavaScript等. shell似乎是不同版本的linux系统之间的通用功能.shell脚本只要用心写,就能应用到很多系统上. shell脚本的过人之处 简单性:shell是高级语言 可移植性:通过POSIX(可移植操作系统接口，是IEEE为要在各种UNIX操作系统上运行的软件，而定义API的一系列互相关联的标准的总称)所定义的功能,可以在不同的系统上执行,无需需改. 开发容易:短时间即可完成一个功能强大又好用的脚本(字啊以后的学习中就能看到) 简单的shell脚本who 能看到以下内容 [root/shell] ]$cat 1.sh #!/bin/bash who [root/shell] ]$./1.sh root :0 2016-09-19 13:53 (:0) root pts/0 2017-02-13 12:49 (:0) root pts/2 2017-02-19 20:57 (192.168.247.1) 表示系统当前有多少人登陆，登陆用户-使用的终端-登陆时间&amp;登出时间 who | wc -l 统计当前登陆了多少人 脚本第一行#/bin/bash 指定运行此脚本的程序 也可以执行一些独立的程序 比如：#/bin/awk -f 以下是几个初级的陷阱: 1.对#!这一行的长度尽量不要超过64个字符 2.脚本的可移植性取决于是否有完整的路径名称 3.不要在选项之后放置任何空白,因为空白也会跟着选项一起传递给被引用的程序. 4.需要知道解释器的完成路径的名称.这样可以规避可移植性的问题,厂商不同,同样的东西可能放在不同的地方 5.一些较久的系统,内核不具备#!的能力,有些shell会自行处理,这些shell对于#!与紧随其后的解释器名称之间是否可以有空白,可能有不同的解释. 查看当前发行版本可以使用的shell:cat /etc/shells 查看系统默认的shell:echo $SHELL:一般情况下是输出/bin/bash. 如果想切换shell的版本,只需要直接输入shell的版本.例如想使用csh,直接输入csh即可,使用exit退出当前shell回到原shell. shell的基本元素shell识别三种基本命令: 内建命令:就是linux的命令,例如cd,ls,mkdir等,这些命令是由于其必要性才内建的,内外一种命令的村子啊是为了效率,其中最典型的就是test, shell函数:功能健全的一系列程序代码,用shell语言写成,可以像使用命令一样使用,就是在C++中调用函数. 外部命令:是由shell的副本(新的进程)所执行的命令,还是命令. shell中的变量在shell中,变量值可以是(通常是)空值,也就是不含有任何字符.这是合理的,也是常见的,好用的特性.空值就是null在shell中变量名的长度无限制,所能保存的字符数同样没有限制.变量的赋值方式:变量名=值,中间不能有任何的空格,如果想去除shell变量的值时,需要在变量名前加上$字符.当所赋予的值包含空格的时候,需要将值用单引号或者双引号包起来,用单引号包起来的后果是单引号里面的所有特殊符号都不具备特殊含义,用双引号包起来代表特殊符号有特殊含义.例如:123name=syx;echo &apos;name&apos; #输出 nameecho &quot;$name&quot; #输出 syx 如果想将 name1=syx,name2=zsf合并,成syxzsf则name=${name1}${name2},echo $name name=syxzsf,貌似还有其他的合并方法,个人觉得这一种最好.至于变量的四种类型什么的,暂时不学。 简单的echo输出echo的作用就是产生输出,可以提示用户,或者用来产生数据提供用户,或者产生数据进一步处理. 以前的echo只能将参数打印到shell交互界面上,参数之间以一个空格隔开,并以换行符号结尾.后来又衍生出了-n选项,省略结尾的换行符号. etho的语法: etho [string……] 用途是产生shell脚本的输出,没有什么主要选项.行为模式是将参数打印到标准输出,参数之间用空格隔开,并以换行符结尾.转义序列用来表示特殊字符,以及控制其行为模式. 参 数： -n 不要在最后自动换行-e 若字符串中出现以下字符，则特别加以处理，而不会将它当成一般文字输出：常用的转移序列: 123456789\a #发出警告声\b #删除前一个字符\c # 最后不加上换行符号；\f #换行但光标仍旧停留在原来的位置\n #换行\r #回车\t #水平制表符\v #垂直制表符\\ #反斜杠字符 华丽的printf 输出如同echo命令,printf命令可以输出简单的字符串，但是printf 不提供自动换行 语法printf format-string [arguments...] 12printf &quot;Hello, Shell\n&quot;Hello, Shell 123456789101112131415161718192021222324252627# format-string为双引号printf &quot;%d %s\n&quot; 1 &quot;abc&quot;1 abc# 单引号与双引号效果一样 printf &apos;%d %s\n&apos; 1 &quot;abc&quot; 1 abc# 没有引号也可以输出printf %s abcdefabcdef# 格式只指定了一个参数，但多出的参数仍然会按照该格式输出，format-string 被重用printf %s abc defabcdefprintf &quot;%s\n&quot; abc defabcdefprintf &quot;%s %s %s\n&quot; a b c d e f g h i ja b cd e fg h ij# 如果没有 arguments，那么 %s 用NULL代替，%d 用 0 代替printf &quot;%s and %d \n&quot; and 0# 如果以 %d 的格式来显示字符串，那么会有警告，提示无效的数字，此时默认置为 0printf &quot;The first program always prints&apos;%s,%d\n&apos;&quot; Hello Shell-bash: printf: Shell: invalid numberThe first program always prints &apos;Hello,0&apos; I/O重定向标准的输入输出在了解重定向之前,需要先了解一下标准的输入输出,总的来说,所有的数据都有来源,也都应该都重点,默认的标准输入输出就是终端.例如:我们只是输入 cat命令,并不指定任何参数,接着我们输入hello world,就是打印helloworld 到终端. [root~] ]$cat test #输入的 test #输出的 所谓的I/O重定向就是通过与终端交互,或是在shell脚本里设置,重新安排从哪里输入或者输出到哪里. 重定向与管道&lt; 改变标准输入> 改变标准输出 重定向符号在目的地文件不存在的时候会新建一个文件，如果存在，则会覆盖！&gt;&gt; 此重定向符号为追加| 管道可以将 标准输出 改为标准输入 如 cat /etc/paswd | wc -l 在构造管道的时候,应该试着让每个阶段的数据量变少,也就是说,把会让数据变少的命令放在前边,提高后面的命令的执行效率.例如,sort之前,先用grep找出相关的行,这样可以让sort少做些事. /dev/null和/dev/tty/dev/null 当被用作重定向输出时，程序的输出被直接丢弃。该文件用在那些不关心程序输出的地方。 当被用作重定向输入时，输入则是文件结束。/dev/tty 当被用作重定向时，表示重定向到终端。 shell基本命令查找与添加 shell会沿着\$PATH来寻找命令.\$PATH是一个以冒号分割的目录列表,你可以在列表所指定的目录下找到所要执行的命令.命令可能是shell脚本,也可能是编译后的可执行文件,从用户角度来看,二者并无不同. 默认路径至少包含/bin和/usr/bin,或许还包含其他的. 名称为bin的目录用来保存可执行文件. 如果要编写自己的脚本,最好准备一个自己的bin目录来存放他们,并且让shell能够自动找到他们. 要想永久生效,在/etc/profile文件中把你的bin目录加入到\$PATH,而每次登陆时Shell都将读取.profile文件. PATH=\$PATH:[你存放脚本的目录] 如“\$PATH:/usr/local/myshell $PATH里的空项目表示当前项目.空项目位于路径中间时,可以用两个连续的冒号来表示,如果将冒号直接置于最前端或尾端,分别表示查找的时候最先查找或最后查找当前目录. \$PATH=:/bin:/usr/bin 先找当前目录 \$PATH=/bin::/usr/bin 当前目录居中 \$PATH=/bin:/usr/bin: 最后找当前目录 不应该在查找路径中放进当前项目. 访问脚本的参数比如我们想查看当前某个用户是否登陆，那么新建脚本 finduser.sh 12#!/bin/bashwho | grep $1 12345./finduser/sh root$1 就是指执行脚本传入的第一个参数 rootroot :0 2016-09-19 13:53 (:0)root pts/0 2017-02-13 12:49 (:0)root pts/2 2017-02-20 20:45 (192.168.247.1) 理想状态下，是这样的，但是如果用户不输入参数，脚本就会报错了，所以更好的情况是把脚本可能出现的事件都做个判断以及友情的提示，更加智能化 基本的正则表达式(BRE)简单的正则举例12345678tolstoy: 匹配一行上任意位置的7个字母:tolstoy^tolstoy: 7个字母tolstoy,出现在一行的开头tolstoy$: 出现在一行的结尾^tolstoy$: 正好包含这7个字母的一行,没有其他的任何字符.[tT]olstoy: 在一行的任意位居中,含有Tolstoy或者tolstoytol.toy:在一行的任意位居中,含有tol这三个字母,加上一个特殊字符,在接着toy这三个字母tol.*toy:在一行的任意位居中,含有tol这三个字母,加上任意的0或者多个字符, 再继续toy这三个字母(例如:toltoy,tolstoy,tolWHOtoy都是满足要求的). shell中的通配符12345*: 代表0个或者多个任意字符?: 代表一定有一个的任意字符[]: 代表一定有一个在括号内的字符(非任意字符).例如[abcd]代表一定有一个字符,可能是abcd这四个选项的任意一个.[-]: 代表在编码顺序内的所有自负.例如:0-9代表0到9之间的所有数字,因为数字的语系编码是连续的.[^]: 若括号内的第一个字符为指数字符\(^) 表示反选,例如:\^abc代表是非abc的其他字符就可以. #####shell中的特殊字符1234567891011121314#: 注释字符\: 将特殊字符或者通配符还原成一般字符|: 管道符,分割两个管线命令的界定;: 连续命令下达分隔符~: 用户的家目录$: 放在变量前面,正确使用变量&amp;: 工作控制,将命令编程背景下工作!: 非(!)的意思,逻辑运算符&gt;,&gt;&gt;: 输出重定向,分别是覆盖和追加&gt;&lt;,&lt;&lt;: 输入重定向&gt;&apos;&apos;: 单引号,不具有变量置换的功能&gt;&quot;&quot;: 双引号,具有变量置换的功能&gt;(): 在中间的为子shell的起始与结束&gt;&#123;]: 在中间为命令块的组合 #####shell中正则表达式的控制字符 1234567891011^: 匹配行首位置$: 匹配行尾位置.: 匹配任意祖父*: 对*之前的匹配整体或字符匹配任意次(包括0次)\?: 对\?之前的匹配整体或字符匹配0次或1次\&#123;n\&#125;: 对 \ &#123; 之前的匹配整体或字符匹配n次\&#123;m,\&#125;: 对 \ &#123; 之前的匹配整体或字符匹配至少m次\&#123;m,n&#125;: 对 \ &#123; 之前的匹配整体或字符匹配m到n次 [abcdef]: 对单字符而言匹配中的字符[a-z]; 对单字符而言,匹配任意一个小写字母[^a-z]: 不匹配括号中的内容 基本正则表达式匹配单个字符 1.匹配一般字符:一般字符是指无特殊含义的字符,包括所有文本和数字字符,绝大多数的空白字符以及标点符号字符,因此,正则a,匹配a. 2.如果相匹配,因为是特殊字符,所以需要用 \ 转义,正则*,匹配*. 3..(点号)字符意即”任意字符”,例如a.c匹配于abc,aac. 4.使用方括号表达式.例如x[abcdefg]z,可以匹配xaz,xbz,等,方括号里如果存在(^),表示取反的意思,就是说不匹配列表里的任意字符. [0123456789]表示所数字,但是这样写太麻烦,我们可以用[0-9]来表示,[abcdefg]同样可以用[a-g] 单个表达式匹配多字符 最简单的办法就是把它们一一列出来:正则abc匹配于abc. 虽然(.)meta字符与方括号表达式都提供了依次匹配一个字符的很好方式,单正则真正强大而有力地功能是修饰符meta字符的使用上. 最常用的修饰符是(*),表示匹配0个或多个前面的单个字符.因此ab*c表示”匹配一个a,0个或多个b字符以及a空c”.这个正则匹配的有ac,abc,abbcabbbbc. 匹配0或多个,不表示匹配其他的某一个.例如正则abc,文本aQc是不匹配的.但是ac是匹配的. ()修饰符虽然好用,但是他没有限制,如要只要指定次数,使用一个复杂的方括号表达式虽然也能指定次数,但是太过麻烦.我们就引入了区间表达式.所谓的区间表达式有三种变化 \{n\} 前置正则表达式所得结果重现n次 \{n,\} 前置正则表达式所得结果至少出现n次 \{n,m\} 出现n到m次 例如我们想要表达”重现5个a&#39; =&gt;a\{5\}&#39;,重现10到42个q&#39;=&gt;q\{10,42\}&#39;; 文本匹配锚点 两个meta字符是脱节符号(^),与货币字符($),他们叫做锚点,因为其用途在限制正则表达式匹配时,针对要被匹配字符的开始或者结尾处进行匹配, 假定有一串字符串:abcABCdefDEF 模式 是否匹配 理由 ABC 是 居中的456匹配 ^ABC 否 起始不是ABC def 是 居中的def匹配 def$ 否 结尾不是def [[:upper:]]{3} 是 结尾的大写ABC匹配 [[:upper:]]{3}$ 是 结尾的大写DEF匹配 ^[[:alpha:]]{3} 是 结尾的大写ABC匹配 #####BRE运算优先级,由高到低1234567[..]\[==][::] -----用于字符拍的方括号符号\metacharacter ----转移的meta字符[] --------------- 方括号表达式\&#123; \&#125; ------------子表达式* \&#123; \ &#125; ---------前置单个字符重现的正则表达式无符号--------------连续^$ -------------- 锚点 扩展正则表达式(ERE) BRE与ERE在大多数的meta字符与功能应用上几乎是完全一致,单ERE理由写meta字符看起来与BRE类似,却具有完全不同的类型. 扩展正则表达式与基础正则表达式的唯一区别在于：? + () {} 这几个字符。 基础正则表达式中，如果你想? + () {}表示特殊含义，你需要将他们转义 而扩展正则表达式中，如果你想? + () {} 不表示特殊含义，你需要将他们转义。 转义符号，都是一样的，\符号。 所谓特殊含义，就是正则表达式中的含义。非特殊含义，就是这个符号本身。 例如12345echo aaa|grep &apos;a?&apos;;echo aaa|grep &apos;a\?&apos;; \#aaa\#egrep使用的是扩展正则表达式echo aaa|egrep &apos;a?&apos;; \#aaaecho aaa|egrep &apos;a\?&apos;; 打印 如果希望打印文件,最好预先处理一下,包括调整边距,设置行高,设置标题等,这样打印出来的文件更加美观.当然,不处理也能打印,但是可能会比较丑陋. pr命令pr命令就是转换文件格式的,可以把较大的文件分割成多个页面进行打印,并未每个页面添加标题. 语法:option(s) filename(s)```12常见选项: -k:分成激烈打印,默认为1 -d:两倍行距(并不是所有版本的pr都有效) -h “title” 设置每个文件的标题 -l PAGE_LENGTH :每页显示多少行.默认是每个页面一共66行. -o MARGIN:每行缩进的空格数 -w PAGE_WIDTH:多列输出时,设置页面宽度,默认是72个字符.123456789例如我有一个文件food,里面的内容为:&gt; Sweet Tooth&gt; Bangkok Wok&gt; Mandalay&gt; Afghani Cuisine&gt; Isle of Java&gt; Big Apple Deli&gt; Sushi and Sashimi&gt; Tio Pepe&apos;s Peppers 使用命令:pr -2 -h “food” food 输出结果为: 2015-06-22 12:27 food weet Tooth Isle of Java Bangkok Wok Big Apple Deli Mandalay Sushi and Sashimi Afghani Cuisine Tio Pepe’s Peppers’123456789 解释:&gt;pr会以文件的修改时间作为页面标题的时间戳;如果输入时自管道而来,则使用当前的时间,接上文件名称(如果输入的数据内容在管道中,则为空)以及页码.&gt; lp 和 lpr 命令将文件传送到打印机进行打印。使用 pr 命令将文件格式化后就可以使用这两个命令来打印。例如:``` pr -2 -h &quot;food&quot; food | lpr 命令成功执行会返回一个表示打印任务的ID，通过这个ID可以取消打印或者查看打印状态。 如果你希望打印多份文件，可以使用 lp 的 -nNum 选项，或者 lpr 命令的 -Num 选项。Num 是一个数字，可以随意设置。 如果系统连接了多台打印机，可以使用 lp 命令的 -dprinter 选项，或者 lpr 命令的 -Pprinter 选项来选择打印机。printer 为打印机名称。 lpstat 和 lpq 命令 lpstat 命令可以查看打印机的缓存队列（有多少个文件等待打印），包括任务ID、所有者、文件大小、请求时间和请求状态。 提示：等待打印的文件会被放到打印机的的缓存队列中。 使用 lpstat -o 命令查看打印机中所有等待打印的文件，lpstat -o 命令按照打印顺序输出队列中的文件。 cancel 和 lprm 分别用来终止 lp 和 lpr 的打印请求。使用这两个命令，需要指定ID（由 lp 或 lpq 返回）或打印机名称。 lprm 命令用来取消当前用户的正在等待打印的文件，使用任务号作为参数可以取消指定文件，使用横线(-)作为参数可以取消所有文件。 lprm 会返回被取消的文件名。 提取文件开头或者结尾head &amp; tail 个人觉得最好用的显示文本文件的头几行最好用的是 head -n [file(s)] head的常用选项:1234&gt; -q: 隐藏文件名&gt; -v: 显示文件名&gt; -c&lt;字节&gt;: 显示字节数&gt; -n&lt;行数&gt;: 显式的行数 在交互式shell通信期中,有时需要监控某个文件的输出—-如日志这类持续写入状态的文件.-f选项这时就派上用场了,他可以要求tail显示指定的文件结尾行数,接着进入无止境的循环中—-休息一秒后又再度醒来并检查是否需要显示更多的输出结果.再设置-f的状态下,tail只有当你中断它时才会停止—-通常是输入Ctrl+C来中断; -n 25 -f``` 此选项不可用于shell脚本.1234&gt; 直到按了ctrl+c选项后才停止.&gt; 由于tail加上-f选项之后便不会自己中断,所以此选项不能用于shell脚本.使用-f选项有实时监听的效果. head案例: 使用命令:head -n 3 /etc/passwd结果是显示文件的头三行, 如果命令为:head -n -3 /etc/passwd 结果是显示除了最后三行都显示,注意到区别没有? 相似的,显示文件的前n个字节,以及除了最后n个字节以外的内容也没问题了. head和tail如果组合使用: head -n 5 /etc/passwd | tail -n 3 输出/etc/passwd的第三道第五行.123456789101112131415#### shell变量与算数test.shname=vic #定义一个变量readonly name #变量只读unset name #删除变量sleep 5 #等待5秒##### 参数的展开 var=”hello world”echo ${var} #hello world #所谓的参数的展开，基本上就是变量，shell中，参数是变量的超集，只不过变量不能以数字开头，而参数可以，比如$1，表示传递的第一个参数12##### 位置参数 $0 #程序名$1到$9 #直接表示${10} #大于9的时候要用花括号 $ #接收所有参数，$@ #传递给脚本或函数的所有参数。被双引号(“ “)包含时，与 $ 稍有不同 #但是当它们被双引号(“ “)包含时，”$*” 会将所有的参数作为一个整体！以”$1 $2 … $n”的形式输出所有参数；”$@” 会将各个参数分开，以”$1” “$2” … “$n” 的形式输出所有参数。 $? #上个命令的退出状态，或函数的返回值$$ #SHELL的进程ID$# #参数个数123456##### 展开运算符（参数的运算符） ${varname:-zili} #如果varname存在且不是NULL，返回varname，反之，设为zili。可用于设置变量默认值！！ ${varname:+zili} #如果varname存在且不是NULL，返回varname，反之，返回null12##### 模式运算符 var=br1br2eadecho ${var$$br}输出:2eadecho ${var#br}输出:1br2ead ${parameter%word}或${parameter%%word}作用:与前例相似,唯一不同的是从$parameter的为不开始匹配.var=”La.Maison.en.Petits.Cubes.avi”echo ${var%.}输出:La.Maison.en.Petits.Cubesecho ${var%%.}输出:La 分析:匹配案例中的”.”时,shell会从$var的尾部开始查找”.”,如果是最短匹配(echo ${var%.}),则会找到第一个”.”就停止,否则(echo ${var%%.})会一直找到最后一个”.”才停止.可以看到,这种用法可以分方便的去掉文件后缀,从而得到文件名.12345678#### 退出状态和 if 语句##### 退出状态&gt; 每一条命令,不管是内置的,shell函数,还是外部的,当它退出时,都会返回一个小的整数值给引用它的程序,这就是程序的退出状态.在shell下执行进程有很多方式可取用程序的退出状态.&gt; 以管理状态来说，0 表示成功，也就是当$? 返回的值为0的时候，证明程序执行成功，其他为失败 0 #命令成功地退出 0 #在重定向或单词展开期间(~,变量,命令,算数展开,以及单词切割)失败1-125 #命令不成功的退出.特定的退出值的含义,是由各个单独的命令定义的.126 #命令找到了,但文件无法执行127 #命令没找到128 #命令因受到信号而死亡12###### exit cd $(dirname $0) || exit 1 ##进入脚本所在目录 否则退出12 if [ $# -ne “2” ]; then echo ‘’ exit 2fi12##### if语法 if [xxxx];then xxxxfi if [xxxx];then xxxx else xxxxfi if [xxxx];then xxxx elif [xxxx];then xxxx….….else xxxxfi12 #!/bin/bashread -p “what is your backup directoy : “ BakDirif [ -d $BakDir ];then echo “$BakDir alerdy exist”else echo “$BakDir is not exist,will make it” mkdir $BakDirfi12 #!/bin/bashUserNum=who | wc -lif [ $UserNum -gt 3 ]; then echo “Alert, too many login users ( Total: $UserNum).”else echo “Login Users:” who | awk ‘{print $1,$2}’fi12345678910111213**注意**&gt; if 与[ 之间必须有空格&gt;&gt; [ ]与判断条件之间也必须有空格&gt;&gt; ]与; 之间不能有空格#### 逻辑判断##### 字符串判断 str1 = str2 当两个串有相同内容、长度时为真str1 != str2 当串str1和str2不等时为真-n str1 当串的长度大于0时为真(串非空)-z str1 当串的长度为0时为真(空串)1234##### 数字的判断 int1 -eq int2 两数相等为真int1 -ne int2 两数不等为真int1 -gt int2int1大于int2为真int1 -ge int2int1大于等于int2为真int1 -lt int2int1小于int2为真int1 -le int2int1小于等于int2为真12##### 文件的判断 -r file 用户可读为真-w file 用户可写为真-x file 用户可执行为真-b file 若文件存在且是一个块特殊文件，则为真-c file 若文件存在且是一个字符特殊文件，则为真-d file 若文件存在且是一个目录，则为真-e file 若文件存在，则为真-f file 若文件存在且是一个规则文件，则为真-g file 若文件存在且设置了SGID位的值，则为真-h file 若文件存在且为一个符合链接，则为真-k file 若文件存在且设置了”sticky”位的值-p file 若文件存在且为一已命名管道，则为真-s file 若文件存在且其大小大于零，则为真-u file 若文件存在且设置了SUID位，则为真-o file 若文件存在且被有效用户ID所拥有，则为真12##### 复杂的逻辑判断 -a 与-o 或! 非12#####test的使用 #!/bin/bashcd /binif test -e ./bash //其实这里相当于if [ -e ./bahs ]then echo ‘the file already exist!’else echo ‘the file not exist!’fi输出结果为:the file already exist!1234##### 注意和简写与扩展###### 注意 if [ -n “$str” -a -f “$file” ] 一个test命令,两种条件if [-n “str”] &amp;&amp; [ -f “$file” ] 两个命令,一块接方式计算if [-n “$str” &amp;&amp; -f “$file”] 语法错误！！！12###### 简写 [1 eq1 ] &amp;&amp;echo’OK’输出:ok [ 2 &lt; 1 ] &amp;&amp;echo ‘OK’输出:-bash: 1: No such file or directory使用命令:[ 2 \&lt; 1 ] &amp;&amp;echo ‘OK’这样就可以了 使用命令:[ 2 -gt 1 -a 3 -lt 4 ]&amp;&amp;echo ‘Ok’输出:Ok 使用命令:[ 2 -gt 1 &amp;&amp; 3 -lt 4 ]&amp;&amp;echo ‘Ok’输出:-bash: [: missing `]’ 注意：在[] 表达式中，常见的&gt;,&lt;需要加转义字符，表示字符串大小比较，以acill码位置作为比较。不直接支持&lt;&gt;运算符，还有逻辑运算符 || 和 &amp;&amp; 它需要用-a[and] –o[or]表示。12###### 扩展 [[]] [[ 2 &lt; 3 ]]&amp;&amp;echo ‘OK’输出OK. [[ 2 &lt; 3 &amp;&amp; 4 &lt; 5 ]] &amp;&amp; echo ‘ok’输出:ok 注意：[[]] 运算符只是[]运算符的扩充。能够支持&lt;,&gt;符号运算不需要转义符，它还是以字符串比较大小。里面支持逻辑运算符 || 和 &amp;&amp; bash 的条件表达式中有三个几乎等效的符号和命令：test，[]和[[]]。通常，大家习惯用if [];then这样的形式。而[[]]的出现，根据ABS所说，是为了兼容&gt;&lt;之类的运算符。 不考虑对低版本bash和对sh的兼容的情况下，用[[]]是兼容性强，而且性能比较快，在做条件运算时候，可以使用该运算符。12345678910111213141516#### case```shell#!/bin/shread -p &apos;input a number 1 to 4&apos; unumcase $unum in 1) echo &apos;Number is 1&apos; ;; 2|3) echo &apos;Number is 2 or 3&apos; ;; 4) echo &apos;Number is 4&apos; ;; *) echo &apos;1 to 4,Please&apos; ;;esac ) 相当于其他语言中的default。 除了)模式，各个分支中;;是必须的，;;相当于其他语言中的break | 分割多个模式，相当于or 循环for for循环是将串行的元素取出,依次放入指定的变量中,重复执行在do和done之间的命令,直到所有元素取尽为止 12345678910for 变量 in 串行do....donefor((i=0;i&lt;100;i++))do....done 12345678910#!/bin/shfor i in $(seq 1 10)do mkdir /tmp/test$&#123;i&#125; cd /tmp/test$&#123;i&#125; for j in $(seq 1 5) do touch test$&#123;j&#125; donedone 123456789#!/bin/shdir=&quot;/var&quot;cd $dirfor i in $(ls $dir)do if [ -d $i ];then du -sh $i fi done while1234while 条件测试do....done 123456789#!/bin/shsum=100i=0while [ $i -le 100 ] do sum=$(($sum+$i)) i=$(($i+1)) doneecho $sum until123456until 条件测试do....done#条件为真时，循环停止 12345678sum=0i=1until ((i&gt;100))do sum=$(( $sum+$i )) i=$(( $i+1 ))doneecho $sum 退出/跳出循环break 直接打断循环 continue 跳过本次循环 shift shift每执行一次，参数指针像右移动一位， 1234567891011#!/bin/bashuntil [ $# -eq 0 ]do echo &quot;第一个参数为: $1 参数个数为: $#&quot; shiftdon第一个参数为: 1 参数个数为: 4第一个参数为: 2 参数个数为: 3第一个参数为: 3 参数个数为: 2第一个参数为: 4 参数个数为: 1 getopts 以后研究 Linux相关命令详解grep语法grep (option) [file] 选项 -A 1 表示找到所有匹配行，并显示所有匹配行后的一行 -B 1 表示找到所有匹配行，并显示所有匹配行的前面一行 -C 1表示找到所有匹配行，并显示所有匹配行的前一行，后一行 -V:显示不匹配的行 -a 表示把所有文件当作ASCII文件来处理 搜索二进制文件 -b 表示显示match的字符串在文件中的offset -c 显示有多少行match -e 后面跟一个正则表达式，指定多个正则表达式的时候很有用 -f可以指定pattern在我们的文件中 pattern文件中的每一行都会来进行匹配 -i:模式匹配时忽略大小写 -l 出匹配模式的文件名称,而不是打印匹配的行 -m 最多匹配几个后，就停止，这样速度会比较快 -n 匹配之后，在前面打印行号，这个还是有用的 -o 只打印匹配的内容 -R 搜索子目录 参数文件，文档等 实例 grep -n ‘root’ /etc/passwd grep -m 1 ‘root’ /etc/passwd tr语法tr (选项) (参数) 选项 -c或——complerment：取代所有不属于第一字符集的字符； -d或——delete：删除所有属于第一字符集的字符； -s或——squeeze-repeats：把连续重复的字符以单独一个字符表示； -t或——truncate-set1：先删除第一字符集较第二字符集多出的字符。 参数 字符集1：指定要转换或删除的原字符集。当执行转换操作时，必须使用参数“字符集2”指定转换的目标字符集。但执行删除操作时，不需要参数“字符集2”； 字符集2：指定要转换成的目标字符集。 实例输入的字符串大写转成小写： 123echo &quot;HELLO WORLD&quot; | tr &apos;A-Z&apos; &apos;a-z&apos;hello world#由于是转换，所以必须要有字符集2 也就是&apos;a-z&apos; 用tr压缩字符，可以压缩输入中重复的字符： 12echo &quot;thissss is a text linnnnnnne.&quot; | tr -s &apos; sn&apos;this is a text line. sed 语法 sed的命令格式： sed [option] ‘sed command’filename sed的脚本格式：sed [option] -f ‘sed script’filename 选项 -n ：只打印模式匹配的行 -e ：直接在命令行模式上进行sed动作编辑，此为默认选项 -f ：将sed的动作写在一个文件内，用–f filename 执行filename内的sed动作 -r ：支持扩展表达式 -i ：直接修改文件内容 实例1234567sed -n &apos;5p&apos; /etc/passwd #打印某一行sed -n &apos;5,8P&apos; /etc/passwd #打印5-8行sed -n &apos;/root/p&apos; /etc/passwd #匹配某字符的行sed -n &apos;/root/,5p&apos; /etc/passwd #以匹配某字符的行 到某行sed -n &apos;1,/adm/p&apos; /etc/passwd #匹配从哪里开始 以某关键字结尾的行sed -n &apos;1,4&#123;=;p&#125;&apos; /etc/passwd #打印带行号的sed -n &apos;1,4!&#123;=;p&#125;&apos; /etc/passwd # ！感叹号取反 不打印1-4行 sed 匹配正则 -r选项 12345678910111213141516171819^ 锚点行首的符合条件的内容，用法格式&quot;^pattern&quot;$ 锚点行首的符合条件的内容，用法格式&quot;pattern$&quot;^$ 空白行. 匹配任意单个字符* 匹配紧挨在前面的字符任意次(0,1,多次).* 匹配任意长度的任意字符? 匹配紧挨在前面的字符0次或1次\&#123;m,n\&#125; 匹配其前面的字符至少m次，至多n次\&#123;m,\&#125; 匹配其前面的字符至少m次\&#123;m\&#125; 精确匹配前面的m次\&#123;0,n\&#125;:0到n次\&lt; 锚点词首----相当于 \b，用法格式：\&lt;pattern\&gt; 锚点词尾， 用法格式:\&gt;pattern\&lt;pattern\&gt; 单词锚点分组，用法格式：pattern，引用\1,\2[] 匹配指定范围内的任意单个字符[^] 匹配指定范围外的任意单个字符[:digit:] 所有数字, 相当于0-9， [0-9]---&gt; [[:digit:]][:lower:] 所有的小写字母 实例1234567#######sed的匹配模式支持正则表达式##################### sed &apos;5 q&apos; /etc/passwd #打印前5行 sed -n &apos;/r*t/p&apos; /etc/passwd #打印匹配r有0个或者多个，后接一个t字符的行 sed -n &apos;/.r.*/p&apos; /etc/passwd #打印匹配有r的行并且r后面跟任意字符 sed -n &apos;/o*/p&apos; /etc/passwd #打印o字符重复任意次 sed -n &apos;/o\&#123;1,\&#125;/p&apos; /etc/passwd #打印o字重复出现一次以上 sed -n &apos;/o\&#123;1,3\&#125;/p&apos; /etc/passwd #打印o字重复出现一次到三次之间以上 sed编辑命令12345678910111213141516p 打印匹配行（和-n选项一起合用）= 显示文件行号a\ 在定位行号后附加新文本信息i\ 在定位行号前插入新文本信息d 删除定位行c\ 用新文本替换定位文本w filename 写文本到一个文件，类似输出重定向 &gt;r filename 从另一个文件中读文本，类似输入重定向 &lt;s 使用替换模式替换相应模式q 第一个模式匹配完成后退出或立即退出l 显示与八进制ACSII代码等价的控制符&#123;&#125; 在定位行执行的命令组，用分号隔开n 从另一个文件中读文本下一行，并从下一条命令而不是第一条命令开始对其的处理N 在数据流中添加下一行以创建用于处理的多行组g 将模式2粘贴到/pattern n/y 传送字符，替换单个字符 ####### 实例 1234567891011121314151617sed -n &apos;/^#/p&apos; /etc/profile #打印以井号开头的 &apos;/^#/!P&apos;加感叹号表示没有注释的行sed -n &apos;/^#/!&#123;/^$/!p&#125;&apos; /etc/profile #这样过滤所有的#开头和空白行sed -e &apos;/^#/d&apos; -e &apos;/^$/d&apos; /etc/profile #等同上面，-e 支持对单个文件进行不同的操作sed &apos;/root/s/^/SSSSSSSSSSSSS/&apos; /etc/passwd #匹配root的行，行首添加SSSSSS...sed &apos;/root/s/$/SSSSSSSSSSSSS/&apos; /etc/passwd #匹配root的行，行尾添加SSSSSS...sed &apos;s/root/&amp; LLL/&apos; /etc/passwd #匹配root关键字，前面添加 LLLsed &apos;s/root/LLL &amp;/&apos; /etc/passwd #匹配root关键字，后面添加 LLLsed &apos;/zabbix/i ZZZ&apos; /etc/passwd #匹配root关键字，前一行添加 ZZZsed &apos;/zabbix/a ZZZ&apos; /etc/passwd #匹配root关键字，后一行添加 ZZZsed &apos;/zabbix/a ZZZ \n OOO&apos; /etc/passwd #\n 可以用来换行sed &apos;s/^/DDDDDDDD/&apos; /etc/passwd #每行的开头添加 DDDDDD....sed &apos;s/$/DDDDDDDD/&apos; /etc/passwd #每行的结尾添加 DDDDDD....sed &apos;1，3s/^/#/&apos; /etc/passwd #每行的开头# 这个用来添加注释 sed删除12345sed &apos;/^#/d&apos; #删除#开头的sed &apos;/^#/!d&apos; #删除非#开头的sed &apos;/root/d&apos; #删除匹配root的字符sed &apos;/\&lt;you&gt;\/&apos; #删除包含you这个单词的行 \&lt;&gt;\用来定位单词... sed替换(脚本中较多使用)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#================源文件里面的内容=============================== [root@jie1 ~]# cat test anonymous_enable=YES write_enable=YES local_umask=022 xferlog_enable=YES connect_from_port_20=YES root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin DEVICE=&quot;eth0&quot; BOOTPROTO=&quot;static&quot; HWADDR=&quot;00:0C:29:90:79:78&quot; ONBOOT=&quot;yes&quot; IPADDR=172.16.22.1 NETMASK=255.255.0.0 #====================================================================== [root@jie1 ~]# sed -i &apos;/DEVICE/c\Ethernet&apos; test #匹配DEVICE的行，替换成Ethernet这行 [root@jie1 ~]# sed -i &apos;s/static/dhcp/&apos; test #把static替换成dhcp(/,@,#都是前面所说的地址定界符) [root@jie1 ~]# sed -i &apos;/IPADDR/s@22\.1@10.12@&apos; test #匹配IPADDR的行，把22.1替换成10.12由于.号有特殊意义所有需要转义 [root@jie1 ~]# sed -i &apos;/connect/s#YES#NO#&apos; test #匹配connect的行，把YES替换成NO [root@jie1 ~]# sed -i &apos;s/bin/tom/2g&apos; test #把所有匹配到bin的行中第二次及第二次之后出现bin替换成tom [root@jie1 ~]# sed -i &apos;s/daemon/jerry/2p&apos; test #把所有匹配到bin的行中第二次出现的daemon替换成jerry，并在生产与匹配行同样的行 [root@jie1 ~]# sed -i &apos;s/adm/boss/2&apos; test #把所有匹配到adm的行中仅仅只是第二次出现的adm替换成boss [root@jie1 ~]# sed -i &apos;/root/&#123;s/bash/nologin/;s/0/1/g&#125;&apos; test #匹配root的行，把bash替换成nologin，且把0替换成1 [root@jie1 ~]# sed -i &apos;s/root/(&amp;)/g&apos; test #把root用括号括起来，&amp;表示引用前面匹配的字符 [root@jie1 ~]# sed -i &apos;s/BOOTPROTO/#BOOTPROTO/&apos; test #匹配BOOTPROTO替换成#BOOTPROTO，在配置文件中一般用于注释某行 [root@jie1 ~]# sed -i &apos;s/ONBOOT/#&amp;/&apos; test #匹配ONBOOT的行的前面添加#号，在配置文件中也表示注释某行 [root@jie1 ~]# sed -i &apos;/ONBOOT/s/#//&apos; test #匹配ONBOOT的行，把#替换成空，即去掉#号，也一般用作去掉#注释 #================执行以上sed命令之后文件显示的内容==================== [root@jie1 ~]# cat test anonymous_enable=YES write_enable=YES local_umask=022 xferlog_enable=YES connect_from_port_20=NO (root):x:1:1:(root):/(root):/bin/nologin bin:x:1:1:tom:/tom:/stom/nologin daemon:x:2:2:jerry:/sbin:/stom/nologin daemon:x:2:2:jerry:/sbin:/stom/nologin adm:x:3:4:boss:/var/adm:/sbin/nologin lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin Ethernet #BOOTPROTO=&quot;dhcp&quot; HWADDR=&quot;00:0C:29:90:79:78&quot; ONBOOT=&quot;yes&quot; IPADDR=172.16.10.12 NETMASK=255.255.0.0 sed 引用变量 (脚本中也较多使用)第一种当sed命令里面没有默认的变量时可以把单引号改成双引号第二种当sed命令里面有默认的变量时，自己定义的变量需加单引号，且sed里面的语句必须用单引 123#!/bin/shmy_name=lised -i &apos;s/&apos;bbb&apos; /&apos;$my_name&apos;/&apos; /shell/myfile sed的其他用法操作一个文件，并写入到另一个文件1234567891011[root@jie1 ~]# cat test #sed操作的文件中的内容 Ethernet #BOOTPROTO=&quot;dhcp&quot; HWADDR=&quot;00:0C:29:90:79:78&quot; ONBOOT=&quot;yes&quot; IPADDR=172.16.10.12 NETMASK=255.255.0.0 [root@jie1 ~]# sed -i &apos;s/IPADDR/ip/w ip.txt&apos; test #把sed操作的文件内容保存到另外一个文件中，w表示保存，ip.txt文件名 [root@jie1 ~]# cat ip.txt #查看新文件的内容 ip=172.16.10.12 读取一个文件到正在用sed操作的文件中 1234567891011121314151617181920212223242526[root@jie1 ~]# cat myfile #文件内容 hello world i am li how are you li [root@jie1 ~]# cat test #将用sed操作的文件的内容 Ethernet #BOOTPROTO=&quot;dhcp&quot; HWADDR=&quot;00:0C:29:90:79:78&quot; ONBOOT=&quot;yes&quot; IPADDR=172.16.10.12 NETMASK=255.255.0.0 [root@jie1 ~]# sed -i &apos;/Ethernet/r myfile&apos; test #在匹配Ethernet的行，读进来另一个文件的内容，读进来的文件的内容会插入到匹配Ethernet的行后 [root@jie1 ~]# cat test #再次查看用sed命令操作的行 Ethernet hello world i am li how are you li #BOOTPROTO=&quot;dhcp&quot; HWADDR=&quot;00:0C:29:90:79:78&quot; ONBOOT=&quot;yes&quot; IPADDR=172.16.10.12 NETMASK=255.255.0.0 [root@jie1 ~]# sed的经典例子1234567891011121314151617181920212223242526[root@jie1 ~]# cat myfile #文件内容 hello world i am li how are you li [root@jie1 ~]# cat test #将用sed操作的文件的内容 Ethernet #BOOTPROTO=&quot;dhcp&quot; HWADDR=&quot;00:0C:29:90:79:78&quot; ONBOOT=&quot;yes&quot; IPADDR=172.16.10.12 NETMASK=255.255.0.0 [root@jie1 ~]# sed -i &apos;/Ethernet/r myfile&apos; test #在匹配Ethernet的行，读进来另一个文件的内容，读进来的文件的内容会插入到匹配Ethernet的行后 [root@jie1 ~]# cat test #再次查看用sed命令操作的行 Ethernet hello world i am li how are you li #BOOTPROTO=&quot;dhcp&quot; HWADDR=&quot;00:0C:29:90:79:78&quot; ONBOOT=&quot;yes&quot; IPADDR=172.16.10.12 NETMASK=255.255.0.0 [root@jie1 ~]# AWK基础语法1234567891011121314151617181920212223awk [options] file ...#逐行读取并打印出来，默认以空格分割awk &apos;&#123;print $0&#125;&apos; /etc/passwd #读取每行的第一个域的内容，并打印出来awk -F: &apos;&#123;print $1&#125;&apos; /etc/passwd #匹配的列,只要有匹配就打印，不分域awk &apos;/root/ &#123;print $1&#125;&apos; /etc/passwd#统计行数awk &apos;&#123;count++&#125;END&#123;print count&#125;&apos; /etc/passwd#count是自定义变量,这里没有初始化count,虽然默认是0,但是妥当的做法还是初始化为0.awk &apos;BEGIN&#123;count=0&#125;&#123;count=count+1&#125;END&#123;print count&#125;&apos; /etc/passwd#字符长度大于N的行awk -F: &apos;length($1)&gt;5&apos; /etc/passwd#统计某个文件夹下的文件占用的字节数ls -l |awk &apos;BEGIN &#123;size=0;&#125; &#123;size=size+$5;&#125; END&#123;print &quot;[end]size is &quot;, size&#125;&apos;#按照M为单位显示ls -l |awk &apos;BEGIN &#123;size=0;&#125; &#123;size=size+$5;&#125; END&#123;print &quot;[end]size is &quot;, size/1024/1024,&quot;M&quot;&#125;&apos; 内置函数1234567891011ARGC 命令行参数个数ARGV 命令行参数排列ENVIRON 支持队列中系统环境变量的使用FILENAME awk浏览的文件名FNR 浏览文件的记录数FS 设置输入域分隔符，等价于命令行 -F选项NF 浏览记录的域的个数NR 已读的记录数OFS 输出域分隔符ORS 输出记录分隔符RS 控制记录分隔符 12345#统计/etc/passwd:文件名，每行的行号，每行的列数，对应的完整行内容:awk -F: &apos;&#123;print &quot;filename:&quot; FILENAME &quot;,linenumber:&quot; NR &quot;,columns:&quot; NF &quot;,linecontent:&quot;$0&#125;&apos; /etc/passwd#命令行参数个数awk &apos;&#123;print ARGC&#125;&apos; file file2... awk可以做很多事情，赋值，运算，变量等等…具体就不一一说明了，自行搜索. sort基本语法1sort [option] [files...] 选项12345678910111213-b：忽略每行前面开始处的空格字符；-c：检查文件是否已经按照顺序排序，排序过为真；-d：排序时，处理英文字母、数字和空格字符，以字典顺序排序。忽略其他所有字符；-f：排序时，将小写字母视为大写字母；-i：排序时，处理040~176之间的ASCII字符，忽略其他所有字符；-m：将几个排序好的文件进行合并；-M：将前面3个字母按月份的缩写进行排序；-n：按照数值大小进行排序；-o outfile.txt：将排序后的结果存入outfile.txt；-r：以相反的顺序进行排序；-k：指定需要排序的列数（栏数）；就是指定按第几列进行排序-t 分隔符：指定排序时所用到的栏位分隔符；-u 去重 不过一般使用 uniq操作 例如,如下文本 one_two one_two_three one_two_four one_two_five 12### 以下划线为分割 第一第二列进行排序,那么默认第三列会按顺序进行排序，所以结果会被打乱sort -t_ -k1,1 -k2,2 filename [root/shell] ]$sort -t _ -k1,1 -k2,2 cone_twoone_two_fiveone_two_fourone_two_three 12#所以，sort提供了--stable参数来进行补救。sort -t_ -k1,1 -k2,2 filename uniq选项1234567891011-c, --count //在每行前加上表示相应行目出现次数的前缀编号-d, --repeated //只输出重复的行-D, --all-repeated //只输出重复的行，不过有几行输出几行-f, --skip-fields=N //-f 忽略的段数，-f 1 忽略第一段-i, --ignore-case //不区分大小写-s, --skip-chars=N //根-f有点像，不过-s是忽略，后面多少个字符 -s 5就忽略后面5个字符-u, --unique //去除重复的后，全部显示出来，根MySQL的distinct功能上有点像-z, --zero-terminated end lines with 0 byte, not newline-w, --check-chars=N //对每行第N 个字符以后的内容不作对照--help //显示此帮助信息并退出--version //显示版本信息并退出 注意 二点! 1，对文本操作时，它一般会和sort命令进行组合使用，因为uniq 不会检查重复的行，除非它们是相邻的行。如果您想先对输入排序，使用sort -u。 2，对文本操作时，若域中为先空字符(通常包括空格以及制表符)，然后非空字符，域中字符前的空字符将被跳过 fmt文本块操作语法1fmt [option] [file-list] 选项1234-s 截断长行，但不合并-t 除每个段落的第1行外都缩进-u 改变格式化，使字之间出现一个空格，句子之间出现两个空格-w n 将输出的行宽改为n个字符。不带该选项时，fmt输出的行宽度为75个字符 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253例如,我有一个文件demo,内容为:A long time ago, there was a huge apple tree. A little boy loved to come and play around it every day. He climbed to the tree top, ate the apples, took a nap under the shadow… He loved the tree and the tree loved to play with him. 使用命令 fmt -s demo,输出为: A long time ago, there was a huge apple tree. A little boy lovedto come and play around it every day. He climbed to the tree top, atethe apples, took a nap under the shadow… He loved the tree and thetree loved to play with him.该命令的含义是节段2长行. 使用fmt -t demo命令的意思是说排除首行的缩进,结果为:A long time ago, there was a huge apple tree. A little boy loved to come and play around it every day. He climbed to the tree top, ate the apples, took a nap under the shadow… He loved the tree and the tree loved to play with him. 使用fmt -u demo命令的意思是说格式化单词和句子的间隔.输出为:A long time ago, there was a huge apple tree. A little boy loved to comeand play around it every day. He climbed to the tree top, ate the apples,took a nap under the shadow… He loved the tree and the tree loved toplay with him.显然A little boy前面的多个空格变成了两个. 使用命令fmt -w 40 demo意思是说指定行的宽度,这里的行宽为40个字符.所以输出为:A long time ago, there was a hugeapple tree. A little boyloved to come and play around itevery day. He climbed to the tree top,ate the apples, took a nap under theshadow… He loved the tree and thetree loved to play with him. 仅作切割的选项： -s , 在你想将长的行绕回，短的行保持不动时很好用，这么做也能使结果与原始版本间的差异达到最小,例如:fmt -s -w 10 &lt;&lt; EOFone two three four fivesixseveneight输出为:one twothreefour fivesixseveneight fmt的小案例:下面以拼音字典为例：字典文件：/usr/dict/words或者/usr/share/dict/words。sed -n -e 9991,10010p /usr/share/dict/words | fmtsed -n -e 9991,10010p /usr/share/dict/words | fmt -w 30 wc选项1234567-c:统计字节数-l:统计行数-m:统计字符数.这个标志不能与-c标志一起使用-w:统计字数.一个字被定义为由空白,挑个或换行字符分隔的字符串.-L:打印最常行的长度-help:显示帮助信息--version:显示版本信息 seq123-s 指定分隔符，默认是换行-w 等位补全，就是宽度相等，不足的前面补 0-f 格式化输出，就是指定打印的格式 12345seq 1 10 #输出1到10seq -s &quot;--&quot; 1 3 #输出1--2--3seq -w 1 3 #等宽输出seq -f %03g 1 20 #格式化为五位，不足用0补齐# %后面指定数字的位数 默认是%g，%3g那么数字位数不足部分是空格。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ansible基础]]></title>
    <url>%2F2017%2F02%2F25%2Fansible%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[前言Ansible is Simple IT Automation——简单的自动化IT工具，可以实现 批量系统配置、批量程序部署、批量运行命令等功能，简而言之，就是 分布式集中管理工具， 通俗的讲就是批量在远端服务器上执行命令。其实，ansible自身不具备部署能力的，只是提供框架，其核心为模块 什么是ansible? 五大部分 功能 connection plugins 远程连接插件 hosts 定义管理主机或主机组 modules 包含各个核心模块及自定义模块 Plugin 完成模块功能的补充，如日志插件、邮件插件等 Playbook ansible的任务配置文件，将多个任务定义在剧本中进行管理 ​ ​ ​ ansible 的工作流程 ​ ​ ​ 安装ansible1234567891011#配置源 ansible默认不在yum仓库中rpm -iUvh http://ftp.jaist.ac.jp/pub/Linux/Fedora/epel//7/x86_64/e/epel-release-7-9.noarch.rpm#此源主要是为了安装PyYAMLwget http://mirrors.163.com/.help/CentOS7-Base-163.repo mv CentOS7-Base-163.repo /etc/yum.repos.d/yum -y install ansibleansible --version#可查看当前ansible版本 配置登录 ansible 使用ssh登录，所以主奴之间要配置密钥进行认证，这样才能开始正常工作 1234567ssh-keygen -t rsa #回车#将会生成密钥/root/.ssh/id_rsa.pubssh-copy-id -i root@ipaddress #公钥将会被cp到各个ipaddress节点#至此 已经实现了master与各节点的连接 定义Ansible的节点清单12345678910vim /etc/ansible/hosts[testgroup]-----#服务器组的名字，方便统一管理，划分和命名要有规划192.168.1.XX----#组内节点的地址192.168.1.XXX等等[websever]....[DBserver].... 简单的远程操作通过执行who，查看服务器登录信息 12345678910111213141516171819ansible testgroup -m command -a 'who' #组ansible all -m command -a 'who' # 所有ansible 192.168.1.XX -m command -a 'who' #单个ip##192.168.247.152 | SUCCESS | rc=0 &gt;&gt;root :0 2017-02-15 22:33 (:0)root pts/0 2017-02-15 22:34 (:0)root pts/1 2017-02-18 13:08 (192.168.247.1)root pts/2 2017-03-07 22:52 (:0)root pts/3 2017-03-07 22:54 (192.168.247.156)# 以ashin用户身份ping .134ansible 192.168.1.134 -m ping -u zili# 以用户zili身份使用sudo来ping 组testgroup# -K是输入root密码ansible v1 -m ping -u zili --sudo -K 定义变量定义主机变量12345678910[web]192.168.247.152 http_port=80............... http_port=303[mysql]192.168.247.152...#组名以及ip根本自己需求定义#主机指定变量，以便后面供palybooks配置使用。#定义两台web服务器的apache参数http_port，可以让两台服务器产生的apache配置文件httpd.conf差异化 定义组变量123456[web]192.168.247.152[web:vars]http_port=80#组变量的作用域是覆盖组所有成员，通过定义一个新块，块名由组名+ ":vars"组成。 嵌套组12345678910111213141516 [web] 192.168.247.152 [mysql] 192.168.247.152 ... [nested：children] web mysql [nested：vars] ntp_server=s1b.time.edu.cn ##嵌套组定义一个新块，块名由 组名+":chilren" 组成。同是嵌套组也可以定义组变量，作用域是嵌套组里的所有组, 嵌套组只能在/usr/bin/ansible-playbook中，在/usr/bin/ansible中不起作用，下面会介绍playbook 分离主机和组特定数据 为更好的规范定义的主机与组变量，我们实际是不会在hosts里直接写的var，将定义的主机名与组变量单独剥离出来放到指定的文件中，将采用YAML格式存放全局的变量放在group_vars/all中，局部变量放在group_vars/x中，特定的host使用特定的变量可以使用host_vars/x，子group中的变量会覆盖上级变量，hosts变量总是覆盖groups变量存放位置规定：”/etc/ansible/group_vars/名”和”/etc/ansible/host_vars/主机名”分别存放指定组名或主机名定义的变量，如/etc/ansible/group\_vars/mysql.yml/etc/ansible/host\_vars/192.168.11.1.yml使用变量要用jinja语法去引用 123456789cat mysql.yml --- ntp_server: s1b.time.edu.cn database_server: 192.168.247.152##规范变量名字，是因为，ansible会自动加载这目录下的变量，否则无法调用，当然也有解决不放此目录的方法 例如1234567891011121314151617181920212223242526272829303132333435363738394041[root@master ansible]# tree├── create_user.yml├── group_vars│ └── t1.yml├── hosts[root@master ansible]# cat hosts[t1]10.1.27.24所以├── group_vars│ └── t1.yml #他的内容就是t1的变量[root@master ansible]# cat group_vars/t1.yml ---user: ansibleTest1[root@master ansible]# cat create_user.yml # create user---- name: create user hosts: t1 user: root tasks: - name: useradd &#123;&#123; user &#125;&#125; #引用t1变量 user: name=&quot;&#123;&#123; user &#125;&#125;&quot;返回结果如下[root@master ansible]# ansible-playbook create_user.yml PLAY [create user] ***********************************************************************************************************TASK [Gathering Facts] *******************************************************************************************************ok: [10.1.27.24]TASK [useradd ansibleTest1] **************************************************************************************************changed: [10.1.27.24]PLAY RECAP *******************************************************************************************************************10.1.27.24 : ok=2 changed=1 unreachable=0 failed=0 命令参数 ansible [options] 12345678910111213141516171819202122-m MODULE_NAME, --module-name=MODULE_NAME 要执行的模块，默认为 command -a MODULE_ARGS, --args=MODULE_ARGS 模块的参数 -u REMOTE_USER, --user=REMOTE_USER ssh 连接的用户名，默认用 root，ansible.cfg 中可以配置-k, --ask-pass 提示输入 ssh 登录密码，当使用密码验证登录的时候用 -s, --sudo sudo 运行-U SUDO_USER, --sudo-user=SUDO_USER sudo 到哪个用户，默认为 root-K, --ask-sudo-pass 提示输入 sudo 密码，当不是 NOPASSWD 模式时使用-B SECONDS, --background=SECONDS run asynchronously, failing after X seconds(default=N/A)-P POLL_INTERVAL, --poll=POLL_INTERVAL set the poll interval if using-B (default=15)-C, --check 只是测试一下会改变什么内容，不会真正去执行-c CONNECTION 连接类型(default=smart)-f FORKS, --forks=FORKS fork 多少个进程并发处理，默认 5-i INVENTORY, --inventory-file=INVENTORY 指定hosts文件路径默认 default =/etc/ansible/hosts-l SUBSET, --limit=SUBSET 指定一个 pattern，对&lt;host_pattern&gt;已经匹配的主机中再过滤一次--list-hosts 只打印有哪些主机会执行这个 playbook 文件：不是实际执行该 playbook-M MODULE_PATH, --module-path=MODULE_PATH 要执行的模块的路径，默认为/usr/share/ansible/-o, --one-line 压缩输出，摘要输出--private-key=PRIVATE_KEY_FILE 私钥路径-T TIMEOUT, --timeout=TIMEOUT ssh 连接超时时间，默认 10 秒-t TREE, --tree=TREE 日志输出到该目录，日志文件名会以主机名命名-v, --verbose verbose mode (-vvv for more, -vvvv to enable connection debugging) Pattern可以直接指定ip或hosts中的组名，同时指定多个组或者多个ip使用:分割123456789101112131415ansible group1:group2 -m pingansible ip1:ip2 -m ping#all 或者 * 代表全部ansible all -m ping# 感叹号 ! 表示非g1:!g2 #表示在g1分组中，但是不在g2中的hosts# &amp;符号表示交集g1:&amp;g2 #表示在g1分组中，也在g2中的hosts#使用下标g1[2] #组的第三个g1[0:3] #组的前四个 常用模块copy模块12目的：把主控端/root目录下的a.sh文件拷贝到到指定节点上 命令：ansible 192.168.247.152 -m copy -a 'src=/root/a.sh dest=/tmp/ owner=root group=root mode=0755' file模块12目的：更改指定节点上/tmp/t.sh的权限为755，属主和属组为root 命令：ansible all -m file -a "dest=/tmp/t.sh mode=755 owner=root group=root" cron模块12目的：在指定节点上定义一个计划任务，每隔3分钟到主控端更新一次时间 命令：ansible all -m cron -a 'name="custom job" minute=*/3 hour=* day=* month=* weekday=* job="/usr/sbin/ntpdate 192.168.247.152"' group模块12目的：在所有节点上创建一个组名为nolinux，gid为2014的组 命令：ansible all -m group -a 'gid=2014 name=nolinux' uesr模块1234目的：在所有节点上创建一个用户名为nolinux，组为nolinux的用户 命令：ansible all -m user -a 'name=nolinux groups=nolinux state=present'删除用户 命令：ansible all -m user -a 'name=nolinux state=absent remove=yes' yum模块123目的：在指定节点上安装 apache 服务 命令：ansible all -m yum -a "state=present name=httpd"#state=latest 安装最新版本 shell模块12目的：在指定节点上安装 apache 服务 命令：ansible testgroup -m shell -a 'yum -y install httpd' command模块12目的：在指定节点上运行hostname命令命令：ansible 192.168.247.152 -m command -a &apos;hostname&apos; raw模块12目的：在192.168.247.152节点上运行ifconfig命令命令：ansible 192.168.247.152 -m raw-a &apos;ifconfig|eth0&apos; script模块12目的：在指定节点上执行/root/a.sh脚本(该脚本是在ansible主控端) 命令：ansible 10.1.1.113 -m script -a '/root/a.sh' command,script,shell,raw的区别 思考：四者有何区别？ command模块 [执行远程命令]1ansible client -m command -a &quot;uname -n&quot; -s script模块 [在远程主机执行主控端的shell/python脚本] 1ansible client -m script -a &quot;/soft/ntpdate.py&quot; -s shell模块 [执行远程主机的shell/python脚本] 1ansible client -m shell -a &quot;/soft/file.py&quot; -s raw模块 [类似于command模块、支持管道传递] 1ansible client -m raw -a &quot;ifconfig eth0|sed -n 2p|awk &apos;&#123;print \$2&#125;&apos;&quot; -s service模块12目的：启动指定节点上的 httpd 服务，并让其开机自启动 命令：ansible 192.168.247.152 -m service -a 'name=httpd state=restarted enabled=yes' ping模块12目的：检查指定节点机器是否还能连通 命令：ansible 192.168.247.152 -m ping get_url123目的：下载百度下的图标文件到节点的/tmp文件下命令：ansible testgroup -m get_url -a &apos;url=https://www.baidu.com/favicon dest=/tmp&apos;#结果为error.html，但是证明了模块是可用的 stat模块12目的：获取远程文件状态信息，包括atime、ctime、mtime、md5、uid、gid等信息ansible web -m stat -a &apos;path=/etc/sysctl.conf&apos; template模块1template使用了Jinja2格式作为文件模版，进行文档内变量的替换的模块。它的每次使用都会被ansible标记为”changed”状态。 模块参数 参数名 是否必须 默认值 选项 说明 backup no no yes/no 建立个包括timestamp在内的文件备份，以备不时之需. dest yes 远程节点上的绝对路径，用于放置template文件。 group no 设置远程节点上的的template文件的所属用户组 mode no 设置远程节点上的template文件权限。类似Linux中chmod的用法 owner no 设置远程节点上的template文件所属用户 src yes 本地Jinjia2模版的template文件位置 模块参数案例把/mytemplates/foo.j2文件经过填写参数后，复制到远程节点的/etc/file.conf，文件权限相关略过1- template: src=/mytemplates/foo.j2 dest=/etc/file.conf owner=bin group=wheel mode=0644 跟上面一样的效果，不一样的文件权限设置方式1- template: src=/mytemplates/foo.j2 dest=/etc/file.conf owner=bin group=wheel mode=&quot;u=rw,g=r,o=r&quot; 12345678910111213141516#详细说明 roles/templates/server.xml中的template文件关键部分如下： &lt;user username="&#123;&#123; admin_username &#125;&#125;" password="&#123;&#123; admin_password &#125;&#125;" roles="manager-gui" /&gt; #当这个文件还没被template执行的时候，本地的admin_username及admin_password 都是变量状态。 #当playbook执行完template的时候，远程的admin_username*及admin_password 会变成变量所对应的值。 #例 #前面的那个Playbook,如果我们在tomcat-servers设置了这两个变量如下： dmin_username: admin admin_password: adminsecret#那么在执行这个Playbook前，对应的那个template文件（俗称模版），将在本地保持&#123;&#123; admin_username &#125;&#125;及&#123;&#123; admin_password &#125;&#125;的状态。在Ansible调用template模版执行的时候，这里将由Jinjia2从”tomcat-servers”读取对应的值，然后替换掉模版里的变量，然后把这个替换变量值后的文件拷贝到远程节点。#这个就是template的意义所在。 更多模块ansible-doc -l 查询 playbook的配置和使用配置文件后缀名为.yml 官网demo说明1234567891011121314151617181920212223#这个是你选择的主机- hosts: webservers#这个是变量 vars: http_port: 80 max_clients: 200#远端的执行权限 remote_user: root tasks:#利用yum模块来操作 - name: ensure apache is at the latest version yum: pkg=httpd state=latest - name: write the apache config file template: src=/srv/httpd.j2 dest=/etc/httpd.conf#触发重启服务器 notify: - restart apache - name: ensure apache is running service: name=httpd state=started#这里的restart apache 和上面的触发是配对的。这就是handlers的作用。相当于tag handlers: - name: restart apache service: name=httpd state=restarted 123456#有的系统做了sudo限制，所以需要在playbook中开启权限，如下- hosts: web remote_user: vic tasks: - service: name=nginx state=started sudo: yes 脚本实例12345678910111213141516171819202122#create_user.yml- name: create user hosts: testgroup user: root ##facts可以调用client的变量来使用，后面变量里会详细介绍 gather_facts: false vars: - user: "usertest1" tasks: - name: create &#123;&#123; user &#125;&#125; user: name="&#123;&#123; user &#125;&#125;" #返回结果如下[root/] ]$ansible-playbook create_user.ymlPLAY [create user] *************************************************************TASK [create usertest1] ********************************************************ok: [192.168.247.152]PLAY RECAP *********************************************************************192.168.247.152 : ok=1 changed=0 unreachable=0 failed=0 给脚本添加service的调用12345678910111213141516171819202122232425#create_user.yml- name: create user hosts: testgroup user: root gather_facts: false vars: - user: "usertest1" tasks: - name: create &#123;&#123; user &#125;&#125; user: name=&#123;&#123; user &#125;&#125; - name: start httpd service: name=httpd state=startd #添加了httpd服务的开启 #返回结果如下 PLAY [create user] *************************************************************TASK [create usertest2] ********************************************************ok: [192.168.247.152]#可以注意到 TASK [service]显示已经开启了TASK [service] *****************************************************************changed: [192.168.247.152]PLAY RECAP *********************************************************************192.168.247.152 : ok=2 changed=1 unreachable=0 failed=0 给脚本添加copy模块的调用123456789101112131415161718192021222324252627282930313233#create_user.yml- name: create user hosts: testgroup user: root gather_facts: false vars: - user: "usertest1" tasks: - name: create &#123;&#123; user &#125;&#125; user: name=&#123;&#123; user &#125;&#125; - name: start httpd service: name=httpd state=startd #添加了httpd服务的开启 - name: Copy file to client copy: src=/tmp/test.test dest=/tmp/ #添加了copy服务的开启 #返回结果如下[root/ansible_yml] ]$ansible-playbook create_user.ymlPLAY [create user] ************************************************************TASK [create usertest2] *******************************************************ok: [192.168.247.152]TASK [service] ****************************************************************ok: [192.168.247.152]#可以注意到 TASK [copy file to clent]已成功TASK [copy file to clent] *****************************************************changed: [192.168.247.152]PLAY RECAP ********************************************************************192.168.247.152 : ok=3 changed=1 unreachable=0 failed=0 copy传送的时候，可能报错 1234567afewbug | FAILED &gt;&gt; &#123; &quot;checksum&quot;: &quot;4ee72f7427050dcd97068734d35ca7b2c651bc88&quot;, &quot;failed&quot;: true, &quot;msg&quot;: &quot;Aborting, target uses selinux but python bindings (libselinux-python) aren‘t installed!&quot; 是因为ansible需要libselinux-python包。（被控端需要安装libselinux-python**） 可以在copy前先调用yum模块，安装libselinux-python template模板（支持jinja2）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#create_user.yml- name: create user hosts: testgroup user: root gather_facts: false vars: - user: "usertest1" - temp: temptest tasks: - name: create &#123;&#123; user &#125;&#125; user: name=&#123;&#123; user &#125;&#125; - name: start httpd service: name=httpd state=startd #添加了httpd服务的开启 - name: Copy file to client copy: src=/tmp/test.test dest=/tmp/ #添加了copy服务的开启 - name: template test template: src=/tmp/temp dest=/tmp/&#123;&#123;temp&#125;&#125; #&#123;&#123;temp&#125;&#125;变量来自vars #添加了template模板使用 #返回结果[root/ansible_yml] ]$ansible-playbook create_user.ymlPLAY [create user] *************************************************************TASK [create usertest2] ********************************************************ok: [192.168.247.152]TASK [start httpd] *************************************************************ok: [192.168.247.152]TASK [copy file to clent] ******************************************************ok: [192.168.247.152]#可以注意到 返回结果显示成功，去client相关目录即可看到文件TASK [template test] ***********************************************************changed: [192.168.247.152]PLAY RECAP *********************************************************************192.168.247.152 : ok=4 changed=1 unreachable=0 failed=0###template模块可以引用变量到源文件/tmp/temp&#123;&#123;user&#125;&#125;&#123;&#123;temp&#125;&#125;#执行yml后[root/ansible_yml] ]$ansible testgroup -m command -a 'cat /tmp/temptest'192.168.247.152 | SUCCESS | rc=0 &gt;&gt;##client返回的就是主机源文件中引入的变量usertest1temptest 执行外部命令的模块1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#create_user.yml- name: create user hosts: testgroup user: root gather_facts: false vars: - user: "usertest1" - temp: temptest tasks: - name: create &#123;&#123; user &#125;&#125; user: name=&#123;&#123; user &#125;&#125; - name: start httpd service: name=httpd state=startd #添加了httpd服务的开启 - name: Copy file to client copy: src=/tmp/test.test dest=/tmp/ #添加了copy服务的开启 - name: template test template: src=/tmp/temp dest=/tmp/&#123;&#123;temp&#125;&#125; #&#123;&#123;temp&#125;&#125;变量来自vars #添加了template模板使用 - name: run shell shell: /usr/bin/ls /tmp/ || /bin/true #/bin/true 防中断 - name: run command command: mkdir /tmp/command-test #添加了两个执行外部命令模块shell和command#返回结果如下[root/ansible_yml] ]$ansible-playbook create_user.ymlPLAY [create user] *************************************************************TASK [create usertest2] ********************************************************ok: [192.168.247.152]TASK [start httpd] *************************************************************ok: [192.168.247.152]TASK [copy file to client] *****************************************************changed: [192.168.247.152]TASK [template test] ***********************************************************changed: [192.168.247.152]TASK [shell~] ******************************************************************changed: [192.168.247.152]TASK [run this command] ********************************************************changed: [192.168.247.152] [WARNING]: Consider using file module with state=directory rather than runningmkdirPLAY RECAP *********************************************************************192.168.247.152 : ok=6 changed=4 unreachable=0 failed=0####1./usr/bin/...||/bin/true 前面失败的话/bin/true：返回true。防止中断，继续执行。类似的判断还有chenge_when参数 变量功能facts 一个常用的组件，可实现对远程自己系统信息的获取，比如：主机名，IP地址，操作系统，分区情况，硬件信息等，配合playbook使用，更加的灵活和个性化定制 ansible ip/group -m setup可以获取clients的facts信息 123456789101112131415[root~] ]$ansible testgroup -m setup192.168.247.152 | SUCCESS =&gt; &#123; "ansible_facts": &#123; "ansible_all_ipv4_addresses": [ "192.168.122.1", "192.168.247.152" ], "ansible_all_ipv6_addresses": [ "fe80::20c:29ff:feb5:6e6" ], "ansible_architecture": "x86_64", "ansible_bios_date": "07/02/2015", "ansible_bios_version": "6.00", ...... 脚本中开启Facts功能 1234567891011121314151617181920212223242526272829#create_user.yml- name: create user hosts: testgroup user: root gather_facts: false #开启facts tasks: - name: template test template: src=/tmp/temp dest=/tmp/&#123;&#123;temp&#125;&#125; #&#123;&#123;temp&#125;&#125;变量来自vars#返回结果，[root/ansible_yml] ]$ansible-playbook create_user.ymlPLAY [create user] *************************************************************TASK [setup] *******************************************************************ok: [192.168.247.152]TASK [template test] ***********************************************************changed: [192.168.247.152]PLAY RECAP *********************************************************************192.168.247.152 : ok=2 changed=1 unreachable=0 failed=0#查看[root/ansible_yml] ]$ansible testgroup -m raw -a "ls /tmp | grep 192*"192.168.247.152 | SUCCESS | rc=0 &gt;&gt;[u'192.168.122.1', u'192.168.247.152']Shared connection to 192.168.247.152 closed.#IP地址有两个所以文件名很奇怪 当然，我们也可以在主机的/tmp/temp下调用facts变量 1234567891011121314151617181920212223242526272829303132#修改/tmp/temp文件test&#123;&#123;ansible_all_ipv4_addresses&#125;&#125;#create_user.yml- name: create user hosts: testgroup user: root gather_facts: false #开启facts tasks: - name: template test template: src=/tmp/temp dest=/tmp/factstest#结果如下[root/ansible_yml] ]$ansible-playbook create_user.ymlPLAY [create user] *************************************************************TASK [setup] *******************************************************************ok: [192.168.247.152]TASK [template test] ***********************************************************changed: [192.168.247.152]PLAY RECAP *********************************************************************192.168.247.152 : ok=2 changed=1 unreachable=0 failed=0[root/ansible_yml] ]$ansible testgroup -m raw -a "cat /tmp/factstest"192.168.247.152 | SUCCESS | rc=0 &gt;&gt;test[u'192.168.122.1', u'192.168.247.152']Shared connection to 192.168.247.152 closed. 自定义变量 如何facts的变量并不能满足需求的，就可以自定义facts模板来实现 另外可以通过本地facts来实现，只需在client的/etc/ansible/facts.d目录定义JSON,INI或可执行的JSON输出，后缀名一定要用.fact，那么这些文件就可以作为本地的facts ######在client定义变量，供ansible主机使用 12345[root@test1 ~]# mkdir /etc/ansible/facts.d -p[root@test1 ~]# cd /etc/ansible/facts.d/[root@test1 facts.d]# cat client.fact[general]name=zili ansible主机 123456789101112[root/ansible_yml] ]$ansible 192.168.247.152 -m setup -a "filter=ansible_local" 192.168.247.152 | SUCCESS =&gt; &#123; "ansible_facts": &#123; "ansible_local": &#123; #本地facts "client": &#123; #文件名 "general": &#123; #节点名 "name": "zili" #key-value &#125; &#125; &#125; &#125;, "changed": false&#125; 那么就可以通过如下方式去调用自定义的facts变量 12345678910111213141516[root/ansible_yml] ]$ansible-playbook create_user.ymlPLAY [create user] *************************************************************TASK [setup] *******************************************************************ok: [192.168.247.152]TASK [template test] ***********************************************************changed: [192.168.247.152]PLAY RECAP *********************************************************************192.168.247.152 : ok=2 changed=1 unreachable=0 failed=0#调用成功，并可看到client内容已变化[root/ansible_yml] ]$ansible testgroup -m raw -a "cat /tmp/factstest2" 192.168.247.152 | SUCCESS | rc=0 &gt;&gt;zili #Shared connection to 192.168.247.152 closed. 在操作主机定义变量，来控制client思路就是在执行playbook的时候将本地的facts推送到client相关目录下 12345678 - name: create directory for ansible custom facts file: state=directory recurse=yes path=/etc/ansible/facts.d - name: install custom facts copy: src=/etc/ansible/host.fact dest=/etc/ansible/facts.d - name: re-read facts after adding custom fact setup: filter=ansible_local#如此相当于批量在client创建了facts变量#然后就可以主机调用了! 注册变量 变量可以将一条命令的返回值进行保存，然后提供给playbook使用 12345678910[root@ansible ansible]# cat user1.yml- hosts: testgroup remote_user: root tasks: - shell: /usr/bin/foo register: z #注册了一个foo\_resul变量，变量值为shell: /usr/bin/foo的运行结果; ignore_errors: True #ignore\_errors: True为忽略错误 - shell: touch /tmp/LLL #当变量注册完成后，就可以在后面的playbook中使用了 when: z.rc == 5 #当条件语句when: z.rc == 5成立时，shell: touch /tmp/LLL命令才会执行 12345678910111213141516171819202122232425262728293031323334353637383940#可以注意到command是skipping的。因为返回值是127，所以client肯定还是没有创建LLL的[root/ansible_yml] ]$ansible-playbook user1.ymlPLAY [testgroup] ***************************************************************TASK [setup] *******************************************************************ok: [192.168.247.152]TASK [command] *****************************************************************fatal: [192.168.247.152]: FAILED! =&gt; &#123;"changed": true, "cmd": "/usr/bin/foo", "delta": "0:00:00.003488", "end": "2017-03-11 13:08:45.996549", "failed": true, "rc": 127, "start": "2017-03-11 13:08:45.993061", "stderr": "/bin/sh: /usr/bin/foo: No such file or directory", "stdout": "", "stdout_lines": [], "warnings": []&#125;...ignoringTASK [command] *****************************************************************skipping: [192.168.247.152]PLAY RECAP *********************************************************************192.168.247.152 : ok=2 changed=1 unreachable=0 failed=0##所以我门修改z.rc的返回值为127在执行#以为返回值是对的，所以执行了touch，warning是友情提示，最好用线管模块进行文件的操作[root/ansible_yml] ]$ansible-playbook user1.ymlPLAY [testgroup] ***************************************************************TASK [setup] *******************************************************************ok: [192.168.247.152]TASK [command] *****************************************************************fatal: [192.168.247.152]: FAILED! =&gt; &#123;"changed": true, "cmd": "/usr/bin/foo", "delta": "0:00:00.003539", "end": "2017-03-11 13:11:01.955975", "failed": true, "rc": 127, "start": "2017-03-11 13:11:01.952436", "stderr": "/bin/sh: /usr/bin/foo: No such file or directory", "stdout": "", "stdout_lines": [], "warnings": []&#125;...ignoringTASK [command] *****************************************************************changed: [192.168.247.152] [WARNING]: Consider using file module with state=touch rather than running touchPLAY RECAP *********************************************************************192.168.247.152 : ok=3 changed=2 unreachable=0 failed=0[root/ansible_yml] ]$ 语句条件语句 playbook的执行结果取决于变量，不管是facts还是tasks结果赋值的，而变量的值可以依赖于其他变量，当然一会印象ansible的执行 有时候我们，想要跳过某些主机的执行步骤，比如，某些client不安装某个软件包，不清理垃圾等等 就要使用判断了 when123456789- name: when hosts: testgroup remote_user: root gather_facts: true tasks: - name: shutdown centos command: /sbin/shutdown -t now when: ansible_hostname == 'test1'#when返回bool值，为true是执行，false则不执行 when 针对不同分支的二级处理 123456789101112131415161718- name: when hosts: web remote_user: root gather_facts: true tasks: - command: /sbin/ip a register: result ignore_errors: True - command: /bin/something when: result|failed - command: /bin/something_else when: result|success - command: /bin/still/something_else when: result|skipped # when: result|success"的意思为当变量result执行结果为成功#将执行/bin/something_else命令，其他同理。#其中success为Ansible内部过滤器方法，返回True代表命令运行成功。 循环语句12345678910111213141516171819202122- name: whell hosts: testgroup remote_user: root gather_facts: true tasks: - name: "add user" user: name=&#123;&#123; item &#125;&#125; state=present groups=wheel with_items: - tiger1 - tiger2 #创建用户的。with_items会自动循环执行上面的语句"user: name=&#123;&#123; item &#125;&#125; state=present groups=wheel"，循环的次数为with_items的元素个数。这里有2个元素，分别为tiger1、tiger2，会分别替换&#123;&#123; item &#125;&#125;项#等同于- name: whell hosts: testgroup remote_user: root gather_facts: true tasks: - name: "add user tiger1" user: name=tiger1 state=present groups=wheel - name: "add user tiger2" user: name=tiger2 state=present groups=wheel 循环元素支持列表12345678910111213141516171819#首先定义好列表 list.ymlpackages_base: - [ 'vsftpd', 'vim' ]packages_apps: - [[ 'mysql',httpd' ]]#然后引入使用- name: whell hosts: testgroup remote_user: root gather_facts: true var_files: - /etc/ansible/list.yml tasks: - name: "install rpm" yum: name=&#123;&#123; item &#125;&#125; state=installed with_flattened: #此语句 用来循环定义好的列表 - packages_base - packages_apps handlers 和 include 当多个playbook涉及复用的任务列表时，可以将复用的内容剥离出来，写到独立的文件里，需要的地方include进来即可 除了tasks之外，还有一个handlers的命令，handlers是在执行tasks之后服务器发生变化之后可供调用的handler 123456789101112131415161718- name: write the httpd config file hosts: testgroup remote_user: root gather_facts: true tasks: - name: write the httpd.conf to client template: src=/httpd.conf.j2 dest=/etc/httpd/conf/httpd.conf notify: # 如果copy执行完之后/etc/httpd/conf/httpd.conf文件发送了变化，则执行 - restart httpd # 调用handler - include: playbook/tasks/httpd.yml handlers: - name: restart httpd #此处的标识必须和notify一样才可以引起触发 service: name=httpd state=restarted #注意上面使用的- include: playbook/tasks/httpd.yml，看一下这个文件的内容- name: ensure httpd is running service: name=httpd state=started notify这个action可用于在每个play的最后被触发，这样可以避免多次有改变发生时每次都执行指定的操作，取而代之，仅在所有的变化发生完成后一次性地执行指定操作。 Handlers 是由通知者进行 notify, 如果没有被 notify,handlers 不会执行。 Handlers 最佳的应用场景是用来重启服务,或者触发系统重启操作.除此以外很少用到了。 roles 使用前面的所有都在一个文件内.还有一种方法可以进行更好的组织架构使用roles12345678910111213141516171819202122232425[root@master roles]# tree.├── test│ └── tasks│ └── main.yml└── test.ymltest.yml为入口文件,每次执行它即可.他的内容如下[root@master roles]# cat test.yml ---- hosts: all roles: - role: test定义了主机/主机组,然后定义了要使用的roles,(也就是roles下的文件夹的名字)test文件夹下定义了tasks,内有 **main.yml** 这个命名是规定好的.必须是mainmain.yml 书写了tasks的任务.[root@master roles]# cat test/tasks/main.yml ---- name: test role ping ping:[root@master roles]# 结果如下:123456789101112131415[root@master roles]# ansible-playbook test.yml PLAY [all] ************************************************************************************TASK [Gathering Facts] ************************************************************************ok: [10.1.27.28]ok: [10.1.27.24]TASK [test : test role ping] ******************************************************************ok: [10.1.27.28]ok: [10.1.27.24]PLAY RECAP ************************************************************************************10.1.27.24 : ok=2 changed=0 unreachable=0 failed=0 10.1.27.28 : ok=2 changed=0 unreachable=0 failed=0 roles有很多结构,ansible可以根据其进行解析. 1234567├── defaults├── files├── handlers├── meta├── tasks├── templates└── vars 如果roles/x/tasks/main.yml存在,则自动将里面的tasks添加到play中。如果roles/x/handlers/main.yml存在,则自动将里面的handlers添加到play中。如果roles/x/vars/main.yml存在, 则自动将其中的variables添加到play中。如果roles/x/meta/main.yml存在,则添加role的依赖关系roles中。任何copy任务、script任务都可以引用roles/x/files中的文件，无论是使用绝对或相对路径都可以。任何template任务都可以引用roles/x/templates中的文件，无论绝对或相对路径。任何include任务都可以引用roles/x/tasks/中的文件，无论相对或绝对路径 具体可以参见文档：http://docs.ansible.com/playbooks_intro.html ansible和saltstack的对比 1、salt要安装agent , ansible通过ssh连接。 2、salt在server端要启进程；ansible不需要。 3、salt与ansible都有模块，可使用任意语言开发模块。 4、salt与ansible都使用yaml语言格式编写剧本。 ansible走的是ssh,所以它有认证以及加密码的过程，使得ansible非常慢，不适用于大规模环境（指上千台）]]></content>
      <categories>
        <category>运维工具</category>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx+tomcat+redis实现负载与session]]></title>
    <url>%2F2017%2F02%2F20%2Fnginx-tomcat-redis%E5%AE%9E%E7%8E%B0%E8%B4%9F%E8%BD%BD%E4%B8%8Esession%2F</url>
    <content type="text"><![CDATA[可实现nginx的负载,session共享,后台健康检测,以达到故障后实现快速切换安装需要准备的包 12345678commons-pool2-2.2.jarjedis-2.7.2.jartomcat-redis-session-manage-tomcat7.jar#目前上面这些组件不支持tomcat8.0apache-tomcat-7.0.75.tar.gzjdk-8u45-linux-x64.tar.gz #用以支持JAVAnginx-1.7.8.tar.gznginx_upstream_check_module-master.zip #后台健康监测插件，需要安装Nginx时编译进去 YUM源为epel 规划—(测试机的配置基本一致，本文只书写其一) IP 备注 192.168.247.151 Nginx+Redis 192.168.247.152 tomcat（test1） 192.168.247.153 tomcat（test2） 192.168.247.151 安装Nginx为了支持Nginx的rewrite功能，首先安装pcre*模块 1yum -y install pcre* 为了进行后台的健康检测，所以下载淘宝的检测插件，安装Nginx直接编译进去 /usr/local/src nginx_upstream_check_module-master.zip 和nginx-1.7.8.tar.gz 123456unzip nginx_upstream_check_module-master.ziptar -zxvf nginx-1.7.8.tar.gzcd nginx-1.7.8./configure --prefix=/usr/local/nginx --with-http_ssl_module --with-http_spdy_module --with-http_stub_status_module --with-pcre --add-module=/usr/local/src/nginx_upstream_check_module-mastermakemake install 注意：如果是Nginx安装后进行的编译 1234567cd nginx-1.7.8patch -p1 &lt; ../nginx_http_upstream_check_module/check_1.7.?+.patch #版本根据Nginx选择./configure --prefix=/usr/local/nginx --with-http_ssl_module --with-http_spdy_module --with-http_stub_status_module --with-pcre --add-module=/usr/local/src/nginx_upstream_check_module-mastermake #千万不能 make install 不然就真的覆盖了mv /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx-1.7.0.bakcp ./objs/nginx /usr/local/nginx/sbin//usr/local/nginx/sbin/nginx #启动Nginx 配置Nginx/usr/local/nginx/conf/nginx.conf 123456789101112131415161718192021222324252627282930313233343536373839http &#123; include mime.types; default_type application/octet-stream; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #access_log logs/access.log main; sendfile on; keepalive_timeout 65; #开启负载均衡，指向后台tomcat集群 upstream test &#123; server 192.168.247.152:8080; server 192.168.247.153:8080; #开启健康检测机制 check interval=3000 rise=2 fall=5 timeout=1000 type=http; check_http_send &quot;HEAD /test HTTP/1.0\r\n\r\n&quot;; check_http_expect_alive http_2xx http_3xx; &#125; server&#123; listen 80; #server_name test.test.com; #设置域名 #健康检测界面 location = /nstatus &#123; check_status; access_log off; allow all; &#125; #测试页面 自己在tomcat上新建的 location /test &#123; proxy_pass http://test; proxy_set_header Host $host; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125;&#125; 启动Nginx 输入健康检测地址即可看到后台tomcat状态 安装Redis 实现session共享下载redis包官网http://redis.io 注：redis的test需要tcl的支持，所以可先检查下是否安装了tcl 12345yum - y installwget http://download.redis.io/redis-stable.tar.gztar –zxvf redis-stable.tar.gzcd redis-stablemake 完毕后 src下会多出几个文件 redis-benchmark redis-check-aof redis-check-rdb redis-cli redis-sentinel redis-server 可手动将其复制到/usr/local/bin目录下，也可执行make install 此处选择make install 1make install 注意：若此时执行redis-server –v (查看版本命令)，若提示redis-server command not found，则需要将/usr/local/bin目录加到环境变量，如何添加，此处不做详细介绍，可查看修改/etc/profile，(查看环境变量命令：echo $PATH) redis安装完毕 修改redis配置文件创建redis目录用以存放redis 日志 数据库 进程 1mkdir -p /var/redis/&#123;data,log,run&#125; 拷贝解压包下的redis.conf文件至/etc/redis 12cp -p /usr/local/src/redis-stable/redis.conf /etc/redis.confvim /etc/redis.conf 12345678port 6379daemonize yes #开启后台进程pidfile /var/redis/run/6379.pidlogfile /var/redis/log/redis.logdbfilename dump.rdbdir /var/redis/data #数据库路径 默认是./requirepass centos #设置密码为centos#bind 127.0.0.1 默认是开启的，只允许本地登陆，所以，要不添加IP，要不给注释了 启动redis 123456789redis-server /etc/redis.confps -aux | grep redisredis-cli #客户端连接，进入redisAUTH centos #密码认证SHUTDOWNexitservice redis start 设置redis开机启动12cp -p /usr/local/src/redis-stable/utils/redis_init_script /etc/init.d/redisll #看有没有执行权限 修改脚本的pid,conf等路径,添加开机启动权限 12345678910111213141516#开机启动#chkconfig: 2345 90 10#description: Redis is a persistent ket-value database#added by zili on 20170218 REDISPORT=6379EXEC=/usr/local/bin/redis-serverCLIEXEC=/usr/local/bin/redis-cliPIDFILE=/var/redis/run/6379.pidCONF=&quot;/etc/redis.conf&quot;...#如果是在生产环境，那么就规划好端口等，尽量使用变量去实现，加以区分比如PIDFILE=/var/redis/run/$&#123;REDISPORT&#125;.pidCONF=&quot;/etc/redis_$&#123;REDISPORT&#125;.conf&quot; 12service redis star | stop #等均可使用了，不能使用就查看权限 llchkconfig redis on 192.168.254.152/153 安装tomcattomcat 安装依赖JAVA的JDK 所以判断JDK是否安装并进行安装 1rpm -qa | grep java 删除openjdk1rpm -e --nodeps java-1.7....... # -e 删除 --nodeps强行删除 下载 jdk-8u45-linux-x64.tar.gz 解压 到 /usr/java/ 配置全局变量 vim /etc/profile 在末尾添家，注意路径！特别是JDK文件名字 123456export RUN_AS_USER=rootexport JAVA_HOME=/usr/local/jdk1.8.0_45export CLASS_HOME=/usr/local/jdk1.8.0_45/lib:$JAVA_HOME/jre/lib#export JRE_HOME=/usr/local/jdk1.8.0_45/jreexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib:$CLASSPATHexport PATH=$PATH:$JAVA_HOME/bin 1java -version #不报错，能看版本，安装成功 下载tomcat包 apache-tomcat-7.0.75.tar.gz （注意redis组件目前不支持tomcat8.0） 以及三个是jar插件 commons-pool2-2.2.jar jedis-2.7.2.jar tomcat-redis-session-manage-tomcat7.jar 解压 tomcat安装包 到/usr/local/tomcat 1234tar -zxvf apache-tomcat-7.0.75.tar.gz mv apache-tomcat-7.0.75 /usr/local/tomcatmv 3个插件 /usr/local/tomcat/lib/usr/local/tomcat/bin/startup.sh 浏览器即可访问tomcat 默认端口8080 tomcat配置manager-gui等配置,去conf文件下修改 tomcat-users.xml 添加相应权限 注！只可以本地访问manager 12345678910 &lt;role rolename="tomcat"/&gt; &lt;role rolename="role1"/&gt; &lt;user username="tomcat" password="tomcat" roles="tomcat"/&gt; &lt;user username="both" password="tomcat" roles="tomcat,role1"/&gt; &lt;user username="role1" password="tomcat" roles="role1"/&gt; &lt;role rolename="admin"/&gt; &lt;role rolename="admin-gui"/&gt; &lt;role rolename="manager-gui"/&gt; &lt;user username="vic" password="tomcat" roles="manager-gui,admin-gui,admin"/&gt;&lt;/tomcat-users&gt; 重启生效 编辑test下的测试页面 主要测试session 1234567891011121314151617&lt;%@ page language="java" %&gt;&lt;html&gt; &lt;head&gt;&lt;title&gt;152&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;font color="green"&gt;152&lt;/font&gt;&lt;/h1&gt; &lt;table align="centre" border="1"&gt; &lt;tr&gt; &lt;td&gt;Session ID&lt;/td&gt; &lt;% session.setAttribute("tomcat.suzf.net","tomcat.suzf.net"); %&gt; &lt;td&gt;&lt;%= session.getId() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Created on&lt;/td&gt; &lt;td&gt;&lt;%= session.getCreationTime() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt;&lt;/html&gt; session共享保存设置1vim /usr/local/tomcat/conf/context.xml 12345678&lt;Valve className=&quot;com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve&quot; /&gt; &lt;Manager className=&quot;com.orangefunction.tomcat.redissessions.RedisSessionManager&quot; host=&quot;192.168.247.151&quot; &lt;!-- Redis地址 --&gt; port=&quot;6379&quot; &lt;!-- Redis端口 --&gt; password=&quot;centos&quot; &lt;!-- Redis密码 --&gt; database=&quot;0&quot; &lt;!-- 存储Session的Redis库编号 --&gt; maxInactiveInterval=&quot;60&quot; &lt;!-- Session失效的间隔（秒） --&gt;/&gt; 重启生效 如若出现500错误 查看防火墙，selinux，iptables等以及redis是否启动 完毕]]></content>
      <categories>
        <category>web</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows常用命令]]></title>
    <url>%2F1111%2F11%2F11%2Fwindows%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[wmic先决条件a. 启动Windows Management Instrumentation服务，开放TCP135端口。b. 本地安全策略的“网络访问: 本地帐户的共享和安全模式”应设为“经典-本地用户以自己的身份验证”。 wmic /node:”192.168.1.20” /user:”domain\administrator” /password:”123456” 硬件信息(管理)获取磁盘资料：wmic DISKDRIVE get deviceid,Caption,size,InterfaceType 获取分区资料：wmic LOGICALDISK get name,Description,filesystem,size,freespace 获取CPU资料:wmic cpu get name,addresswidth,processorid 获取主板资料:wmic BaseBoard get Manufacturer,Product,Version,SerialNumber 获取内存数:wmic memlogical get totalphysicalmemory 获得品牌机的序列号:wmic csproduct get IdentifyingNumber 获取声卡资料:wmic SOUNDDEV get ProductName 获取屏幕分辨率wmic DESKTOPMONITOR where Status=&#39;ok&#39; get ScreenHeight,ScreenWidth PROCESS(进程管理)：列出进程wmic process list brief(Full显示所有、Brief显示摘要、Instance显示实例、Status显示状态) wmic 获取进程路径:wmic process where name=&quot;jqs.exe&quot; get executablepath wmic 创建新进程 123wmic process call create notepadwmic process call create &quot;C:\Program Files\Tencent\QQ\QQ.exe&quot; wmic process call create &quot;shutdown.exe -r -f -t 20&quot; wmic 删除指定进程: 123wmic process where name=&quot;qq.exe&quot; call terminate wmic process where processid=&quot;2345&quot; delete wmic process 2345 call terminate wmic 删除可疑进程 123wmic process where &quot;name=&apos;explorer.exe&apos; and executablepath&lt;&gt;&apos;%SystemDrive%\windows\explorer.exe&apos;&quot; deletewmic process where &quot;name=&apos;svchost.exe&apos; and ExecutablePath&lt;&gt;&apos;C:\WINDOWS\system32\svchost.exe&apos;&quot; call Terminate USERACCOUNT(账号管理)：更改当前用户名 123WMIC USERACCOUNT where &quot;name=&apos;%UserName%&apos;&quot; call rename newUserName WMIC USERACCOUNT create /? SHARE(共享管理)：建立共享 WMIC SHARE CALL Create &quot;&quot;,&quot;test&quot;,&quot;3&quot;,&quot;TestShareName&quot;,&quot;&quot;,&quot;c:\test&quot;,0(可使用 WMIC SHARE CALL Create /? 查看create后的参数类型) 删除共享WMIC SHARE where name=&quot;C$&quot; call deleteWMIC SHARE where path=&#39;c:\\test&#39; delete SERVICE(服务管理)：更改telnet服务启动类型[Auto|Disabled|Manual]wmic SERVICE where name=&quot;tlntsvr&quot; set startmode=&quot;Auto&quot; 运行telnet服务wmic SERVICE where name=&quot;tlntsvr&quot; call startservice 停止ICS服务wmic SERVICE where name=&quot;ShardAccess&quot; call stopservice 删除test服务wmic SERVICE where name=&quot;test&quot; call delete FSDIR(目录管理)列出c盘下名为test的目录wmic FSDIR where &quot;drive=&#39;c:&#39; and filename=&#39;test&#39;&quot; list 删除c:\good文件夹wmic fsdir &quot;c:\\test&quot; call delete 重命名c:\test文件夹为abcwmic fsdir &quot;c:\\test&quot; rename &quot;c:\abc&quot;wmic fsdir where (name=&#39;c:\\test&#39;) rename &quot;c:\abc&quot; 复制文件夹wmic fsdir where name=&#39;d:\\test&#39; call copy &quot;c:\\test&quot; datafile(文件管理)重命名wmic datafile &quot;c:\\test.txt&quot; call rename c:\abc.txt 任务计划：wmic job call create &quot;notepad.exe&quot;,0,0,true,false,********154800.000000+480wmic job call create &quot;explorer.exe&quot;,0,0,1,0,********154600.000000+480 自动脚本12345678910111213141516171819202122@echo off::get os datawmic os get Caption,Version,SerialNumber,InstallDate /valueecho ---:: get ip datawmic nicconfig where &quot;IPEnabled = True&quot; get Description,DefaultIPGateway,IPAddress,IPSubnet,MACAddress /valueecho ---:: get system datawmic COMPUTERSYSTEM get Name,NumberOfLogicalProcessors,NumberOfProcessors,TotalPhysicalMemory /valueecho ---:: get cpu datawmic CPU get NAME,DeviceID /valueecho ---:: get phydisk datawmic diskdrive get serialnumber,DeviceID,Size /valueecho ---:: get logicaldisk datawmic logicaldisk get DeviceID,FreeSpace,Size,VolumeSerialNumber /value::wmic nicconfig where &quot;IPEnabled = True&quot; get Description,DefaultIPGateway,IPAddress,IPSubnet,MACAddress /value|findstr [1-9]:: 可去除不相关的回车换行等 cmd(bat)取ip123@echo off for /f &quot;tokens=2 delims=:&quot; %%b in (&apos;ipconfig^|find /i &quot;ip&quot;&apos;) do set minion=%%becho %minion% powershell获取系统硬件信息1234567891011121314$os_version=Get-CimInstance -ClassName Win32_OperatingSystem | Select-Object -ExpandProperty Caption$os_kernel=Get-CimInstance -ClassName Win32_OperatingSystem | Select-Object -ExpandProperty version$cpu_model=Get-CimInstance Win32_processor | Select-Object -ExpandProperty name -Unique$cpu_num=(Get-CimInstance Win32_processor | Select-Object -ExpandProperty name).count$cpu_core=(Get-CimInstance Win32_processor | Select-Object -ExpandProperty processorid).count$mem_total=(get-CimInstance -class Win32_PhysicalMemory -namespace &quot;root\cimv2&quot;).Capacity$disk_total=Get-CimInstance -class win32_logicaldisk | Measure-Object -Sum size | Select-Object -ExpandProperty sum$product_id=Get-CimInstance -ClassName Win32_OperatingSystem | Select-Object -ExpandProperty SerialNumber$os_info = @&quot;&#123;&quot;os_sys&quot;:&quot;Windows&quot;,&quot;os_version&quot;:&quot;$os_version&quot;,&quot;os_kernel&quot;:&quot;$os_kernel&quot;,&quot;cpu_model&quot;:&quot;$cpu_model&quot;,&quot;cpu_num&quot;:&quot;$cpu_num&quot;,&quot;cpu_core&quot;:&quot;$cpu_core&quot;,&quot;mem_total&quot;:&quot;$mem_total&quot;,&quot;disk_total&quot;:&quot;$disk_total&quot;,&quot;product_id&quot;:&quot;$product_id&quot;&#125;&quot;@$os_info]]></content>
      <categories>
        <category>windows</category>
      </categories>
      <tags>
        <tag>-个人备忘手册</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux个人备忘手册]]></title>
    <url>%2F1111%2F11%2F11%2Flinux%E4%B8%AA%E4%BA%BA%E5%A4%87%E5%BF%98%E6%89%8B%E5%86%8C%2F</url>
    <content type="text"><![CDATA[一些小命令的记录 按当前日期命名文件1234567创建备份Shell脚本:输入/粘贴以下内容：#!/bin/bashmysqldump -uusername -ppassword DatabaseName &gt; /home/backup/DatabaseName_$(date +%Y%m%d_%H%M%S).sql对备份进行压缩：#!/bin/bashmysqldump -uusername -ppassword DatabaseName | gzip &gt; /home/backup/DatabaseName_$(date +%Y%m%d_%H%M%S).sql.gz 定时备份1234#!/usr/bin/bashcd /var/log/tar -zcf /var/log/haproxy_log_bk/$(date +%Y%m%d_%H%M%S).tar.gz haproxy.logecho &quot;&quot; &gt; haproxy.log -mtime1234567891011查找 并移动3天前的find /net-log/ -mtime +3 -name &quot;*.log&quot; -exec mv &#123;&#125; /tmp/ \;删除find /net-log/ -mtime +3 -name &quot;*.log&quot; -exec rm -rf &#123;&#125; \;命令可写到定时任务中,对长时间不读取文件进行删除crontab -e* * * * * + 程序 +命令或脚本#如果是bash命令 可直接写.例:每天0点执行test.py0 0 * * * /usr/bin/python3 /script/test.py ssh快捷登录12345678910zili@Ubuntu:~$ cat ~/.ssh/configServerAliveInterval 60 #60S发送一次存活信息,以免断开Host studyUser rootHostname 10.1.1.11Port 21131#默认为22 有修改则填写#若有多个主机,直接复制修改即可zili@Ubuntu:~$ ssh studyroot@10.1.1.11&apos;s password: mysql开启远程GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;youpassword&#39; WITH GRANT OPTION; 12345678910111213141516171819202122232425262728293031mysql&gt; select user,host from mysql.user;+--------+-----------+| user | host |+--------+-----------+| root | 127.0.0.1 || root | localhost |+--------+-----------+mysql&gt; show status like &apos;Threads%&apos;;+-------------------+-------+| Variable_name | Value |+-------------------+-------+| Threads_cached | 58 || Threads_connected | 57 | ###这个数值指的是打开的连接数| Threads_created | 3676 || Threads_running | 4 | ###这个数值指的是激活的连接数，这个数值一般远低于connected数值+-------------------+-------+Threads_connected 跟show processlist结果相同，表示当前连接数。准确的来说，Threads_running是代表当前并发数这是是查询数据库当前设置的最大连接数mysql&gt; show variables like &apos;%max_connections%&apos;;+-----------------+-------+| Variable_name | Value |+-----------------+-------+| max_connections | 1000 |+-----------------+-------+可以在/etc/my.cnf里面设置数据库的最大连接数[mysqld]max_connections = 10000 开启snmpyum –y install net-snmp net-snmp-devel若要使用snmpwalk进行安装检测，则还需要yum –y install net-snmp-utils vi /etc/snmp/snmpd.conf把62行中的systemview改为mib2把89行的#去掉。 然后在最后一行添加rwcommunity ge.保存退出。 防火墙添加策略,重启服务即可snmpwalk -v 2c -c public localhost sysName.0可做验证,默认社区号是public若需要修改则41行中public`换为指定字符串即可 openssl自签Key是私用秘钥，通常是RSA算法Csr是证书请求文件，用于申请证书。在制作csr文件时，必须使用自己的私钥来签署申，还可以设定一个密钥。crt是CA认证后的证书文，签署人用自己的key给你签署凭证。1234567891011# 生成一个RSA密钥openssl genrsa -des3 -out 33iq.key 1024# 拷贝一个不需要输入密码的密钥文件openssl rsa -in 33iq.key -out 33iq_nopass.key# 生成一个证书请求openssl req -new -key 33iq.key -out 33iq.csr# 自己签发证书openssl x509 -req -days 365 -in 33iq.csr -signkey 33iq.key -out 33iq.crt pip源更换pip国内的一些镜像 - 阿里云 http://mirrors.aliyun.com/pypi/simple/ - 中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/ - 豆瓣(douban) http://pypi.douban.com/simple/ - 清华大学 https://pypi.tuna.tsinghua.edu.cn/simple/ - 中国科学技术大学 http://pypi.mirrors.ustc.edu.cn/simple/ 临时使用：可以在使用pip的时候在后面加上-i参数，指定pip源pip install scrapy -i https://pypi.tuna.tsinghua.edu.cn/simple 永久修改： linux: 修改 ~/.pip/pip.conf (没有就创建一个)，如下：12[global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple shell保留最近的N个文件cd 指定目录 &amp;&amp; ls -lt | awk &#39;{if(NR&gt;=11){print $9}}&#39; | xargs rm -f shell for循环计数比对1234567891011121314151617181920212223get_disk()&#123; i=1 for line in `iostat -d | awk -F &quot; *&quot; &apos;&#123;print $1&#125;&apos;`;do i=$((i+1)) done ii=1 printf &quot;&#123;\n&quot; printf &quot;\t\&quot;data\&quot;:[\n&quot; for line in `iostat -d | awk -F &quot; *&quot; &apos;&#123;print $1&#125;&apos;`;do ii=$((ii+1)) disk=$line if [ &quot;$ii&quot; == $i ]; then printf &quot;\t&#123;\t\t\&quot;&#123;#DISK&#125;\&quot;:\&quot;$disk\&quot;\t&#125;&quot;; else printf &quot;\t&#123;\t\t\&quot;&#123;#DISK&#125;\&quot;:\&quot;$disk\&quot;\t&#125;,&quot;; fi done printf &quot;\n\t]\n&quot; printf &quot;&#125;\n&quot;&#125;echo $(get_disk) shell 统计指定文件ip数12345678910111213141516171819在/tmp下有大量文件access1.log,access2.log...，内容格式为:时间 IP,例:a1.log2018-01-01 127.0.0.12018-01-02 127.0.0.12018-01-02 127.0.0.12018-01-02 10.10.2.22018-01-03 192.168.1.1......取出最后十个文件,文件内容去重,并统计重复IP数,取第四行,存入count中!/bin/bashfor filename in find /tmp-type f -name &quot;access*.log&quot; | tail -n 10do sed -n &apos;4p&apos; $filename | awk &apos;&#123;print $2&#125;&apos; | uniq -c &gt;&gt;countdone shell 系统判断123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123#!/bin/bashcheck_os_release()&#123; while true do os_release=$(grep &quot;Red Hat Enterprise Linux Server release&quot; /etc/issue 2&gt;/dev/null) os_release_2=$(grep &quot;Red Hat Enterprise Linux Server release&quot; /etc/redhat-release 2&gt;/dev/null) if [ &quot;$os_release&quot; ] &amp;&amp; [ &quot;$os_release_2&quot; ] then if echo &quot;$os_release&quot;|grep &quot;release 5&quot; &gt;/dev/null 2&gt;&amp;1 then os_release=redhat5 echo &quot;$os_release&quot; elif echo &quot;$os_release&quot;|grep &quot;release 6&quot; &gt;/dev/null 2&gt;&amp;1 then os_release=redhat6 echo &quot;$os_release&quot; elif echo &quot;$os_release&quot;|grep &quot;release 7&quot; &gt;/dev/null 2&gt;&amp;1 then os_release=redhat7 echo &quot;$os_release&quot; else os_release=&quot;&quot; echo &quot;$os_release&quot; fi break fi os_release=$(grep &quot;Aliyun Linux release&quot; /etc/issue 2&gt;/dev/null) os_release_2=$(grep &quot;Aliyun Linux release&quot; /etc/aliyun-release 2&gt;/dev/null) if [ &quot;$os_release&quot; ] &amp;&amp; [ &quot;$os_release_2&quot; ] then if echo &quot;$os_release&quot;|grep &quot;release 5&quot; &gt;/dev/null 2&gt;&amp;1 then os_release=aliyun5 echo &quot;$os_release&quot; elif echo &quot;$os_release&quot;|grep &quot;release 6&quot; &gt;/dev/null 2&gt;&amp;1 then os_release=aliyun6 echo &quot;$os_release&quot; elif echo &quot;$os_release&quot;|grep &quot;release 7&quot; &gt;/dev/null 2&gt;&amp;1 then os_release=aliyun7 echo &quot;$os_release&quot; else os_release=&quot;&quot; echo &quot;$os_release&quot; fi break fi os_release_2=$(grep &quot;CentOS&quot; /etc/*release 2&gt;/dev/null) if [ &quot;$os_release_2&quot; ] then if echo &quot;$os_release_2&quot;|grep &quot;release 5&quot; &gt;/dev/null 2&gt;&amp;1 then os_release=centos5 echo &quot;$os_release&quot; elif echo &quot;$os_release_2&quot;|grep &quot;release 6&quot; &gt;/dev/null 2&gt;&amp;1 then os_release=centos6 echo &quot;$os_release&quot; elif echo &quot;$os_release_2&quot;|grep &quot;release 7&quot; &gt;/dev/null 2&gt;&amp;1 then os_release=centos7 echo &quot;$os_release&quot; else os_release=&quot;&quot; echo &quot;$os_release&quot; fi break fi os_release=$(grep -i &quot;ubuntu&quot; /etc/issue 2&gt;/dev/null) os_release_2=$(grep -i &quot;ubuntu&quot; /etc/lsb-release 2&gt;/dev/null) if [ &quot;$os_release&quot; ] &amp;&amp; [ &quot;$os_release_2&quot; ] then if echo &quot;$os_release&quot;|grep &quot;Ubuntu 10&quot; &gt;/dev/null 2&gt;&amp;1 then os_release=ubuntu10 echo &quot;$os_release&quot; elif echo &quot;$os_release&quot;|grep &quot;Ubuntu 12.04&quot; &gt;/dev/null 2&gt;&amp;1 then os_release=ubuntu1204 echo &quot;$os_release&quot; elif echo &quot;$os_release&quot;|grep &quot;Ubuntu 12.10&quot; &gt;/dev/null 2&gt;&amp;1 then os_release=ubuntu1210 echo &quot;$os_release&quot; elif echo &quot;$os_release&quot;|grep &quot;Ubuntu 14.04&quot; &gt;/dev/null 2&gt;&amp;1 then os_release=ubuntu1204 echo &quot;$os_release&quot; elif echo &quot;$os_release&quot;|grep &quot;Ubuntu 16.04&quot; &gt;/dev/null 2&gt;&amp;1 then os_release=ubuntu1604 echo &quot;$os_release&quot; else os_release=&quot;&quot; echo &quot;$os_release&quot; fi break fi os_release=$(grep -i &quot;debian&quot; /etc/issue 2&gt;/dev/null) os_release_2=$(grep -i &quot;debian&quot; /proc/version 2&gt;/dev/null) if [ &quot;$os_release&quot; ] &amp;&amp; [ &quot;$os_release_2&quot; ] then if echo &quot;$os_release&quot;|grep &quot;Linux 6&quot; &gt;/dev/null 2&gt;&amp;1 then os_release=debian6 echo &quot;$os_release&quot; elif echo &quot;$os_release&quot;|grep &quot;Linux 7&quot; &gt;/dev/null 2&gt;&amp;1 then os_release=debian7 echo &quot;$os_release&quot; else os_release=&quot;&quot; echo &quot;$os_release&quot; fi break fi break done&#125;os_release=$(check_os_release) shell获取系统硬件资源信息123456789101112131415161718192021222324252627282930313233343536373839404142#获取centos信息get_info()&#123; os_sys=`uname -o` product_id=`dmidecode -t 1 | grep Serial` if [[ $os_release =~ &apos;ubuntu&apos; ]];then os_version=`grep -i &quot;ubuntu&quot; /etc/issue | awk -F&apos; &apos; &apos;&#123;print $1$2$3&#125;&apos;` elif [[ $os_release =~ &apos;centos&apos; ]];then os_version=`cat /etc/redhat-release` elif [[ $os_release =~ &apos;redhat&apos; ]];then os_version=`cat /etc/redhat-release` else os_version=`cat /etc/redhat-release` fi os_kernel=`uname -r` cpu_model=`grep &apos;model name&apos; /proc/cpuinfo |uniq |awk -F : &apos;&#123;print $2&#125;&apos;` cpu_num=`cat /proc/cpuinfo| grep &apos;physical id&apos;| sort| uniq| wc -l` cpu_core=`grep &apos;cpu cores&apos; /proc/cpuinfo |uniq |awk -F : &apos;&#123;print $2&#125;&apos;` cpu_load=`cat /proc/loadavg | awk &apos;&#123;print $1&#125;&apos;` #mem_total=`free -m |grep -i mem |awk &apos;&#123; print $2&#125;&apos;` #系统总内存,与物理不符,因为系统初始化会保留一部分内存 mem_total=(`dmidecode -t memory | grep &apos;Installed Size&apos; | awk -F : &apos;NR==1&#123; print $2 &#125;&apos;`) #disk_total=`lsblk | grep -E -i &apos;disk|磁盘&apos; | grep -E -i &apos;sd|vd&apos; | awk &apos;&#123; print $4 &#125;&apos; | sed &apos;s/G//g&apos;` disk_total_o=`cat /proc/partitions | grep -w &quot;0&quot; |grep -E -i &apos;sd|vd&apos; | awk &apos;&#123;print $3&#125;&apos;` disk_total=$[disk_total_o/1024/1024] # SUSE lsblk -m | grep -E -i &apos;disk|磁盘&apos; | grep -E -i &apos;sd|vd&apos; | awk &apos;NR==1&#123; print $2 &#125;&apos;#dict echo &quot;&#123;\ \&quot;os_sys\&quot;:\&quot;$os_sys\&quot;,\ \&quot;os_version\&quot;:\&quot;$os_version\&quot;,\ \&quot;os_kernel\&quot;:\&quot;$os_kernel\&quot;,\ \&quot;cpu_model\&quot;:\&quot;$cpu_model\&quot;,\ \&quot;cpu_num\&quot;:\&quot;$cpu_num\&quot;,\ \&quot;cpu_core\&quot;:\&quot;$cpu_core\&quot;,\ \&quot;mem_total\&quot;:\&quot;$mem_total\&quot;,\ \&quot;product_id\&quot;:\&quot;$product_id\&quot;,\ \&quot;disk_total\&quot;:\&quot;$disk_total\&quot;\ &#125;&quot;&#125;echo $(get_info) win7 centos双系统 引导修复先有centos7 再有win7 1234# 修复grub引导grub2-install --root-directory=/mnt/sysimage /dev/sdasyncreboot 先有win7 再有centos7 需要安装ntfs-3g 12345678910111213yum -y install epel-releaseyum -y install ntfs-3g# 修复启动项grub2-mkconfig -o /boot/grub2/grub.cfg# 设置默认启动win7，&quot;Windows 7&quot;是根据文件/boot/grub2/grub.cfg中得到的# 查找配置文件中的 menuentry &apos;xxxxxx&apos; 的项就是了, &apos;xxxxxx&apos;可随意更改。grub2-set-default &quot;Windows 7&quot;grub2-editenv list]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>-个人备忘手册</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python相关备忘]]></title>
    <url>%2F1111%2F11%2F11%2Fpython%E7%9B%B8%E5%85%B3%E5%A4%87%E5%BF%98%2F</url>
    <content type="text"><![CDATA[python相关的一些记录,初衷是记录一些 包括web,linux,以及python语法等 web相关python3安装123456789101112131415161718192021222324#安装Python3.4yum -y install epel-releaseyum install python34#安装pip3yum -y install python34-pip或yum install python34-setuptoolseasy_install-3.4 pip#使用pip3了，如：pip3 install numpy#pip更换源安装阿里云 http://mirrors.aliyun.com/pypi/simple/中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/ 豆瓣(douban) http://pypi.douban.com/simple/ 清华大学 https://pypi.tuna.tsinghua.edu.cn/simple/中国科学技术大学 http://pypi.mirrors.ustc.edu.cn/simple/#使用方法很简单，直接 -i 加 urlpip install web.py -i http://pypi.douban.com/simple 字符串取数字12t = &apos;aaa18aaa&apos;print(filter(str.isdigit, t))]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用配置文件示例]]></title>
    <url>%2F1111%2F11%2F11%2Fzz%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%A4%BA%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[常用配置文件示例 nginx反代,跨域,session一个tomcat下跑多个应用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188#user nobody;worker_processes auto;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; use epoll; worker_connections 1024; multi_accept on;&#125;http &#123; include mime.types; default_type application/octet-stream; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #access_log logs/access.log main; server_names_hash_bucket_size 128; client_header_buffer_size 32k; large_client_header_buffers 4 32k; client_max_body_size 50m; sendfile on; tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; gzip on; gzip_min_length 1k; gzip_buffers 4 16k; gzip_http_version 1.1; gzip_comp_level 2; gzip_types text/plain application/javascript application/x-javascript text/javascript text/css application/xml application/xml+rss; gzip_vary on; gzip_proxied expired no-cache no-store private auth; gzip_disable &quot;MSIE [1-6]\.&quot;; server &#123; listen 80; server_name 192.168.1.42; error_log logs/error.log; access_log logs/access.log; default_type &apos;text/html&apos;; charset utf-8; #charset koi8-r; #access_log logs/host.access.log main; #root /usr/local/nginx/html; location / &#123; root /usr/local/nginx/html; #index index.html index.htm; add_header &apos;Access-Control-Allow-Origin&apos; *; try_files $uri $uri/ @router; index index.html index.htm; &#125; location /itsm/ &#123; root /usr/local/nginx/html; add_header &apos;Access-Control-Allow-Origin&apos; *; #try_files $uri $uri/ @router; try_files $uri $uri/ /itsm/index.html; index index.html index.htm; #error_log logs/vue_itsm_error.log; #access_log logs/vue_itsm_access.log; &#125; location @router &#123; rewrite ^.*$ /index.html last; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # location ~ \.php$ &#123; root /usr/local/nginx/html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /usr/local/nginx/html/$fastcgi_script_name; include fastcgi_params; access_log logs/php_access.log; error_log logs/php_error.log notice; &#125; location /cmdb &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://192.168.1.42:8080/cmdb/; proxy_ignore_client_abort on; #error_log logs/cmdb_error.log; #access_log logs/cmdb_access.log; &#125; location /itsm/cmdb &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://192.168.1.42:8080/cmdb/; proxy_ignore_client_abort on; #error_log logs/cmdb_error.log; #access_log logs/cmdb_access.log; &#125; location /itsmboot &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://192.168.1.42:8080/itsmboot/; proxy_cookie_path /cmdb /itsmboot; #处理跳转的 proxy_ignore_client_abort on; # error_log logs/itsm_error.log; # access_log logs/itsm_access.log; &#125; location /itsm/itsmboot &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://192.168.1.42:8080/itsmboot/; proxy_ignore_client_abort on; # error_log logs/itsm_error.log; # access_log logs/itsm_access.log; &#125; #websocket ping location /cmdb/wsping &#123; proxy_pass http://192.168.1.155:8080/cmdb/webSocket; proxy_redirect off; proxy_read_timeout 300s; proxy_send_timeout 300s; proxy_pass_request_headers on; #proxy_cookie_path /cmdb /itsmboot; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection Upgrade; &#125; location /api &#123; uwsgi_pass 0.0.0.0:18001; include /usr/local/nginx/conf/uwsgi_params; error_log logs/api_error.log; access_log logs/api_access.log; &#125; location /monitor &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://192.168.1.36:8080/monitor/; proxy_ignore_client_abort on; error_log logs/monitor_error.log; access_log logs/monitor_access.log; proxy_redirect off; &#125; &#125;&#125; redis文件中的路径根据实际情况修改 /etc/redis.conf123456789port 6379protected-mode no #保护模式 开启则需要配置bind和密码,否则关闭daemonize yes #开启后台进程pidfile /var/redis/run/6379.pidlogfile /var/redis/log/redis.logdbfilename dump.rdbdir /var/redis/data #数据库路径 默认是./requirepass centos #设置密码为centos#bind 127.0.0.1 默认是开启的，只允许本地登陆，所以，要不添加IP，要不给注释了 /etc/init.d/redis1234567891011121314151617181920212223242526272829303132333435363738#!/bin/shREDISPORT=6379EXEC=/usr/local/redis/bin/redis-serverCLIEXEC=/usr/local/redis/bin/redis-cliPIDFILE=/var/redis/run/$&#123;REDISPORT&#125;.pidCONF=&quot;/etc/redis.conf&quot;case &quot;$1&quot; in start) if [ -f $PIDFILE ] then echo &quot;$PIDFILE exists, process is already running or crashed&quot; else echo &quot;Starting Redis server...&quot; $EXEC $CONF fi ;; stop) if [ ! -f $PIDFILE ] then echo &quot;$PIDFILE does not exist, process is not running&quot; else PID=$(cat $PIDFILE) echo &quot;Stopping ...&quot; $CLIEXEC -p $REDISPORT shutdown while [ -x /proc/$&#123;PID&#125; ] do echo &quot;Waiting for Redis to shutdown ...&quot; sleep 1 done echo &quot;Redis stopped&quot; fi ;; *) echo &quot;Please use start or stop as first argument&quot; ;;esac]]></content>
  </entry>
  <entry>
    <title><![CDATA[李自立-个人简历]]></title>
    <url>%2F1111%2F11%2F01%2F%E4%B8%AA%E4%BA%BA%E7%AE%80%E5%8E%86%2F</url>
    <content type="text"><![CDATA[个人简历 个人信息 3年工作经验姓名 : 李自立 | 男 | 1990年6月生户口 ：河南-平顶山 | 现居住于:上海-闵行区联系方式 : 18521501353E-mail ： zili.li@foxmail.com 求职意向 工作性质：全职期望职业：系统工程师 运维工程师工作地区：上海目前状况：我目前在职，正考虑换个新环境（如有合适的工作机会，到岗时间一个月左右） 自我评价 熟悉Zabbix,Mysql,ELK,Jenkins,ansible等，空闲时学习了PHP，可在LAMP环境下进行web开发，后学习py3，调用微信API，结合Zabbix API，以Django为后台开发出告警系统。对Nginx、redis，saltstack等都有一定的了解与认识 工作经历 2017/03 -- 至今万达信息股份有限公司 |系统工程师行业类别： 计算机软件|企业性质：上市公司规模：1000-9999人|职位月薪：6-8k元/月 1234567工作描述：1: 预约系统.中间件是weblogic,Nginx代理.后搭建ELK对日志进行收集与分析.jenkins对项目部署做支持.2: 监控.部署Zabbix监控平台,并开发配套监控系统.3: 备份.公司各部门的数据备份,做raid5,安装ESXI,搭建备份服务环境,学习使用备份软件,到后续的备份维护与支持.4: 云桌面. 维护申康客服中心,vmware Horizon6云桌面,其中涉及AD,SQL,DHCP等,提供相应技术支持与维护.5: 公司云资源的维护.维护各部门在虚拟化平台上申请的云资源. 2014/04 -- 2017/01上海易声通信技术发展有限公司 |网络工程师行业类别： 通信/电信运营、增值服务企业性质：民营|规模：20-99人|职位月薪：4-6K/月123456工作描述：1：公司业务运维.配合各地pop点对通讯线路进行开通,联调与测试保证业务正常运行，以及对问题的及时响应和处理。2：系统集成项目.综合布线，路由交换，服务器的安装与配置等3：监控.对网络设备,服务器等进行监控. 教育背景 2011/03 -- 2016/01 ： 南阳师范学院 | 计算机科学与技术 | 本科 | 非统招 2016/05-- 2016/09 ： 上海央邦,系统的学习了Linux,并取得相关认证. 项目经验 时间 : 2017/05 – 2017/09项目名称 : 监控系统部署&amp;开发责任描述 :123456此次项目担任工程师职责.由于公司云主机较多,人员架构较复杂,icinga告警的推送较乱且不太智能，由此而有了需求.接着便部署了zabbix server,zabbix proxy,对mysql做了主从同步调用zabbix的api,结合企业微信接口,通过Django 后台,对告警系统进行了升级,做到可交互,权限划分,告警的时刻监控,等功能,将告警的推送范围有效的缩小,并对事件有了跟进效果. 时间 : 2017/04 - 2017/04项目名称 : 预约平台规划与部署责任描述 :1234此次项目担任工程师职责.客服中心有应用上线,需要一个平台.程序是java写的按要求运行在weblogic10上.keepalive做了冗余,前端用nginx做反向代理后续加入了ELK日志统计.对异常IP访问,页面响应时间等进行记录随后搭建jenkins对项目部署做支持.整个环境基本成型,将所有设备加入监控. 作品展示 12网络同事对信息的录入还处于excel手工状态,查询,更新,各同事件的协调都不方便个人根据情况,将数据导入mysql,基于LAMP环境,开发了简单的信息统计系统 1234以Django为后台,调用zabbix API 和微信接口,处理前台交互.菜单页支持最近事件查询,事件批量确认以及未处理事件查询(图片未截全)整个事件都做了相应权限划分,只有相关人员可收到相关信息. 1日志服务器 1RHCE]]></content>
  </entry>
</search>
